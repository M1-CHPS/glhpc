{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GLHPC - Introduction","text":"<p>This course is intended for M1 Calcul Haute Performance et simulation (M1CHPS) students as a crash course for programming techniques specific to High Performance Computing and Artificial Intelligence applications. This course will cover programming basics in C and shell, and will gradually move on to more complex notions such as parallelism, performance profiling, experimental design, and the implementation of a Neural Network from scratch.</p>"},{"location":"#organisation","title":"Organisation","text":"<p>This course is organised as a mixture of lectures and labs. The lectures are available online in the Course section of this website, and may be provided as slides by your professor.</p> <p>The labs subjects are contained in the same section, but code snippets and other ressources will be provided via github classroom.</p>"},{"location":"#advanced-content","title":"Advanced content","text":"<p>Some of you may come from a CS background and already have strong notions of C programming. This course includes Advanced and optionnal sections to keep you busy during class hours.</p>"},{"location":"guide_soutenance/","title":"Graded Project","text":"Submission Checklist <ul> <li>Your archive is named <code>nom_prenom.tar.gz</code></li> <li>It contains a folder <code>nom_prenom/</code></li> <li>You included <code>build.sh</code>, <code>run.sh</code>, and your code in <code>src/</code></li> <li>Your report is named <code>nom_prenom.pdf</code></li> <li>No binaries or compiled files are included</li> <li>You submitted a GitHub repo link in the email</li> </ul>"},{"location":"guide_soutenance/#0-instructions","title":"0 - Instructions","text":"<p>You are to provide a short report, between 3-5 pages, answering the subject below. The submission deadline will be provided via email during the semester.</p>"},{"location":"guide_soutenance/#01-submission-guideline","title":"0.1) Submission guideline","text":"<p>Danger</p> <p>You must follow these submission guidelines exactly. Failure to do so may result in your project not being graded and defaulting to the second exam session.</p> <ul> <li>Send, by email, a .tar.gz file named <code>nom_prenom.tar.gz</code><ul> <li>You can create it by using: <pre><code>tar -czvf nom_prenom.tar.gz ./nom_prenom\n</code></pre></li> </ul> </li> <li>Your project must follow the directory structure below:     <pre><code>nom_prenom/\n    build.sh # Script to build your project (This can call make or cmake, etc.)\n    run.sh   # Script to run your project\n    src/\n        # All of your .c and .h files go here\n    scripts/\n        # All of your analysis or bash scripts go here\n    nom_prenom.pdf # Your report\n</code></pre></li> <li>Create a public github repository containing your code, and send the link along with the archive.</li> <li>Do not include any binaries or compiled files: no <code>.o</code>, <code>.a</code>, <code>.so</code>, or executables.</li> <li>Deadline policy: Submissions after the deadline will incur a penalty of -1 point per 5 minutes.</li> </ul>"},{"location":"lab1/","title":"Lab 1 - Prerequisites - Linux, the shell, Git","text":""},{"location":"lab1/#objective","title":"Objective","text":"<p>In this lab, you will get familliar with the very basics of using the linux shell, using and installing a code editor, and setup git.</p> <p>The final section of this lab will have you combine all this tools to setup a simple project for a Hello World program in C.</p>"},{"location":"lab1/#0-linux","title":"0 - Linux","text":"<p>Linux is a family of Operating Systems (like Windows or MacOS) that are suited for programming. Most High-Performance clusters will run a version of linux, and as such it is mandatory that you learn how to use it.</p> <p>If you have a personal laptop, I highly recommend you to setup linux (Or MacOS) on it. Alternatively, you can use Docker or a virtual machine on Windows, but note that this is highly impractical. Lastly, you can setup and use WSL.</p> <p>Tip</p> <p>The university may be able to lend laptops while you're on-site, but you likely won't be able to bring them home for assignments.</p>"},{"location":"lab1/#1-optional-installing-fedora","title":"1  (Optional)  - Installing Fedora","text":"<p>If you want to install Linux on your personal laptop but aren\u2019t sure where to start, you can follow these instructions.</p> <p>Fedora is a modern, open-source Linux distribution sponsored by Red Hat. It ships with the GNOME 3 desktop environment by default and uses <code>dnf</code> as its package manager.</p> <p>If you're new to Linux and want something simple to use, Fedora is a great place to start.</p>"},{"location":"lab1/#2-the-linux-shell-and-bash","title":"2 - The linux Shell and Bash","text":"<p>On Windows/MacOS, you most likely use the file manager or other graphical interfaces to interact with your computer. On linux however, we use the Linux Shell via a terminal/console.</p> <p></p> <p>The shell is a very powerful tool that allows you to interact with your computer in many ways. We will only cover the basics in this lab.</p>"},{"location":"lab1/#a-first-try-starting-a-new-terminal","title":"a) First, try starting a new terminal","text":"<p>Look for an app called <code>terminal</code>, <code>console</code> or even <code>konsole</code>. In some linux distribution, <code>CTRL+ALT+T</code> will open a new terminal.</p> <ul> <li>A <code>terminal</code> is the graphical application displaying the text.</li> <li>A <code>shell</code> is the underlying program that interprets and executes commands that you provide. By default, your shell will probably be <code>bash</code>, which is one of the most basic shells available. All shells serve the same function, but some come with plugins and other tools to make your life easier.</li> </ul> <p>Warning</p> <p>To copy/paste in your terminal you must use <code>CTRL+SHIFT+C</code> and <code>CTRL+SHIFT+V</code>. Pressing <code>CTRL+C</code> will KILL (stop) the current command.</p> <p>If you press <code>CTRL+S</code>, this will put the terminal on hold. Nothing will display anymore. Press <code>CTRL+Q</code> to re-enable your terminal</p>"},{"location":"lab1/#1-basic-exercices","title":"1. Basic Exercices","text":"<p>We will now dive in the very basics on how to use the shell. Note that the exercices presented here are minimal, and there's much to discover. Lines starting with a <code>#</code> are comments and should not be executed.</p>"},{"location":"lab1/#a-try-inputing-the-following-commands-what-does-the-ls-command-do","title":"a) Try inputing the following commands. What does the <code>ls</code> command do ?","text":"<pre><code># Don't worry about this yet\ncd ~\nls\nls -lh\nls -lah\n</code></pre>"},{"location":"lab1/#b-run-the-following-commands-step-by-step-and-try-to-understand-what-is-happening","title":"b) Run the following commands step-by-step and try to understand what is happening:","text":"<p><pre><code>ls\nmkdir glhpc\nls\ncd ./glhpc\nls\nmkdir lab1\ncd ./lab1\nls\n</code></pre> What does <code>mkdir</code> do ? <code>cd</code> ?</p>"},{"location":"lab1/#c-based-on-the-previous-question-could-you-give-a-definition-for-the-term-current-working-directory-cwd","title":"c) Based on the previous question, could you give a definition for the term \"Current Working Directory\" (CWD) ?","text":"<p>Execute the following to confirm your definition:</p> <pre><code>pwd\n</code></pre>"},{"location":"lab1/#d-execute-the-following-step-by-step","title":"d) Execute the following step-by-step:","text":"<pre><code>echo \"Bonjour\"\necho \"Bonjour, mon username est $USER et mon home est dans $HOME\"\necho \"Bonjour\" &gt; bonjour.txt\nls\ncat ./bonjour.txt\nls -lah &gt; ./bonjour.txt\ncat ./bonjour.txt\n</code></pre> <ul> <li>What does <code>echo</code> do ? What is your <code>USER</code> and your <code>HOME</code> ?</li> <li>What does the <code>&gt;</code> operator do ? (Tips: Did you see the output of this command in your terminal ?)</li> <li>What does <code>cat</code> do ?</li> </ul>"},{"location":"lab1/#e-execute-the-following","title":"e) Execute the following:","text":"<pre><code>pwd\ncd ..\nmkdir lab1\n</code></pre> <ul> <li>Did the last command (<code>mkdir lab1</code>) work ? Why not ?</li> <li>What does <code>cd ..</code> do ? What does <code>..</code> mean ? </li> <li>Execute these commands: <code>pwd</code>, <code>realpath .</code>, <code>realpath ..</code>, <code>realpath ~/glhpc/lab1/..</code></li> </ul>"},{"location":"lab1/#f-run-the-following","title":"f) Run the following:","text":"<pre><code>man mkdir\n</code></pre> <p>What do you see ? Try to find the <code>mkdir</code> flag to disable errors on existing folders, so that <code>mkdir lab1</code> runs succesfully.</p> <p>Press the <code>q</code> key to exit <code>man</code>. </p> <p>Tip</p> <p>What you just saw is called a <code>man page</code>. <code>man</code> is short for <code>manual</code>. It's an offline documentation that is always available on all shells.  Some tools also provide <code>man pages</code> when installed, so that you can always search for documentation. You can even search <code>man man</code> !</p> <p>If you're ever stuck on a problem/bug (and you will), you should always read the documentation, or the man pages, for solutions. Googling a bug or an error message is not cheating. This is commonly referred to as <code>Read The F*cking Manual</code> (RTFM).</p>"},{"location":"lab1/#2-more-exercices","title":"2. More Exercices","text":""},{"location":"lab1/#a-find-what-is-the-shortcut-for","title":"a) Find what <code>~</code> is the shortcut for","text":"<pre><code>cd ~\n</code></pre>"},{"location":"lab1/#b-create-the-following-file-structure-using-only-your-terminal","title":"b) Create the following file structure using only your terminal:","text":"<pre><code>exo7/\n    readme.md # With the text \"Bonjour !\"\n    dossier0/\n        test.txt  # With the text \"test0\"\n    dossier1/\n        test.txt # With the text \"test1\"\n</code></pre> <p>This directory should be located inside <code>~/glhpc/lab1/exo7</code></p> <p>It should look something like this (the <code>tree</code> command may not be available on your shell):</p> <p></p>"},{"location":"lab1/#c-finally-run-the-following-from-glhpclab1","title":"c) Finally, run the following from <code>~/glhpc/lab1</code>","text":"<pre><code>cp -r ./exo7 ./exo7_copy\n</code></pre> <p>What does <code>cp</code> do ? Why do we use the <code>-r</code> flag ?</p> <p>The <code>rm</code> command is used to remove files, while the <code>rmdir</code> command is used to delete empty folders. In order to delete a folder, and all the files it contains, we must use the <code>--force</code> and <code>--recursive</code> flags, also known as <code>rm -rf</code>.</p> <p>Try the following: <pre><code>rm -rf ./exo7_copy\n</code></pre></p> <p>Danger</p> <p><code>rm -rf</code> is definitive: there is no way to recover your files after this. No trashbin. If you delete an important folder, it is gone forever. </p> <p>You should always be very careful when doing this.</p> <p>Thought experiment: what would happen if you were to run <code>rm -rf /</code>, where <code>/</code> is the root of your filesystem ? In modern shells, it will probably show an error, or ask for confirmation, but yes, this could instantly erase all of your files, including your operating system, and crash your computer.</p>"},{"location":"lab1/#3-cheatsheet","title":"3. Cheatsheet \ud83d\udc0d","text":"Goal Command Variants Create a directory <code>mkdir &lt;path&gt;</code> <code>mkdir -p &lt;path&gt;</code> to ignore errors Go inside a directory <code>cd &lt;path&gt;</code> <code>cd ..</code> to go up one level, <code>cd ~</code> to go to your home List all files <code>ls (&lt;path&gt;)</code> <code>ls -lah (&lt;path&gt;)</code> for pretty print with human-readable numbers. Show hidden files Print cwd <code>pwd</code> Convert to absolute path <code>realpath (&lt;path&gt;)</code> Print text <code>echo &lt;text&gt;</code> <code>echo $&lt;VARIABLE&gt;</code> to print a variable Redirect output to file <code>&gt;</code> Example: <code>echo \"Bonjour\" &gt; test.txt</code> Print file content <code>cat &lt;path&gt;</code> For big files: <code>less &lt;path&gt;</code> Delete a file <code>rm &lt;path&gt;</code> Delete a directory <code>rmdir &lt;path&gt;</code> Delete a non empty directory <code>rm -rf &lt;path&gt;</code> Create empty file <code>touch &lt;path&gt;</code> Copy a file <code>cp &lt;input&gt; &lt;output&gt;</code> <code>cp -r &lt;input&gt; &lt;output&gt;</code> to copy folders recursively"},{"location":"lab1/#4-going-further-upgrading-bash","title":"4.  (Going-Further) Upgrading bash","text":"<p>While powerful, <code>bash</code> is a very basic shell. Some shells like <code>fish</code> or <code>oh-my-zsh</code> come with extensions/plugins that can significantly improve your workflow, with auto-completion, coloring, suggestions and many other.</p> <p>In the near future, you will spend a lot of time in your programming environment. Taking a few hours making it more practical or comfortable is a worthwhile investement.</p> <p>A minimalist <code>oh-my-zsh</code> setup is described here. <code>fish</code> is very simple to install and pretty powerful, but I do not recommend it due to some <code>bash</code> incompatibilities. </p>"},{"location":"lab1/#3-optional-code-editor-vscode","title":"3 -  (Optional)  Code Editor (VSCode)","text":"<p>We are now going to see the second most critical tool you will use during the Master, second only to the shell: a code editor. Modern code editors allow you to open source files, images, pdf, or even videos. You use your editor to create programs, and the shell to execute them. </p> <p></p> <p>As a starting point, you should download <code>VSCode</code> which will cover most of your needs in the future. Do NOT listen to your obnoxious classmates telling you to \"just use vim\". They cannot be saved.</p>"},{"location":"lab1/#1-installation","title":"1. Installation:","text":""},{"location":"lab1/#a-direct-download","title":"a) Direct download","text":"<p>Go to the VSCode Website and select the option matching your OS. For Fedora, click on the <code>.rpm</code> button. </p> <p>Then double click on the downloaded <code>.rpm</code> file to automatically install <code>VSCode</code>. </p> <p>You can achieve the same effect using: <pre><code># Replace with the correct file:\nsudo dnf install ./code-1.99.3-1744761644.el8.x86_64.rpm\n</code></pre></p>"},{"location":"lab1/#b-snap-install","title":"b) Snap install","text":"<p>Snap is a very helpful application to automatically install, update, and manage third-party tools (VSCode, pycharm, Spotify, etc.)</p> <pre><code># For Fedora:\nsudo dnf install snap\nsnap install code\n</code></pre>"},{"location":"lab1/#c-usage","title":"c) Usage","text":"<p>Using your shell navigate to the directory you wish to open in VSCode:</p> <pre><code>cd ./glhpc/\ncode .\n</code></pre> <p>From there, try creating a file, installing extensions (Python, C++, cmake, etc.) and familiarize yourself with the shortcuts.</p> <p>Tip</p> <p>You can also open a terminal directly inside VSCode ! </p> <p>The shortcut should be <code>CTRL+J</code>, but you can always use the terminal menu.</p>"},{"location":"lab1/#4-getting-ready-for-git","title":"4 - Getting ready for git","text":"<p>A critical part of programming is called \"versionning\" or \"Version Control System\" (VCS). This answers the following questions:</p> <ul> <li>How can I share my code with my colleagues / classmates / friends / everyone ?</li> <li>How can I keep a history of the different versions of my code ? Say <code>version 1.0</code>, <code>v2.0</code>, <code>v3.0.1.alpha-prelease</code>, etc.</li> <li>How can multiple people work together on the same project ?</li> </ul> <p>We will dive into git later. For now, do the following:</p>"},{"location":"lab1/#a-create-a-github-account-if-you-dont-already-have-one","title":"a) Create a Github account if you don't already have one.","text":"<p>You may wish to keep this account after the master: you should use your personal email so you won't lose acces to it.</p> <p>You should setup two factor authentication (2FA) ASAP.</p> <p>Note</p> <p>Your github page is your portfolio. Your recruiter may look it up, or you may be able to bring it up during interviews to show projects you worked on previously. </p> <p>You should take care of it, and have a few clean projects to show !</p>"},{"location":"lab1/#b-follow-the-official-guide-on-how-to-generate-and-add-an-ssh-key-to-your-github-account","title":"b) Follow the official guide on how to generate and add an ssh key to your github account.","text":""},{"location":"lab1/#5-first-c-project","title":"5 - First C Project","text":""},{"location":"lab1/#1-creating-the-project","title":"1. Creating the project","text":""},{"location":"lab1/#a-create-the-following-file-structure","title":"a) Create the following file structure:","text":"<pre><code>lab1/\n    first_c_project/\n        build.sh # Empty text file\n        src/\n            main.c # Empty text file\n</code></pre> <p>Try to do this only using the shell. If you're using VSCode you can <code>cd</code> into <code>first_c_project</code> and run <code>code .</code></p>"},{"location":"lab1/#b-modify-mainc-so-that-it-contains","title":"b) Modify <code>main.c</code> so that it contains:","text":"main.c<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main(int argc, char** argv) {\n    printf(\"Hello World !\");\n    return 0;\n}\n</code></pre>"},{"location":"lab1/#c-create-a-gitignore-text-file-inside-the-first_c_project-folder-with-the-content","title":"c) Create a .gitignore text file inside the <code>first_c_project</code> folder, with the content:","text":".gitignore<pre><code>*.o\n*.a\n*.so\n*.out\nmain\n</code></pre> <p>A <code>.gitignore</code> file act as a recursive filter for git: all files that match a pattern contained in the <code>.gitignore</code> will be ignored and invisible to git.</p> <p>The <code>*</code> character is called a wildcard: it matches everything. For example, the <code>*.o</code> pattern will filter the files <code>main.o</code>, <code>aaababa.o</code>, etc.</p>"},{"location":"lab1/#2-setup-git","title":"2. Setup git","text":"<p>Please refer to Lecture 1 for all the git commands you will need in this section.</p>"},{"location":"lab1/#a-initialize-a-new-git-repository-inside-the-lab1-folder","title":"a) Initialize a new git repository inside the lab1 folder.","text":""},{"location":"lab1/#b-run-git-status-then-stage-all-files-from-first_c_project-as-well-as-gitignore-in-git","title":"b) Run <code>git status</code>, then stage all files from <code>first_c_project</code> as well as <code>.gitignore</code> in git.","text":""},{"location":"lab1/#c-create-a-first-commit-with-the-message-my-first-commit","title":"c) Create a first commit with the message \"My first commit\"","text":"<p>I recommend you use the command <code>git commit -m \"&lt;message&gt;\"</code> or git may open nano/vim for you to edit the commit message, which may be confusing.</p>"},{"location":"lab1/#d-ensure-the-commit-worked","title":"d) Ensure the commit worked:","text":"<p><code>git log</code> should display the previous commit, and <code>git status</code> should no longer display the content of <code>first_c_project</code>. Feel free to commit files from the previous exercises of the lab if you want.</p>"},{"location":"lab1/#3-compiling-and-running-c-code","title":"3. Compiling and running C code","text":"<p>We will now try to run our first program, but before that we need to install a few tools.</p>"},{"location":"lab1/#a-install-gcc","title":"a) Install GCC","text":"<p>First, we need a C compiler to transform the <code>main.c</code> file into an executable. We will see in future courses what this does.</p> <p>For now, install the following packages:</p> Fedora<pre><code>sudo dnf install gcc glibc-devel make gdb valgrind\n</code></pre> Ubuntu<pre><code>sudo apt update\nsudo apt install gcc libc6-dev make gdb valgrind\n</code></pre>"},{"location":"lab1/#b-check-gcc-is-working","title":"b) Check GCC is working","text":"<p>Run the following:</p> <p><pre><code>gcc --version\n</code></pre> Expected output<pre><code>gcc (GCC) 14.3.1 20250808 (Red Hat 14.3.1-3)\nCopyright (C) 2024 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre></p>"},{"location":"lab1/#c-compiling-mainc","title":"c) Compiling <code>main.c</code>","text":"<p>You can now compile your first program by running</p> <pre><code>gcc src/main.c -o main -g \n</code></pre> <p>You should see that a <code>main</code> file has been created for you.</p>"},{"location":"lab1/#d-run-main","title":"d) Run main","text":"<p>Run the program by using <code>./main</code></p>"},{"location":"lab1/#4-first-compilation-script","title":"4. First compilation script","text":""},{"location":"lab1/#a-create-a-buildsh-script-that-contains-the-compilation-command","title":"a) Create a <code>build.sh</code> script that contains the compilation command.","text":""},{"location":"lab1/#b-try-to-run-buildsh-does-it-work","title":"b) Try to run <code>./build.sh</code>. Does it work ?","text":"<p>Linux uses a concept of file permissions: some files can be read, written to, executed, or a mix of the previous. These permissions are user dependent: you are allowed to read your own files, but this privilege should not extend to other users.</p> <p>Run the following:</p> <pre><code>ls -lah\n</code></pre> Expected output<pre><code>-rw-r--r--.  1 user user   0 Aug 26 9:48 build.sh\n</code></pre> <p><code>rw-r--r--</code> can be read as: </p> <ul> <li>The user can Read and Write</li> <li>The group can Read</li> <li>Others can Read</li> </ul>"},{"location":"lab1/#c-make-buildsh-executable","title":"c) Make <code>build.sh</code> executable","text":"<p>Run the following:</p> <pre><code>chmod +x ./build.sh\n</code></pre> <p><code>chmod</code> is a command to modify the permissions of a file. <code>x</code> designates the eXecution permission, so this command can be read as add execution permission to build.sh.</p> <p>You should see that the file now has permissions <code>rwxr-xr-x</code>. This can be read as:</p> <ul> <li>The user can Read, Write, and eXecute</li> <li>The Group can Read and eXecute</li> <li>Others can Read and eXecute</li> </ul>"},{"location":"lab1/#d-restrict-permissions-so-that-only-you-the-owner-can-read-write-and-execute-buildsh-neither-the-group-nor-others-should-have-any-permissions","title":"d) Restrict permissions so that only you (the owner) can read, write, and execute build.sh. Neither the group nor others should have any permissions.","text":"<p>In binary:</p> <ul> <li><code>rwx</code> = 111 = 7</li> <li><code>r-x</code> = 101 = 5</li> <li><code>r--</code> = 100 = 4</li> </ul> <p>One can write <code>chmod 444 ./build.sh</code> which translates to <code>r--r--r--</code> (100 100 100). </p> <p>Use this to find the command needed to only give permissions to yourself.</p>"},{"location":"lab1/#5-uploading-to-github","title":"5. Uploading to GitHub","text":""},{"location":"lab1/#a-commit-all-changes-youve-made-so-far-to-git","title":"a) Commit all changes you've made so far to git","text":"<p>Tip</p> <p>Git is recursive: it doesn't matter whether you run the git commands from <code>lab1</code> or <code>first_c_project</code>: git knows whether the <code>cwd</code> is contained inside a git repository.</p>"},{"location":"lab1/#b-create-an-empty-repository-on-the-github-website","title":"b) Create an empty repository on the GitHub website","text":"<p>Make sure the repository is empty, or you'll have to force push later on to overwrite it.</p>"},{"location":"lab1/#c-setup-the-remote-on-your-local-repository","title":"c) Setup the remote on your local repository","text":"<p>On the github website, you should see a green <code>code</code> button with an <code>ssh</code> option. Copy the link here. It should look something like:</p> <pre><code>git@github.com:user/lab1_repository.git\n</code></pre> <p>Then run: <pre><code>git remote add origin &lt;Your github link here&gt;\n</code></pre> This registers the GitHub repository repository as the remote repository. Origin is the name of the remote.</p>"},{"location":"lab1/#d-push-on-github","title":"d) Push on GitHub","text":"<p>The first time you push on the repository, git might:</p> <ul> <li>Ask you to setup your email/username: Follow git instructions and make sure to use the same as the one you've used on GitHub.</li> <li>Set the upstream branch using <code>--set-upstream</code>: Follow git instructions</li> </ul>"},{"location":"lab1/#5-summary","title":"5 - Summary","text":"<p>Upon completing this first lab, you should:</p> <ul> <li> Have a working programming environment</li> <li> Know how to navigate the file system with the shell</li> <li> Know how to use basic file operations</li> <li> Know how to use VSCode to write and edit files</li> <li> Be ready to use git with Github</li> </ul>"},{"location":"lab2/","title":"Lab 2: Performance Aware C Computing","text":""},{"location":"lab2/#objective","title":"Objective","text":"<p>You are tasked with implementing an efficient image processing pipeline. A pipeline looks like this:</p> Example transformation pipeline<pre><code>0 -1 load images/image1.png\n1 0 quantize 8\n2 1 invert\n3 2 save output/image0_transformed.png\n</code></pre> <p>The line <code>1 0 quantize 8</code> declares the node 1, whose parent is the node 0, and performs a quantization transformation with 8 levels. </p> <p>Note</p> <p>This structure is a Directed Acyclic Graph (DAG), a type of graph often used in data processing and scheduling.</p> Example Processing pipeline you will have to implement"},{"location":"lab2/#provided-files","title":"Provided Files","text":"<p>The parsing and pipeline execution logic have already been implemented so you can focus on managing memory and kernel implementations. The starter codebase contains the following directories and files:</p> Path Description <code>images/</code> Image resources for the lab. <code>pipelines/</code> Sample transformation pipelines to test your implementation. <code>src/</code> C source code for this lab. Contains the files listed below: <code>src/main.c</code> Parses the transformation graph and executes it. <code>src/parser.(c|h)</code> DAG representation for the image processing pipeline. <code>src/image.(c|h)</code> Image structure and utilities for memory allocation and management. <code>src/stb_image.h</code> Public domain header-only image I/O library (from GitHub). <code>src/transformation.c/h</code> Implementation of image processing kernels. Most functions are missing and must be implemented by you."},{"location":"lab2/#1-compiling-the-program","title":"1 - Compiling the program","text":""},{"location":"lab2/#a-write-a-makefile-that","title":"a) Write a <code>Makefile</code> that:","text":"<ul> <li>Compiles <code>main.c</code>, <code>image.c</code>, <code>parser.c</code> and <code>transformation.c</code> using <code>gcc</code></li> <li>Produces a binary named <code>mystransform</code> at the root of the project</li> <li>Exposes a <code>clean</code> target that removes compiled artifacts<ul> <li>This includes any <code>.o</code>, <code>.so</code>, <code>.out</code>, as well as the <code>mytransform</code> binary</li> </ul> </li> <li>You should link to the math standard library by using the <code>-lm</code> compilation flag </li> </ul> <p>Danger</p> <p>The output binary must be named <code>mystransform</code>, or later parts of the lab may not work correctly.</p>"},{"location":"lab2/#b-define-a-cflags-variable-inside-the-makefile","title":"b) Define a <code>CFLAGS</code> variable inside the <code>Makefile</code>","text":"<p>To get started, you should use <code>-Og -g -Wall -Wextra</code> as compilation flags. We will update this later. Ensure the flags are in effect.</p>"},{"location":"lab2/#c-run-make-then-try-running-mytransform","title":"c) Run <code>make</code> then try running <code>mytransform</code>","text":"<p>Execute the following: Running a simple pipeline<pre><code>./mytransform ./pipelines/test.pipeline\n</code></pre></p> Expected Output<pre><code>create_image - Not implemented yet\nCould not allocate image for load\nconvert_to_grayscale - Not implemented yet\ninvert_image - Not implemented yet\nNode 3 requested to save an image from node 2, which did not produce an image\nquantize_image_naive - Not implemented yet\nNode 5 requested to save an image from node 4, which did not produce an image\ninvert_image - Not implemented yet\nNode 7 requested to save an image from node 6, which did not produce an image\n</code></pre> <p>This indicates that your build works correctly and you can continue the lab. If needed, fix your <code>Makefile</code> until you obtain the same results.</p>"},{"location":"lab2/#2-allocating-manipulating-memory","title":"2 - Allocating &amp; Manipulating memory","text":"<p>Look at <code>image.c</code> and <code>image.h</code>, and try to understand the provided structure.</p> <ul> <li>Pixels are stored as <code>unsigned char* pixels[3]</code>: what does that mean in practice ? How many arrays do we have to allocate to store an RGB Image ? What's the size of each arrray ? What happens if we have a grayscale image (black &amp; white).</li> <li>How do we distinguish between grayscale and RGB images ?</li> </ul>"},{"location":"lab2/#1-implement-memory-allocation","title":"1. Implement Memory Allocation","text":""},{"location":"lab2/#a-implement-image-allocation","title":"a) Implement image allocation","text":"<p>You must implement the function <code>image.c:create_image(...)</code>.</p> <p>This function should allocate memory buffers big enough to hold an image of size \\(\\text{width} \\cdot \\text{height}\\). Note for this lab, channels can either be 1 (grayscale) or 3 (RGB).</p>"},{"location":"lab2/#b-implement-image-deallocaiton","title":"b) Implement image deallocaiton","text":"<p>You must implement <code>image.c:free_image(...)</code>.</p> <p>Make sure you can free both grayscale and RGB images. Note: you must also free the <code>Image</code> structure itself.</p>"},{"location":"lab2/#c-execute-the-memory-implementation-test","title":"c) Execute the memory implementation test","text":"<p>Compile your program and fix any errors until none are left. Run the following: Memory Test<pre><code>./mytransform --memory-check\n</code></pre></p> <p>You should get the following: Expected Output<pre><code>Memory Allocations tests completed successfully\n&lt;Lots of error about copy failure&gt;\n</code></pre></p>"},{"location":"lab2/#2-image-copying","title":"2. Image Copying","text":""},{"location":"lab2/#a-implement-image-copy","title":"a) Implement image copy","text":"<p>You must implement <code>Image* copy_image(const Image* image)</code> inside <code>src/image.c</code></p> <p>This functions receives an <code>Image*</code>, and produces a deepcopy, meaning that we are not copying the pointers, but allocating new pixels buffers and duplicating the image in memory.</p> <p>You shall not use <code>memcpy</code> or <code>strcpy</code> for this exercise: perform a manual copy.</p>"},{"location":"lab2/#b-execute-the-memory-implementation-test","title":"b) Execute the memory implementation test","text":"<p>Compile again and run: Memory Test<pre><code>./mytransform --memory-test\n</code></pre></p> <p>You should get the following: <pre><code>Memory Allocations tests completed in 5 seconds\nCopy Test: 3000x3000x3 image -&gt; 3524.74 MIOPS, 3.52 GB/s\n</code></pre></p>"},{"location":"lab2/#c-implement-2d-copy-loops","title":"c) Implement 2d copy loops","text":"<p>When copying, we have to deal with three dimensions: the channels, the width and the height.</p> <p>In which order does your current implementation traverse the pixel buffer ?</p> <p>Implement the following loop structure in C: 3D loop traversal<pre><code>for c in channels\n  for x in width\n    for y in height\n      # Do the copy here\n</code></pre></p> <p>Tip</p> <p>You should make a copy of your current implementation before implementing this structure, so you can compare the different versions.  Optionally, make multiple versions of <code>copy_image</code> with different names, and have <code>copy_image</code> call the version you want to test.</p> <p>Now, try swapping out the loop. First iterate on <code>y</code>, then <code>x</code>, then<code>c</code>. Try all possible combinations to find which one is faster. Can you explain why ?</p>"},{"location":"lab2/#d-implement-the-linear-versions","title":"d) Implement the linear versions","text":"<p>While images are 3D structures (When taking the channels into account), you may have noticed that we have stored them as 2D arrays (One linear array per channel).  Each channel is stored in ROW-MAJOR.</p> <ul> <li>Implement two nested loops: the upper levels iterating on the channels, the inner loop iterating over each pixel.</li> <li>Implement one loop: iterate only over the pixel, copying RGB in a single loop.</li> </ul> <p>Compare the performance by running the <code>--memory-check</code> option. Which loops give you the best performance ? Do you understand why ?</p>"},{"location":"lab2/#3-executing-a-transformation-pipeline","title":"3 - Executing a transformation pipeline","text":"<p>Look at <code>src/parser.h</code> and try to understand the different structures of the parser. Do the same for <code>src/transformation.c</code></p>"},{"location":"lab2/#1-implementing-grayscale","title":"1. Implementing Grayscale","text":"<p>The grayscale transform receives an RGB image and converts it into a black and white, single channel image. The formula for the transformation is:</p> \\[ C_{out} = 0.299 \\cdot R_{in} + 0.587 \\cdot G_{in} + 0.114 \\cdot B_{in} \\] <p>Where C is the grayscale channel, and R,G,B are the corresponding components of the RGB image.  Note: if the grayscale transform receives a grayscale image as input, it should output a (deep) copy of the input.</p>"},{"location":"lab2/#a-implement-this-transformation","title":"a) Implement this transformation","text":"<p>You should read data from <code>node.input</code>, and allocate and write data to <code>node.output</code>.  You do not need to free the <code>input</code> and <code>output</code> buffer of any of the nodes: it will be handled for you.</p> <p>Test using Test grayscale<pre><code>mkdir -p ./output\n./mytransform ./pipelines/test.pipeline\n</code></pre></p> <p>At this stage, <code>output/test_grayscale.png</code> should contain the grayscale of <code>images/test.png</code></p>"},{"location":"lab2/#2-implementing-inversion","title":"2. Implementing Inversion","text":"<p>The inversion transform is a simple one</p> \\[ C_{out} = 255 - C_{in} \\] <p>Where C is one of the input image channels (RGB or Grayscale). Implement this kernel in <code>transformation.c:invert_image(...)</code>.</p>"},{"location":"lab2/#3-implementing-quantization","title":"3. Implementing Quantization","text":"<p>We will implement a uniform quantization transform, which uniformly reduces the number of possible values in each component of the image.</p> \\[\\begin{aligned} \\text{step} &amp;= \\frac{255}{\\text{levels} - 1} \\\\\\\\ C_{out} &amp;= \\text{round}\\left(\\frac{C_{in}}{\\text{step}}\\right) \\cdot \\text{step} \\end{aligned}\\] <p>Where \\(\\text{levels}\\) is the target number of discrete values per component. This maps each input color channel value \\(C_{in} \\in [0, 255]\\) to a quantized output \\(C_{out}\\) in the same range.</p>"},{"location":"lab2/#a-implement-this-transformation-using-the-formula-provided-above","title":"a) Implement this transformation using the formula provided above.","text":"<p>You must implement this method in <code>transformation.c:quantize_image_naive(...)</code></p>"},{"location":"lab2/#b-optimize-using-a-lookup-table","title":"b) Optimize using a lookup table","text":"<p>Division and floating-point operations can be costly. Since \\(C_{in} \\in [0, 255]\\), we can easily precompute all possible outputs in a lookup table (LUT) of size 256,  then convert each pixel using:</p> \\[ C_{out} = LUT[C_{in}] \\] <p>We are trading memory overhead for performance, which is a very common pattern.</p> <p>Implement this method in <code>transformation.c:quantize_image_lut(...)</code>, and be sure to correctly allocate and free the LUT.</p>"},{"location":"lab2/#c-compare-performance","title":"c) Compare performance","text":"<p>Modify <code>transformation.c:quantize_image(...)</code> to either use the LUT or the naive version, and run the following code: Benchmarking<pre><code>time ./mytransform ./pipelines/quantize_benchmark.pipeline\n</code></pre></p> <p>Which version is faster ? What's the speedup of the LUT method over the naive version ?</p>"},{"location":"lab2/#4-validation","title":"4) Validation","text":"<p>At this stage, your code should be able to execute all pipelines in the <code>pipelines/</code> directory.  Validate your implementation by checking that output images are generated and appear visually correct.</p>"},{"location":"lab2/#1-improving-performance","title":"1. Improving performance","text":"<p>Once your implementation is functionally correct, your next goal is to optimize performance.</p> <p>Use the provided script:</p> <pre><code># run_all.sh &lt;run_label&gt;\n./run_all.sh first_version\n</code></pre> <p>Tip</p> <p>You should run the previous script with both the LUT and naive implementation of quantization to compare.</p> <p>Check the resulting plots in <code>./results/first_version/</code>. Take a look at <code>./results/first_version/pipeline.pipeline</code> to understand which operations are being evaluated. Re-run the benchmark after every meaningful optimization, and check <code>./results/comparisons.png</code> to see if you improved performance or not. Tip: play around with compilation flags.</p> <p>To remove a version, remove the corresponding folder in <code>./results</code></p> <p>Important</p> <p>You need to have python installed for <code>run_all.sh</code> to work. On Fedora: Installing python on fedora<pre><code>sudo dnf install python3 python3-pip python3-virtualenv\n</code></pre></p>"},{"location":"lab2/#5-summary","title":"5 - Summary","text":"<p>Upon completing this second lab, you should know how to:</p> <ul> <li> Create a makefile, link to a dynamic library.</li> <li> Explore compilation flags for performance</li> <li> Allocate and free memory in C.</li> <li> Explore the effect of memory layout and loop order on performance.</li> <li> Implement loop-based algorithms.</li> <li> Rearrange your algorithm to avoid costly operations.</li> <li> Understand the basics of the optimization loop.</li> </ul>"},{"location":"lab3/","title":"Lab 3: CMake, Unit Tests, and Debugging","text":""},{"location":"lab3/#objectives","title":"Objectives","text":"<ul> <li>Learn how to use CMake for building C projects.</li> <li>Write and run unit tests using the Unity testing framework.</li> <li>Use <code>valgrind</code> to detect memory-related issues and pinpoint invalid memory accesses.</li> <li>Learn how to use <code>gdb</code> to debug logical errors in C programs.</li> <li>Practice setting breakpoints, inspecting variables, and stepping through code in <code>gdb</code>.</li> </ul>"},{"location":"lab3/#provided-files","title":"Provided Files","text":"<p>This lab is a continuation of lab 2. The structure of the project is the same. A new transformation <code>rotate_image_90_clockwise</code>, which you will analyze in the third part of this lab, has been added to the <code>transformations.h</code> and <code>transformations.c</code> files.</p>"},{"location":"lab3/#1-cmake","title":"1 - CMake","text":"<p>In this first part, you will learn how to write a <code>CMakeLists.txt</code> file for a C project, starting from a provided <code>Makefile</code>. The goal is to progressively build a robust and maintainable CMake configuration for an HPC project.</p>"},{"location":"lab3/#1-minimal-build","title":"1. Minimal Build","text":"<p>Create a minimal <code>CMakeLists.txt</code> that builds the shared library <code>libparser.so</code> and the executable <code>mytransform</code>.</p>"},{"location":"lab3/#a-set-the-minimum-required-cmake-version-and-project-name","title":"a) Set the minimum required CMake version and project name","text":"CMakeLists.txt<pre><code>cmake_minimum_required(VERSION 3.15)\nproject(parser LANGUAGES C)\n</code></pre>"},{"location":"lab3/#b-add-include-directories","title":"b) Add include directories","text":"CMakeLists.txt<pre><code>include_directories(src include)\n</code></pre> <p>The <code>include_directories</code> command specifies the directories to search for header files during compilation. Here, <code>include</code> contains the public header of the parser library, and <code>src</code> contains the private headers used internally by the library and the executable.</p>"},{"location":"lab3/#c-add-the-shared-library-target","title":"c) Add the shared library target","text":"CMakeLists.txt<pre><code>add_library(parser SHARED src/parser.c)\n</code></pre> <p>In Linux a shared library has the extension <code>.so</code> (shared object). The <code>add_library</code> command creates a target named <code>parser</code> that builds a shared library from the source file <code>src/parser.c</code>. The final library will be named <code>libparser.so</code> by default.</p>"},{"location":"lab3/#d-add-the-executable-target","title":"d) Add the executable target","text":"CMakeLists.txt<pre><code>add_executable(mytransform src/main.c src/transformation.c src/image.c)\n</code></pre> <p>The <code>add_executable</code> command builds an executable <code>mytransform</code> from the specified source files. Header files were included before.</p>"},{"location":"lab3/#e-link-the-shared-library-to-the-executable","title":"e) Link the shared library to the executable","text":"<pre><code>target_link_libraries(mytransform PRIVATE parser m)\n</code></pre> <p>This command ensures that the <code>mytransform</code> executable is linked against the <code>parser</code> shared library and the math library <code>m</code>. </p> <p>Note</p> <p>The <code>PRIVATE</code> keyword indicates that the dependency is only required for building the <code>mytransform</code> target and does not propagate to other targets that may link against <code>mytransform</code>.</p>"},{"location":"lab3/#f-generate-the-build-system","title":"f) Generate the build system","text":"<pre><code>$ cmake -B build .\n</code></pre> <p>Here <code>-B</code> specifies the build directory (a new directory named <code>build</code>).</p>"},{"location":"lab3/#g-build-the-project","title":"g) Build the project","text":"<pre><code>$ make -C build/\n</code></pre> <p>Note</p> <p>By default, CMake generates a Makefile as the build system on Unix-like systems. Sometimes, it can be useful to call directly the <code>make</code> command to build the project. You can also use <code>cmake --build build</code> to build the project, which is more portable across different platforms and build systems.</p>"},{"location":"lab3/#h-answer-the-following-questions","title":"h) Answer the following questions","text":"<ul> <li>Where are the generated files located?</li> <li>Can you find the <code>libparser.so</code> library? the <code>mytransform</code> executable?</li> <li>Can you run the program? </li> </ul>"},{"location":"lab3/#2-build-configurations","title":"2. Build Configurations","text":"<p>We want to enable different build configurations (e.g., Debug, Release) and set appropriate compiler options.</p>"},{"location":"lab3/#a-configure-the-c-standard-used","title":"a) Configure the C standard used","text":"CMakeLists.txt<pre><code>set(CMAKE_C_STANDARD 11)\nset(CMAKE_C_STANDARD_REQUIRED ON)\n</code></pre> <p>This ensures that the C11 standard is used for compiling the project.</p>"},{"location":"lab3/#b-enable-different-build-types","title":"b) Enable different build types","text":"<p>Define common compiler flags for different build types:</p> CMakeLists.txt<pre><code>set(COMMON_COMPILE_FLAGS\n    $&lt;$&lt;CONFIG:Debug&gt;:-Wall -Wextra -g&gt;\n    $&lt;$&lt;CONFIG:Release&gt;:-Wall -Wextra -O3 -DNDEBUG&gt;\n)\n</code></pre> <p>Apply the flags to the targets:</p> CMakeLists.txt<pre><code>target_compile_options(parser PRIVATE ${COMMON_COMPILE_FLAGS})\ntarget_compile_options(mytransform PRIVATE ${COMMON_COMPILE_FLAGS})\n</code></pre> <p>Rebuild the project and test different configurations:</p> <pre><code>$ cmake -B build -DCMAKE_BUILD_TYPE=Debug .\n</code></pre> <p>You can check that the debug symbols are included in the binary using <code>file</code>:</p> <pre><code>$ file build/mytransform \nbuild/mytransform: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=0d2cbaa0cf08a42b916e2edffe9940ce828b2bd9, for GNU/Linux 3.2.0, with debug_info, not stripped\n</code></pre>"},{"location":"lab3/#3-enable-installation","title":"3. Enable Installation","text":"<p>Now we will add installation rules to install the shared library, executable, and headers.</p>"},{"location":"lab3/#a-give-your-project-a-version-number","title":"a) Give your project a version number","text":"<p>Modify the <code>project</code> command as below:</p> CMakeLists.txt<pre><code>project(parser VERSION 1.0.0 LANGUAGES C)\n</code></pre>"},{"location":"lab3/#b-include-the-gnuinstalldirs-module","title":"b) Include the <code>GNUInstallDirs</code> module","text":"CMakeLists.txt<pre><code>include(GNUInstallDirs)\n</code></pre> <p>This module provides standard installation directory variables like <code>CMAKE_INSTALL_BINDIR</code>, <code>CMAKE_INSTALL_LIBDIR</code>, and <code>CMAKE_INSTALL_INCLUDEDIR</code>.</p>"},{"location":"lab3/#c-add-installation-rules-for-the-shared-library","title":"c) Add installation rules for the shared library","text":"CMakeLists.txt<pre><code>install(TARGETS parser\n    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n    PUBLIC_HEADER DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}\n)\n</code></pre>"},{"location":"lab3/#d-add-installation-rules-for-the-executable","title":"d) Add installation rules for the executable","text":"CMakeLists.txt<pre><code>install(TARGETS mytransform\n    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n)\n</code></pre>"},{"location":"lab3/#e-test-the-installation","title":"e) Test the installation","text":"<pre><code>mkdir install_dir\n$ cmake -B build -DCMAKE_INSTALL_PREFIX=install_dir . \n$ make -C build/ install\n</code></pre> <p>Since <code>install_dir</code> is not a standard system directory, you need to set the <code>LD_LIBRARY_PATH</code> environment variable to include the path to the installed shared library before running the program.</p> <p>Note</p> <p>We can also call <code>cmake --install build --prefix &lt;install_directory&gt;</code> to install the project.</p>"},{"location":"lab3/#f-install-the-public-header-file","title":"f) Install the public header file","text":"<p>As you can see, the public header file <code>parser.h</code> is not installed. To inform CMake about the public headers, you should add the following command:</p> CMakeLists.txt<pre><code>set_target_properties(parser PROPERTIES\n    VERSION ${PROJECT_VERSION}\n    SOVERSION ${PROJECT_VERSION_MAJOR}\n    PUBLIC_HEADER include/parser.h\n)\n</code></pre> <p>Rebuild and install the project again, you should see the <code>parser.h</code> file in the <code>include</code> directory of the installation prefix. Additionally, the shared library should now have a versioned name like <code>libparser.so.1.0.0</code>.</p>"},{"location":"lab3/#3-better-handling-of-include-directories","title":"3. Better handling of include directories","text":"<p>Our current way of handling include directories is not ideal. We will improve it by using <code>target_include_directories</code> which keeps the include directories scoped to each target.</p>"},{"location":"lab3/#a-remove-the-global-include_directories-command","title":"a) Remove the global <code>include_directories</code> command","text":""},{"location":"lab3/#b-add-the-following-commands-to-specify-include-directories-for-each-target","title":"b) Add the following commands to specify include directories for each target","text":"CMakeLists.txt<pre><code>target_include_directories(parser \n    PUBLIC \n        $&lt;BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include&gt;\n        $&lt;INSTALL_INTERFACE:include&gt;\n    PRIVATE\n        ${PROJECT_SOURCE_DIR}/src\n    )\n\ntarget_include_directories(mytransform PRIVATE ${PROJECT_SOURCE_DIR}/src)\n</code></pre> <p>The library target disinguishes between <code>PUBLIC</code> and <code>PRIVATE</code> include directories. <code>PUBLIC</code> directories are needed both when building the library and when using it, while <code>PRIVATE</code> directories are only needed when building the library itself.</p> <p>The <code>BUILD_INTERFACE</code> generator expression specifies the include directory to use when building the project, while the <code>INSTALL_INTERFACE</code> generator expression specifies the include directory to use when the library is installed. This ensures that users of the installed library can include the header files correctly.</p>"},{"location":"lab3/#2-unit-tests","title":"2 - Unit Tests","text":"<p>In this part, you will learn how to integrate unit tests into your CMake project using the Unity testing framework.</p>"},{"location":"lab3/#1-fetch-the-unity-framework","title":"1. Fetch the Unity framework","text":"<p>Fetch the Unity framework:</p> CMakeLists.txt<pre><code># Fetch and build the Unity testing framework\ninclude(FetchContent)\nFetchContent_Declare(\n    unity\n    GIT_REPOSITORY  https://github.com/ThrowTheSwitch/Unity.git\n    GIT_TAG         v2.6.1\n    GIT_SHALLOW TRUE # Only download the specific tag, not full history\n)\n\n# Make Unity available but don't add to ALL target by default\n# This is important to avoid installing unity dependencies which are only needed for testing \n# but are not required in the release version of the project\nFetchContent_GetProperties(unity)\nif(NOT unity_POPULATED)\n    FetchContent_Populate(unity)\n    add_subdirectory(${unity_SOURCE_DIR} ${unity_BINARY_DIR} EXCLUDE_FROM_ALL)\nendif()\n</code></pre> <p>CMake fetches and builds the Unity framework, making it available for use in your project.</p>"},{"location":"lab3/#2-write-a-first-unit-test","title":"2. Write a first unit test","text":"<p>We currently have a set of hard-coded tests in <code>main.c</code>:</p> <ul> <li><code>check_grayscale</code></li> <li><code>check_rgb</code> </li> <li><code>check_copy</code></li> </ul> <p>Read carefully these tests to understand what they do.</p> <p>To convert them into unit tests, we will create a new source file <code>tests/test_image.c</code> and move the test functions there. The <code>check_memory</code> function which ran all the files will be replaced by a test runner in <code>tests/test_runner.c</code>.</p> <p>We will start first by writing the test runner. Create a new file <code>tests/test_runner.c</code> with the following content:</p> tests/test_runner.c<pre><code>#include \"unity.h\"\n\nextern void test_grayscale_image_creation(void);\n\nvoid setUp(void) {}\nvoid tearDown(void) {}\n\nint main(void)\n{\n    UNITY_BEGIN();\n    RUN_TEST(test_grayscale_image_creation);\n    return UNITY_END();\n}\n</code></pre> <p>Note</p> <p>The <code>setUp</code> and <code>tearDown</code> functions are called before and after each test, respectively. They can be used to set up and clean up test fixtures if needed.</p> <p>Now create the <code>tests/test_image.c</code> file and move the <code>check_grayscale</code> function there, renaming it to <code>test_grayscale_image_creation</code>:</p> tests/test_image.c<pre><code>#include \"unity.h\"\n#include \"transformation.h\"\n#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;time.h&gt;\n\nvoid test_grayscale_image_creation(void)\n{\n    Image *img = create_image(100, 100, 1);\n    TEST_ASSERT_NOT_NULL(img);\n    TEST_ASSERT_EQUAL(100, img-&gt;width);\n    TEST_ASSERT_EQUAL(100, img-&gt;height);\n    TEST_ASSERT_EQUAL(1, img-&gt;channels);\n    TEST_ASSERT_NOT_NULL(img-&gt;pixels[0]);\n    TEST_ASSERT_NULL(img-&gt;pixels[1]);\n    TEST_ASSERT_NULL(img-&gt;pixels[2]);\n    free_image(img);\n}\n</code></pre> <p>As you can see, we are using systematically the Unity assertion macros to check conditions.</p>"},{"location":"lab3/#3-add-the-test-runner-executable","title":"3. Add the test runner executable","text":"<p>To run our tests, we need to create a new executable target for the test runner in our <code>CMakeLists.txt</code> file.</p> CMakeLists.txt<pre><code>add_executable(test_runner tests/test_runner.c tests/test_image.c src/transformation.c src/image.c)\ntarget_include_directories(test_runner \n    PRIVATE \n        ${PROJECT_SOURCE_DIR}/src\n)\ntarget_link_libraries(test_runner unity m parser)\n</code></pre> <p>Observe that we link the <code>test_runner</code> target against the <code>unity</code> library, the math library <code>m</code>, and our <code>parser</code> library.</p>"},{"location":"lab3/#4-add-a-custom-target-to-run-the-tests","title":"4. Add a custom target to run the tests","text":"<p>To facilitate running the tests, we can add a custom target in our <code>CMakeLists.txt</code> file that will execute the <code>test_runner</code> executable.</p> CMakeLists.txt<pre><code>add_custom_target(test test_runner \n    DEPENDS $&lt;TARGET_FILE:test_runner&gt;\n    WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR}\n    COMMENT \"Running unit tests...\"\n)\n</code></pre> <p>Check that everything works by building the project and running the tests:</p> <pre><code>$ cmake --build build\n$ make -C build test\n</code></pre>"},{"location":"lab3/#5-add-the-remaining-tests","title":"5. Add the remaining tests","text":"<p>Write unit tests for the <code>check_rgb</code> and <code>check_copy</code> functions in the <code>tests/test_image.c</code> file. </p> <p>Tip</p> <p>For bonus point, separate the logic of the <code>check_copy</code> test into two different tests: <code>test_image_copy</code>, that check the code validity, and <code>test_image_copy_performance</code> that measures and displays the performance.</p>"},{"location":"lab3/#3-debugging-with-gdb-and-valgrind","title":"3 - Debugging with GDB and Valgrind","text":"<p>In this last part, you will learn how to debug two types of bugs in a C program using <code>gdb</code> and <code>valgrind</code>. These bugs are intentionally introduced in the <code>rotate_image_90_clockwise</code> function. The goal is to identify, understand, and fix these bugs while reflecting on the debugging process.</p>"},{"location":"lab3/#1-build-the-program-with-debug-symbols","title":"1. Build the Program with Debug Symbols","text":"<p>Debugging symbols are metadata embedded in a program's binary during compilation, providing detailed information about the source code, such as variable names, function names, and line numbers. These symbols allow tools like gdb and valgrind to map the program's execution back to the original source code, making it easier to inspect variables, set breakpoints, and trace errors. Without debugging symbols, these tools would only display raw memory addresses and machine-level details, making debugging significantly harder.</p> <p>Note</p> <p>To enable debugging symbols, you need to configure CMake to include the <code>-g</code> flag in the compilation process. This can be achieved by setting the <code>CMAKE_BUILD_TYPE</code> to <code>Debug</code>.</p>"},{"location":"lab3/#a-run-the-cmake-command-with-the-debug-build-type","title":"a) Run the <code>cmake</code> command with the <code>Debug</code> build type","text":"<pre><code>$ cmake -B build/ -DCMAKE_BUILD_TYPE=Debug .\n</code></pre>"},{"location":"lab3/#b-build-the-project","title":"b) Build the project","text":"<pre><code>$ make -C build/\n</code></pre>"},{"location":"lab3/#c-run-the-program-using-the-rotate-transformation","title":"c) Run the program using the rotate transformation","text":"<pre><code>$ build/mytransform pipelines/rotate.pipeline\nLoaded image: images/image0.bmp (259x194, 3 channels)\nSegmentation fault (core dumped)\n</code></pre> <p>You should get an error as above.</p>"},{"location":"lab3/#d-analyze-carefully-the-error-message","title":"d) Analyze carefully the error message","text":"<ul> <li>What does <code>Segmentation fault</code> mean?</li> <li>What does <code>(core dumped)</code> mean?</li> <li>What could be the possible causes of this error?</li> </ul>"},{"location":"lab3/#2-running-the-program-with-gdb","title":"2. Running the program with GDB","text":"<p>GDB is the GNU Project Debugger, a powerful tool for debugging programs. It allows you to run your program step by step, inspect variables, set breakpoints, and analyze the program's flow to identify and fix bugs.</p>"},{"location":"lab3/#a-start-gdb-with-the-program-and-its-arguments","title":"a) Start gdb with the program and its arguments","text":"<pre><code>$ gdb --args build/mytransform pipelines/rotate.pipeline\n\nGNU gdb (Ubuntu 15.0.50.20240403-0ubuntu1) 15.0.50.20240403-git\n... [output truncated] ...\n(gdb)\n</code></pre> <p>Note</p> <p>The <code>--args</code> option allows you to pass the program's arguments directly to gdb, so you don't have to type them again after starting gdb. <code>(gdb)</code> is the gdb prompt, where you can enter gdb commands.</p>"},{"location":"lab3/#b-run-the-program-inside-gdb","title":"b) Run the program inside gdb","text":"<pre><code>(gdb) run\nStarting program: lab3/build/mytransform pipelines/rotate.pipeline\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nLoaded image: images/image0.bmp (259x194, 3 channels)\n\nProgram received signal SIGSEGV, Segmentation fault.\nrotate_image_90_clockwise (node=0x5555555802f0)\n    at lab3/src/transformation.c:105\n105 node-&gt;output-&gt;pixels[c][x * width + (height - y - 1)] = node-&gt;input-&gt;pixels[c][y * width + x];\n</code></pre> <p>GDB has caught the segmentation fault and shows you the exact line where the error occurred.</p>"},{"location":"lab3/#c-backtrace-the-function-calls","title":"c) Backtrace the function calls","text":"<p>You can use the <code>backtrace</code> command to see the function call stack leading to the crash:</p> <pre><code>(gdb) backtrace\n#0  rotate_image_90_clockwise (node=0x5555555802f0)\n    at lab3/src/transformation.c:105\n#1  0x0000555555577885 in execute_node (node=0x5555555802f0)\n    at lab3/src/transformation.c:222\n#2  0x00007ffff7fb9c7f in execute_graph (graph=0x5555555802a0)\n    at lab3/src/parser.c:174\n#3  0x0000555555555e4a in main (argc=2, argv=0x7fffffffdae8)\n    at lab3/src/main.c:165\n</code></pre> <p>Here everything appears normal.</p> <p>Note</p> <p>It's possible to change the frame using <code>up</code> and <code>down</code> commands to navigate through the call stack and inspect their variables.</p>"},{"location":"lab3/#d-inspect-the-variables","title":"d) Inspect the variables","text":"<p>You can inspect the values of variables at the point of the crash. For example, to check the values of <code>x</code>, <code>y</code>, <code>c</code>, <code>width</code>, and <code>height</code>, you can use the <code>print</code> command:</p> <pre><code>(gdb) print x \n$1 = 0\n</code></pre> <p>Print each of the variables, do you see anything suspicious at the point of crash?</p>"},{"location":"lab3/#e-fix-and-explain-the-first-bug","title":"e) Fix and explain the first bug","text":"<p>Tip</p> <p>The first bug is a logical error in the loop exit condition at line 109.</p> <p>Once you have identified and understood the first bug, you can fix it directly in the source code. Commit the fix to git and explain the bug and how you fixed it in the commit message.</p> <p>Unfortunately, there is still a second bug that we will fix in the next section.</p>"},{"location":"lab3/#3-using-valgrind-to-detect-memory-issues","title":"3. Using Valgrind to Detect Memory Issues","text":""},{"location":"lab3/#a-run-the-program-with-gdb-again","title":"a) Run the program with GDB again","text":"<pre><code>(gdb) run\nStarting program: lab3/build/mytransform pipelines/rotate.pipeline\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\nLoaded image: images/image0.bmp (259x194, 3 channels)\nmalloc(): corrupted top size\n\nProgram received signal SIGABRT, Aborted.\n__pthread_kill_implementation (no_tid=0, signo=6, threadid=&lt;optimized out&gt;)\n    at ./nptl/pthread_kill.c:44\nwarning: 44 ./nptl/pthread_kill.c: No such file or directory\n(gdb) backtrace\n#0  __pthread_kill_implementation (no_tid=0, signo=6, threadid=&lt;optimized out&gt;)\n    at ./nptl/pthread_kill.c:44\n#1  __pthread_kill_internal (signo=6, threadid=&lt;optimized out&gt;) at ./nptl/pthread_kill.c:78\n#2  __GI___pthread_kill (threadid=&lt;optimized out&gt;, signo=signo@entry=6)\n    at ./nptl/pthread_kill.c:89\n#3  0x00007ffff7c4527e in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26\n#4  0x00007ffff7c288ff in __GI_abort () at ./stdlib/abort.c:79\n#5  0x00007ffff7c297b6 in __libc_message_impl (fmt=fmt@entry=0x7ffff7dce8d7 \"%s\\n\")\n    at ../sysdeps/posix/libc_fatal.c:134\n#6  0x00007ffff7ca8ff5 in malloc_printerr (\n    str=str@entry=0x7ffff7dcc6f7 \"malloc(): corrupted top size\") at ./malloc/malloc.c:5772\n#7  0x00007ffff7cac2fc in _int_malloc (av=av@entry=0x7ffff7e03ac0 &lt;main_arena&gt;, bytes=150738)\n    at ./malloc/malloc.c:4447\n#8  0x00007ffff7cad7f2 in __GI___libc_malloc (bytes=&lt;optimized out&gt;)\n    at ./malloc/malloc.c:3328\n#9  0x0000555555576fd3 in save_image (node=0x555555580320)\n    at lab3/src/transformation.c:70\n#10 0x0)\n    at lab3/src/transformation.c:225\n#11 0x0a0)\n    at lab3/src/parser.c:174\n#12 0x0)\n    at lab3/src/main.c:165\n</code></pre> <p>The program crashes again, but this time with a different error message: <code>malloc(): corrupted top size</code>. This indicates a memory corruption issue.</p> <p>The backtrace does not point to the exact line in your code where the corruption occurred. Why?</p>"},{"location":"lab3/#b-use-valgrind-to-pinpoint-the-memory-issue","title":"b) Use Valgrind to pinpoint the memory issue","text":"<p>Valgrind is a programming tool for memory debugging, memory leak detection, and profiling. It can help you identify memory-related issues in your program, such as invalid memory accesses, memory leaks, and uninitialized memory usage.</p> <pre><code>valgrind build/mytransform pipelines/rotate.pipeline\n\n==241843== Memcheck, a memory error detector\n==241843== Copyright (C) 2002-2022, and GNU GPL'd, by Julian Seward et al.\n==241843== Using Valgrind-3.22.0 and LibVEX; rerun with -h for copyright info\n==241843== Command: build/mytransform pipelines/rotate.pipeline\n==241843== \nLoaded image: images/image0.bmp (259x194, 3 channels)\n==241843== Invalid write of size 1\n==241843==    at 0x12B188: rotate_image_90_clockwise (transformation.c:105)\n==241843==    by 0x12B87D: execute_node (transformation.c:222)\n==241843==    by 0x485BC7E: execute_graph (parser.c:174)\n==241843==    by 0x109E49: main (main.c:165)\n==241843==  Address 0x4bf26f7 is 119 bytes inside an unallocated block of size 3,729,760 in arena \"client\"\n... [output truncated] ...\n</code></pre> <p>How does Valgrind work? Why is it able to provide more detailed information about memory issues than gdb?</p> <p>Here valgrind provides a detailed report of the memory error, including the exact line in your code where the invalid write occurred. Now we will use gdb again to inspect the variables at the point of the invalid write.</p>"},{"location":"lab3/#c-set-a-breakpoint-at-the-faulty-line","title":"c) Set a breakpoint at the faulty line","text":"<pre><code>(gdb) break transformation.c:105\n(gdb) run\n... [output truncated] ...\nBreakpoint 1, rotate_image_90_clockwise (node=0x5555555802f0)\n    at lab3/src/transformation.c:105\n105 node-&gt;output-&gt;pixels[c][x * width + (height - y - 1)] = node-&gt;input-&gt;pixels[c][y * width + x];\n(gdb) \n</code></pre> <p>Observe that gdb stops at the breakpoint you set and allows inspecting the point of the invalid write.</p>"},{"location":"lab3/#d-inspect-the-values-of-x-y-width-height-and-the-computed-index","title":"d) Inspect the values of <code>x</code>, <code>y</code>, <code>width</code>, <code>height</code>, and the computed index:","text":"<p><pre><code>print x\nprint y\nprint width\nprint height\nprint x * width + (height - y - 1)\n</code></pre> GDB allows you to perform arithmetic operations directly in the <code>print</code> command, so you can compute the index and check if it is within bounds. Do you see anything suspicious?</p>"},{"location":"lab3/#e-set-a-conditional-breakpoint","title":"e) Set a conditional breakpoint","text":"<p>We start to suspect that the index calculation is incorrect. To catch the invalid memory write, set a conditional breakpoint that triggers when the computed index is out of bounds. Start gdb again and run the following commands:</p> <pre><code>(gdb) break transformation.c:105\n(gdb) condition 1 x * width + (height - y - 1) &gt;= height * width\n</code></pre> <p><code>condition</code> 1 sets a condition on breakpoint 1, so it only triggers when the condition is true. The condition will trigger when the computed index is greater than or equal to the total number of pixels in the image, which indicates an out-of-bounds access.</p> <p>Run the program again, do you hit the breakpoint?</p>"},{"location":"lab3/#f-analyze-and-fix-the-bug","title":"f) Analyze and fix the bug","text":"<p>Tip</p> <p>Check carefully that the dimensions used in the index calculation are correct. The bug is a mix-up between <code>width</code> and <code>height</code>.</p> <p>As before once you have identified and understood the second bug, you can fix it directly in the source code. Commit the fix to git and explain the bug and how you fixed it in the commit message.</p> <p>Check that the program runs correctly now!</p>"},{"location":"lab3/#4-non-regression-tests","title":"4. Non-regression tests","text":"<p>Now that you have fixed both bugs, it's important to ensure that the bugs will not reappear in the future. To do this, you will write non-regression tests using the Unity testing framework.</p> <p>Add tests that specifically target the scenarios that led to the bugs you fixed. For example, you can create tests that rotate images of various sizes and shapes, including non-square images, to ensure that the <code>rotate_image_90_clockwise</code> function behaves correctly.</p>"},{"location":"lab3/#5-gcov-llvm-cov-optional","title":"5. GCov / llvm-cov (Optional)","text":"<p>GCov analyzes and reports on the code coverage of your tests. It helps you identify which parts of your code are being executed during testing and which parts are not, allowing you to improve your test suite.</p> <p>GCov (or its variant llvm-cov for LLVM/Clang) works by instrumenting your code during compilation to collect coverage data. </p> <p>To use GCov with CMake, you need to enable coverage flags during the build process. When compiling with GCC, you can use the <code>--coverage -O0 -g</code> flags, and link with <code>--coverage</code> flag.</p> <p>Fortunately, CMake provides a convenient way to set these flags using the CodeCoverage module. Retrieve the module cmake file:</p> <pre><code>$ mkdir CMakeModules &amp;&amp; cd CMakeModules\n$ wget https://github.com/bilke/cmake-modules/raw/refs/heads/master/CodeCoverage.cmake\n</code></pre> <p>Then, include the module in your <code>CMakeLists.txt</code> file and add the coverage flags to the test target:</p> CMakeLists.txt<pre><code>set(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/CMakeModules)\ninclude(CodeCoverage)\n\n... [truncated] ...\n\nappend_coverage_compiler_flags_to_target(test_runner)\n</code></pre> <p>Then, you can build your project with the <code>Debug</code> build type:</p> <pre><code>$ cmake -B build -DCMAKE_BUILD_TYPE=Debug .\n$ make -C build/ test \n</code></pre> <p>You should see files with the <code>.gcda</code> extension generated in the build directory. These files contain the coverage data collected during the execution of your tests.</p> <p>Finally, you can generate the coverage report using the <code>gcovr</code> command:</p> <pre><code>$ gcovr -r .\n</code></pre> <p>This will generate a coverage report for the <code>transformation.c</code> file, showing which lines of code were executed during the tests.</p> <p>Tip</p> <p>You can also generate an HTML report using the <code>--html</code> option:</p> <pre><code>$ gcovr -r . --html --html-details -o coverage_report.html\n</code></pre> <p>This will create a detailed HTML report that you can open in a web browser.</p> <p>What is the percentage of code coverage achieved by your tests? Are there any parts of the code that are not covered by the tests? If so, consider adding more tests to cover those areas.</p>"},{"location":"lab3/#4-summary","title":"4 - Summary","text":"<p>Upon completing this third lab, you should know how to:</p> <ul> <li> Use CMake to build and install a shared library and an executable.</li> <li> Configure CMake for different build types and compiler options.</li> <li> Integrate and run unit tests using the Unity testing framework.</li> <li> Debug segmentation faults and memory issues using GDB and Valgrind.</li> <li> Write non-regression tests to prevent reintroducing fixed bugs.</li> </ul>"},{"location":"lab4/","title":"Lab 4: Monte-Carlo Sampling","text":"<p>Monte-Carlo methods are useful for approximating quantities that are difficult or computationally expensive to determine analytically or through deterministic algorithms. These methods introduce randomness into the computations in order to obtain a statistically meaningful estimate over multiple repetitions of the same routine.</p> <p>In this lab, we explore the approximation of \u03c0 using Monte-Carlo sampling. To do this, we consider a unit circle (radius 1) inscribed within a square of side length 2, centered at the origin. By generating random points uniformly within the square and counting how many fall inside the circle, we can estimate the ratio of the areas of the two shapes. </p> <p>Since the area of the circle is \\(\\pi \\cdot r^2 = \\pi\\), and the area of the square is 4, we expect the ratio of points falling inside the circle to converge to \\(\\pi / 4\\).</p> Monte-Carlo Pi"},{"location":"lab4/#1-implementing-the-mc-method","title":"1 - Implementing the MC Method","text":"<p>Implement your own version of the \\(\\pi\\) estimator inside <code>src/compute_pi.c</code> using the Monte-Carlo method. This method receives \\(n\\) the number of Monte-Carlo samples to take as arguments, and must return the approximation of \\(\\pi\\) in <code>double</code> precision.</p> <p>Build your program using <code>make</code> and validate your implementation. The program can be run using: Run the estimator<pre><code># piestimator &lt;nsamples&gt;\npiestimator 1000000\n</code></pre></p>"},{"location":"lab4/#2-timing-and-serialization","title":"2 - Timing and serialization","text":""},{"location":"lab4/#1-implementing-timing","title":"1. Implementing timing","text":""},{"location":"lab4/#a-modify-the-function-srcmaincmc_harness-to-measure-the-execution-time-of-your-method","title":"a) Modify the function <code>src/main.c:mc_harness(...)</code> to measure the execution time of your method.","text":"<p>You must repeat the measurements <code>nmeta</code> times, and record the values of Pi as well as the execution time for every execution.</p> <p>What function did you use to measure time ? How accurate is it ? Is it monotonic ?</p>"},{"location":"lab4/#b-modify-the-function-srcmaincprint_results-to-print-a-table-with-the-following-values","title":"b) Modify the function <code>src/main.c:print_results(...)</code> to print a table with the following values:","text":"Avg. Pi Std Pi Avg. Time Std Time Min Time Max Time Average Value of Pi Standard Deviation of Pi Average execution time Standard Deviation of execution time Min execution time Max Execution time <p>You may need to modify other functions or the provided structure(s) to achieve this.</p>"},{"location":"lab4/#c-implement-csv-serialization-inside-the-program","title":"c) Implement csv serialization inside the program.","text":"<p>You must exactly match this format and header:</p> output.csv<pre><code>NMeta,Pi,Time\n1,3.145584,0.025\n2,3.13547,0.028\n</code></pre> <p>Print at least 10 decimals, and ensure that the file is saved in the path provided by the user.</p> <p>Check that you can run the following: Expected API<pre><code># Run MC Pi Estimator with 1 Million sample, 2048 meta-repetitions and save the results in results.csv\n./piestimator 1000000 2048 results.csv\n</code></pre></p> <p>Warning</p> <p>The following questions will reuse this CSV serialization. Be sure that you match exactly the prescribed format. Be careful not to introduce blank spaces in the header name (e.g. <code>NMeta,Pi,Time</code> rather than <code>NMeta,   Pi,   Time</code>)</p>"},{"location":"lab4/#2-run-the-provided-experiments","title":"2. Run the provided experiments","text":"<p>If you correctly implemented csv serialization, this will generate plots inside the <code>results</code> folder.</p> First sequential run<pre><code># ./run_all.sh &lt;run_label&gt;\n./run_all.sh sequential\n</code></pre>"},{"location":"lab4/#a-first-look-at-the-top-figure-in-convergencepng","title":"a) First, look at the top figure in <code>convergence.png</code>","text":"<p>How do you observe ? How does the error evolve when increasing the number of Monte-Carlo samples ? If needed, fix your program so that the relative error converges towards zero.</p>"},{"location":"lab4/#b-look-at-the-bottom-figure-how-does-execution-time-evolve-when-increasing-the-number-of-samples","title":"b) Look at the bottom figure: how does execution time evolve when increasing the number of samples ?","text":"<p>If needed, fix your program so that the execution time scales linearly with the number of samples.</p>"},{"location":"lab4/#c-look-at-the-top-figure-in-stabilitypng","title":"c) Look at the top figure in <code>stability.png</code>","text":"<p>How are the values of the Pi estimations distributed ? Is there any bias, and if yes, why ? If needed, fix your program so that the Pi estimations are normally distributed around 3.14.</p>"},{"location":"lab4/#d-look-at-the-bottom-figure-how-is-the-execution-time-distributed","title":"d) Look at the bottom figure: how is the execution time distributed ?","text":"<p>Check whether the timings are stable, and if not, propose an explanation. Do you observe any measurement noise ? How would you qualify it ?  </p> <p>If needed, fix your measurements so that the execution time is mostly normally distributed, and the measurement noise is tolerable.</p> <p>Tip</p> <p>The <code>results/expected_results</code> folder contains examples of plots that were run on a stable machine, with a correct implementation of the Monte-Carlo estimator.</p>"},{"location":"lab4/#25-going-further-understanding-the-scripts","title":"2.5 -  (Going-Further) Understanding the scripts","text":""},{"location":"lab4/#1-look-at-run_allsh-and-try-to-understand-each-line","title":"1. Look at <code>run_all.sh</code>, and try to understand each line.","text":""},{"location":"lab4/#a-what-does-set-e-set-o-pipefail-and-21-tee-do","title":"a) What does <code>set -e</code>, <code>set -o pipefail</code> and <code>2&gt;&amp;1 | tee ...</code> do ?","text":""},{"location":"lab4/#b-what-is-the-purpose-of-the-run_label-argument-why-should-we-label-our-data","title":"b) What is the purpose of the <code>run_label</code> argument (Why should we label our data) ?","text":"<p>What files are generated, and what's the purpose of every one of them ?</p>"},{"location":"lab4/#2-look-at-scriptsanalysepy-and-try-to-understand-how-each-plot-is-built","title":"2. Look at <code>scripts/analyse.py</code> and try to understand how each plot is built.","text":"<p>Try to link every components of <code>convergence.png</code> and <code>stability.png</code> (The titles, the axis label, the axis ticks, the distributions, the grid, ...) with the code that generates it.</p>"},{"location":"lab4/#3-optimization","title":"3 - Optimization","text":""},{"location":"lab4/#1-setting-up-makefile","title":"1) Setting up Makefile","text":""},{"location":"lab4/#a-modify-the-makefile-and-play-around-with-compilation-flags-and-different-compilers","title":"a) Modify the <code>makefile</code> and play around with compilation flags and different compilers.","text":"<p>Remember that you can run <code>run_all.sh &lt;run_label&gt;</code> to compare the different runs later.  </p> <p>What configuration gives you the fastest execution time ? Can you understand why ?</p>"},{"location":"lab4/#2-use-openmp-to-parallelize-your-monte-carlo-algorithm","title":"2. Use OpenMP to parallelize your Monte-Carlo algorithm.","text":"<p>You may need to modify the <code>makefile</code> to link to OpenMP.  </p>"},{"location":"lab4/#a-how-are-you-generating-random-numbers-in-the-sampling-algorithm","title":"a) How are you generating random numbers in the sampling algorithm?","text":"<ul> <li>Read the fourth paragraph in the description section of the <code>rand</code>/<code>srand</code> man page using <code>man 3 srand</code> or the online version.</li> <li>If necessary, research thread-safe alternatives.</li> </ul>"},{"location":"lab4/#b-where-did-you-implement-parallelization","title":"b) Where did you implement parallelization?","text":"<ul> <li>Are you averaging multiple Pi values from separate runs, or</li> <li>Are you summing the counts of points inside the circle across threads?<ul> <li>Does each thread accumulate its count in a private variable?</li> <li>If you accumulate in a shared variable, do you protect it using mutexes, locks, or OpenMP critical sections?</li> </ul> </li> </ul>"},{"location":"lab4/#c-do-you-see-any-performans-gains-compared-to-the-sequential-version","title":"c) Do you see any performans gains compared to the sequential version ?","text":""},{"location":"lab4/#d-rerun-the-provided-experiments-and-compare-with-your-previous-sequential-result","title":"d) Rerun the provided experiments, and compare with your previous sequential result.","text":"Running the experiment(s)<pre><code>./run_all.sh parallel\n</code></pre> <p>Is your program faster using OpenMP ? If not, ensure you are correctly running multiple threads.</p>"},{"location":"lab4/#e-is-the-performance-stable-is-there-any-impact-on-the-accuracy-of-your-estimator","title":"e) Is the performance stable? Is there any impact on the accuracy of your estimator?","text":"<p>If performance is unstable, investigate thread affinity and how to bind threads to specific cores.</p> <p>On Intel CPUs, check if your processor has Performance (P) and Efficiency (E) cores, as this can affect timing consistency.</p> Checking your CPU Model Name<pre><code>lscpu | grep \"Model name\"\n</code></pre>"},{"location":"lab4/#e-bonus-for-students-with-an-heterogeneous-cpu-efficiency-e-cores-and-performance-p-coress","title":"e - Bonus) For students with an heterogeneous CPU (Efficiency (E) Cores and Performance (P) Coress)","text":"<p>Using both E and P cores can introduce instabilities in your measurements, load balancing issues, and should be avoided. Run the following to check your CPU topology: Checking CPU Topology<pre><code>lscpu --all --extended\n\n# CPU NODE SOCKET CORE L1d:L1i:L2:L3 ONLINE    MAXMHZ   MINMHZ       MHZ\n#   0    0      0    0 0:0:0:0          yes 5100.0000 800.0000  800.0000\n#   1    0      0    0 0:0:0:0          yes 5100.0000 800.0000  800.0000\n#   2    0      0    1 4:4:1:0          yes 5100.0000 800.0000  800.0000\n#   3    0      0    1 4:4:1:0          yes 5100.0000 800.0000  800.0000\n#   4    0      0    2 8:8:2:0          yes 5100.0000 800.0000  800.0000\n#   5    0      0    2 8:8:2:0          yes 5100.0000 800.0000  800.0000\n#   6    0      0    3 12:12:3:0        yes 5100.0000 800.0000  800.0000\n#   7    0      0    3 12:12:3:0        yes 5100.0000 800.0000  800.0000\n#   8    0      0    4 16:16:4:0        yes 5300.0000 800.0000  843.1520\n#   9    0      0    4 16:16:4:0        yes 5300.0000 800.0000  800.0000\n#  10    0      0    5 20:20:5:0        yes 5300.0000 800.0000 2329.4590\n#  11    0      0    5 20:20:5:0        yes 5300.0000 800.0000  800.0000\n#  12    0      0    6 24:24:6:0        yes 5100.0000 800.0000  800.0000\n#  13    0      0    6 24:24:6:0        yes 5100.0000 800.0000  800.0000\n#  14    0      0    7 28:28:7:0        yes 5100.0000 800.0000  800.0000\n#  15    0      0    7 28:28:7:0        yes 5100.0000 800.0000  800.0000\n#  16    0      0    8 32:32:8:0        yes 3800.0000 800.0000  800.0000\n#  17    0      0    9 33:33:8:0        yes 3800.0000 800.0000  842.6700\n#  18    0      0   10 34:34:8:0        yes 3800.0000 800.0000  799.7680\n#  19    0      0   11 35:35:8:0        yes 3800.0000 800.0000  800.0000\n#  20    0      0   12 40:40:10:0       yes 3800.0000 800.0000  800.0000\n#  21    0      0   13 41:41:10:0       yes 3800.0000 800.0000  800.0000\n#  22    0      0   14 42:42:10:0       yes 3800.0000 800.0000  800.0000\n#  23    0      0   15 43:43:10:0       yes 3800.0000 800.0000  800.0000\n#  24    0      0   16 44:44:11:0       yes 3800.0000 800.0000  799.0440\n#  25    0      0   17 45:45:11:0       yes 3800.0000 800.0000  800.0000\n#  26    0      0   18 46:46:11:0       yes 3800.0000 800.0000  800.0000\n#  27    0      0   19 47:47:11:0       yes 3800.0000 800.0000  800.0000\n</code></pre></p> <p>You should be able to see that some cores have a higher Max Frequency (MAXMHZ) than other: those are typically performance cores. If you have hyperthreading enabled, you should also see that some cores share the same \"core id\": classically, only performance cores have hyperthreading enabled. From the previous output, we can deduce that cores 0-15 are P-cores and that hyperthreading is enabled. As such, we can run the following command to change the thread affinity of our shell to only use physical cores:</p> Restricting Thread Affinity<pre><code># Adjust the core list based on your actual topology\ntaskset -cp 0,2,4,6,8,10,12,14 $$\n# You can also use `hwloc-ls` or `lstopo` (from hwloc) for a visual map of your CPU topology.\n</code></pre> <p>From now on, all the executable run in this shell will inherit this thread affinity. Feel free to create an alias for this command inside your <code>.bashrc</code> for future use.</p> <p>You can also use the following variable for OpenMP: OMP Places for E/P cores<pre><code>OMP_PLACES=\"{0, 2, 4, 6, 8, 10, 12, 14}\"\n</code></pre></p>"},{"location":"lab4/#f-verify-your-implementations-strong-scaling","title":"f) Verify your implementation's strong scaling:","text":"Strong Scaling<pre><code>OMP_NUM_THREADS=1 ./piestimator 1000000\nOMP_NUM_THREADS=2 ./piestimator 1000000\nOMP_NUM_THREADS=4 ./piestimator 1000000\nOMP_NUM_THREADS=8 ./piestimator 1000000\n</code></pre> <p>Does using 2 threads instead of 1 make your code twice as fast ? Propose an explanation.</p>"},{"location":"lab4/#g-verify-your-implementations-weak-scaling","title":"g) Verify your implementation's weak-scaling:","text":"Weak scaling<pre><code>OMP_NUM_THREADS=1 ./piestimator 1000000\nOMP_NUM_THREADS=2 ./piestimator 2000000\nOMP_NUM_THREADS=4 ./piestimator 4000000\nOMP_NUM_THREADS=8 ./piestimator 8000000\n</code></pre> <p>What results do you expect to see ? Does that match your empirical observations ? Propose an explanation.</p>"},{"location":"lab4/#5-summary","title":"5 - Summary","text":"<p>Upon completing this third lab, you should know how to:</p> <ul> <li> Explain the principle of Monte-Carlo algorithms and apply them to numerical estimation</li> <li> Implement and benchmark a Monte-Carlo estimator with statistical analysis (mean, stddev, min/max)</li> <li> Account for variability and noise in timing benchmarks</li> <li> Use OpenMP to parallelize a minimal compute-bound code and understand implications for thread safety</li> <li> Perform simple analysis of scaling behavior (strong/weak scaling)</li> <li> Understand thread affinity and hardware topology impacts on performance and timing stability</li> </ul>"},{"location":"lab5/","title":"Lab 5: Experimental Methodology and Scientific Reporting","text":"<p>Regression is a classical machine learning problem. It aims at learning to predict a continuous variable from input features. For example, we could predict the height of a person (label) depending on their age, gender, and country of origin (features).</p> <p>In this lab, we will focus on two solutions to the regression problem:</p> <ul> <li>The K-Nearest Neighbors (KNN), where we predict the average value from the K nearest points using euclidean or other distances</li> <li>Gradient Boosting Model (GBM) based on decision trees; using the python package LightGBM.</li> </ul> <p>GBM is a very powerful but complex model. Furthermore, it requires the model to be fitted on a training dataset first. Once fitted, predictions are cheap and constant time. KNN is significantly simpler, does not require model training, but predictions scale with the number of samples in the reference dataset.</p> <p>In this lab, we will learn how to use and apply low-level profiling tools to quantify the performance of both methods, and apply the experimental design course to present our results.</p> <p>The provided source code includes:</p> <ol> <li>A brute-force C implementation of the K-Nearest Neighbors (KNN) regression method using OpenMP.</li> <li>An incomplete and partially broken experiment that attempts to compare how the KNN and LightGBM model behave with an increasing number of samples</li> </ol>"},{"location":"lab5/#1-k-nearest-neighbors-implementation","title":"1. K-Nearest Neighbors implementation","text":"<p>The KNN application can be run like so: Running the KNN<pre><code> # Use cmake to build the application, make sure to be in Release mode\nmkdir build &amp;&amp; cd build &amp;&amp; cmake .. -DCMAKE_BUILD_TYPE=Release &amp;&amp; make\n\n# ./build/myknn &lt;samples.csv&gt; &lt;queries.csv&gt; &lt;k&gt; &lt;num_threads&gt; (&lt;output_csv_path&gt;)\n./build/myknn ./datasets/samples.csv ./datasets/queries.csv 10 8\n</code></pre></p> <p>Danger</p> <p>The parser is very basic: both the queries and datasets .csv file must contain exactly the same columns, in the same order.</p> <p>By default, if no output path is provided, the application will output inside <code>./results.csv</code></p>"},{"location":"lab5/#2-broken-experiment","title":"2. Broken Experiment","text":"<p>The script <code>/scripts/lgbm_vs_knn.py</code> objective is to measure the timing and accuracy of LightGBM and KNN when increasing the number of training samples. The gathered data should look something like this: <pre><code>model,time,mae,nsamples\nlgbm,0.2365,0.0186,2400\nlgbm,0.2308,0.0184,2515\nlgbm,0.2394,0.0185,2636\nknn,0.1604,0.02308,2400\nknn,0.1555,0.0243,2515\nknn,0.1633,0.0358,2636\n...\n</code></pre></p> <p>However, the person writing it never finished it. When fixing this script, you should make sure to:</p> <ul> <li>Keep the same test samples for all runs</li> <li>Use <code>np.linspace</code> or <code>np.geomspace</code> to generate the points</li> <li>Have the timing encompass both training and prediction (We only focus on a coarse performance comparison here)</li> <li>Make multiple repetitions to control measurement noise.</li> <li>You can have one plot for accuracy and one for performance, but having both on the same plot using <code>ax.twinx</code> is a very nice bonus.</li> </ul>"},{"location":"lab5/#3-provided-files","title":"3. Provided Files","text":"Path Description <code>CMakeLists.txt</code> CMake for the C implementation of KNN <code>src/dataset.(c\\|h)</code> Contain the logic for parsing a .csv dataset <code>src/main.c</code> Contain the implementation of KNN <code>datasets/</code> Contain both the training dataset and a sample query file <code>scripts/my_experiment.py</code> Skeleton of an experiment that you will have to complete <code>scripts/lgbm_vs_knn.py</code> An incomplete experiment you will have to finish <code>scripts/stability.py</code> A script to check performance and energy measurement stability"},{"location":"lab5/#1-measuring-energy-execution-time-and-cache-misses","title":"1 - Measuring Energy, execution time, and cache misses","text":"<p>Warning</p> <p>Measuring energy is a significant part of this lab. However, the RAPL energy counter may not be available on your CPU (Mostly Intel/AMD). You will have to find a valid machine to run this measurements.</p> <p>Linux Perf is a very powerful tool to collect a variety of performance indicators. Its capable of capturing a list of CPU-events provided by the user, perform automatic meta-repetitions, and aggregate results in a nice JSON format.</p>"},{"location":"lab5/#1-setup-your-environment","title":"1. Setup your environment","text":"<p>Run the following to setup your lab:</p> Setup the lab<pre><code>source ./setup_env.sh\n</code></pre>"},{"location":"lab5/#2-stabilize-your-machine","title":"2. Stabilize your machine","text":"<p>Run <code>./scripts/stability.py</code> and check the results in <code>results/stability.png</code>. Take the necessary actions to make your machine relatively stable:</p> <ul> <li>Set the energy governor to performance     Performance governor<pre><code>sudo cpupower frequency-set -g performance\n</code></pre>     Remember to switch back to <code>powersave</code> when you're done !</li> <li>If your CPU has heterogeneous cores, set the thread affinity to only use performance cores. </li> <li>If on a laptop, remember to plug your laptop to avoid measurements noise due to the battery governor.</li> <li>Kill any background apps</li> </ul>"},{"location":"lab5/#3-measuring-energy","title":"3. Measuring Energy","text":"<p>What does the following command do ? Idle Energy Consumption<pre><code>perf stat -a -j -e power/energy-pkg/,power/energy-cores/ sleep 60\n</code></pre></p> <p>Ensure your machine is mostly idle and execute this command.</p>"},{"location":"lab5/#a-what-does-energy-pkg-measure-and-whats-the-unit-what-about-the-other-events","title":"a) What does <code>energy-pkg</code> measure, and what's the unit ? What about the other events ?","text":"<p>Compute your machine idle power consumption: \\(P_{idle} = \\frac{\\text{energy-pkg}}{T}\\).</p>"},{"location":"lab5/#b-measure-the-knn-energy-consumption","title":"b) Measure the KNN energy consumption","text":"Workload Consumption<pre><code>time perf stat -r 5 -a -j -e power/energy-pkg/,power/energy-cores/ \\\n    ./build/myknn ./datasets/samples.csv ./datasets/queries.csv 5 1 \n</code></pre> <p>Note that the <code>-r 5</code> flag causes <code>perf</code> to perform 5 meta-repetitions. The <code>time</code> command reports the sum of the timings for all runs. Compute the effective power and energy consumption of the <code>knn</code> application. Remember to substract \\(P_{idle}\\).</p>"},{"location":"lab5/#4-measuring-performance-metrics","title":"4. Measuring performance metrics","text":"<p>What does the following command do ? Measuring performance<pre><code>time perf stat -r 5 -e instructions,cycles,cache-references,cache-misses \\\n    ./build/myknn ./datasets/samples.csv ./datasets/queries.csv 5 1 \n</code></pre></p> <p>Execute this command and answer the following questions.</p>"},{"location":"lab5/#a-whats-the-observed-variance-in-the-execution-time","title":"a) What's the observed variance in the execution time ?","text":""},{"location":"lab5/#b-whats-the-mean-instructions-cycle","title":"b) What's the mean instructions / cycle ?","text":"<p>A Memory bound application has the CPU waiting for data to be retrieved for memory, meaning the CPU has a low number of instructions / cycle. A compute bound application is limited by the CPU performance.</p> <p>Is the application memory bound ?</p>"},{"location":"lab5/#c-whats-the-percentage-of-cache-misses","title":"c) What's the percentage of cache misses ?","text":"<p>Memory accesses are reported as \"Cache References\"</p>"},{"location":"lab5/#d-how-does-the-percentage-of-cache-miss-evolve-when-increasing-the-number-of-threads","title":"d) How does the percentage of cache miss evolve when increasing the number of threads ?","text":"<p>Could you explain why ?</p>"},{"location":"lab5/#5-simple-profiling","title":"5. Simple Profiling","text":"<p>Modify the <code>CMakeLists.txt</code> to add the <code>-pg -g</code> compilation flag, then rerun the application:</p> <p>Tip</p> <p>Cmake does not always detect flag changes and may rebuild with the old flags. Delete <code>./build/CMakeCache.txt</code> and rerun <code>setup_env.sh</code></p> <pre><code>./build/myknn ./datasets/samples.csv ./datasets/queries.csv 5 1 \n</code></pre> <p>You should see that a <code>gmon.out</code> file has appeared; this file contains the profile of the application.</p> <p>Run the following:</p> Running gprof<pre><code>gprof ./build/myknn ./gmon.out\n</code></pre> <p>Where is most of the time spent in the application ?</p> <p>Remove the -pg flag as it will slow your application and bias your measurements later on</p>"},{"location":"lab5/#2-scientific-report-model-comparison-and-energy-study","title":"2 - Scientific Report: Model Comparison and Energy Study","text":"<p>You are tasked to write a maximum three page scientific report with the following sections:</p>"},{"location":"lab5/#a-stability-and-environment","title":"a) Stability and Environment","text":"<ul> <li>Document CPU model, number of cores, Cache(s) size, Ram, OS version, compilers / python version<ul> <li>The dataset <code>datasets/samples.csv</code> contains \\(\\text{ncols} * \\text{nrows}\\) floating point values, stored as 32 bits floats in <code>myknn</code>. Does this dataset fit in your CPU caches ?</li> </ul> </li> <li>Specify CPU gorvernor and thread affinity settings used during the experiments</li> <li>A stability plot generated through <code>scripts/stability.py</code>. </li> <li>Make sure to add a table with the mean and standard deviation of each metric.</li> </ul>"},{"location":"lab5/#b-a-corrected-and-improved-version-of-the-provided-experiment-comparing-knn-regression-with-lightgbm","title":"b) A corrected and improved version of the provided experiment comparing KNN regression with LightGBM","text":"<ul> <li>A paragraph describing the goal of the experiment</li> <li>A paragraph explaining your protocol</li> <li>A plot comparing KNN and LightGBM accuracy and execution time when increasing the number of samples<ul> <li>From this plot, we should observe that: Accuracy increases with the number of samples; the execution time of KNN grows linearly with the number of samples; LightGBM has good scalability and accuracy, and is faster than KNN.</li> <li>Make sure to include confidence intervals.</li> </ul> </li> <li>Your observations and conclusions</li> </ul>"},{"location":"lab5/#c-an-experiment-of-your-choosing","title":"c) An experiment of your choosing","text":"<ul> <li>Formulate a specific question of your choice about energy consumption. Examples:<ul> <li>How does the \\(\\text{efficiency} = \\frac{E}{\\text{# of predictions}}\\) scale with the number of threads for both KNN and LightGBM ?</li> <li>How reproducible and stable are RAPL energy measurements for LightGBM and KNN across multiple runs and thread counts?</li> <li>What is the relationship between energy consumption and the number \\(k\\) of nearest neighbors ?</li> </ul> </li> <li>Formulate a clear hypothesis for your energy experiment (What you expect to see)</li> <li>Explain your experimental design</li> <li>Provide an informative plot that answers the question</li> <li>Present your observations and conclusions</li> </ul> <p>Your report will be evaluated on clarity, conciseness, and scientific rigor. Avoid unnecessary implementation details; focus on producing convincing results.</p>"},{"location":"lab6/","title":"Lab 6 - AI Project (1) SGEMM Kernel Optimization","text":""},{"location":"lab6/#1-implementing-a-naive-sgemm","title":"1 - Implementing a naive SGEMM","text":"<p>We work on multiplication of dense matrices. This algorithm is everywhere (ML, data analysis, 3D engines, physics).  Here we focus on single-precision floating point SGEMM as used in many ML workloads.</p> <p>The operation we want to implement is:</p> \\[ \\text{RES} = A \\times B + C \\] <p></p> sgemm.h<pre><code>/**\n * @brief SGEMM (Single-precision General Matrix Multiply)\n *\n * Performs the matrix multiplication operation:\n * RES = A*B + C\n *\n * @param A Input matrix A with dimensions M x K (row-major order)\n * @param B Input matrix B with dimensions K x N\n * @param C Input matrix C with dimensions M x N\n * @param M Number of rows in matrix A and C\n * @param N Number of columns in matrix B and C\n * @param K Number of columns in matrix A and rows in matrix B\n * @param RES Output matrix with dimensions M x N, where the result will be stored\n */\nvoid sgemm(\n    const float *A,\n    const float *B,\n    const float *C,\n    float *RES,\n    size_t M,\n    size_t N,\n    size_t K);\n</code></pre> <p>Matrices are stored in row-major order (C-style). That is, the elements of each row are stored in contiguous memory locations. For example, a 3x3 matrix:</p> \\[ \\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{pmatrix} \\] <p>is stored in memory as:</p> \\[ [a_{11}, a_{12}, a_{13}, a_{21}, a_{22}, a_{23}, a_{31}, a_{32}, a_{33}] \\]"},{"location":"lab6/#1-creating-random-matrices","title":"1. Creating random matrices","text":"<p>Inside <code>src/</code> you find starter files: <code>sgemm.h</code>, <code>sgemm.c</code>, <code>main.c</code>. Inside <code>tests/</code> you will find <code>test_runner.c</code> that contains a starter test harness.</p>"},{"location":"lab6/#a-implement-random_matrix-inside-sgemmc-to-generate-random-matrices","title":"a) Implement <code>random_matrix</code> inside <code>sgemm.c</code> to generate random matrices.","text":""},{"location":"lab6/#b-add-a-test-in-test_sgemmc-that-checks-that-random_matrix-correctly-generates-matrices-with-values-in-the-range-10-10-call-the-test-from-test_runnerc","title":"b) Add a test in <code>test_sgemm.c</code> that checks that <code>random_matrix</code> correctly generates matrices with values in the range \\([-1.0, 1.0]\\). Call the test from <code>test_runner.c</code>.","text":""},{"location":"lab6/#c-create-a-cmakelisttxt","title":"c) Create a <code>CMakeList.txt</code>","text":"<p>It should: - build an executable <code>gemm</code> from <code>main.c</code> and <code>sgemm.c</code>. - build an executable <code>test_runner</code> from <code>test_runner.c</code> and <code>sgemm.c</code> using the <code>unity</code> testing framework as shown in previous labs. - allow changing the build type (Debug/Release) from the command line with different sets of flags.</p> <p>Check that your code compiles and that the test passes.</p>"},{"location":"lab6/#2-naive-sgemm-implementation","title":"2. Naive SGEMM implementation","text":""},{"location":"lab6/#a-implement-the-naive-version-of-sgemm-in-sgemmc-using-three-nested-loops-in-the-order-i-j-k","title":"a) Implement the naive version of <code>sgemm</code> in <code>sgemm.c</code> using three nested loops in the order (i, j, k).","text":""},{"location":"lab6/#b-add-various-tests-in-test_sgemmc-that-checks-that-your-sgemm-implementation-correctly-computes-the-product-of-small-matrices-with-variying-sizes-and-shapes-eg-1x1-2x2-3x1-1x3-3x3","title":"b) Add various tests in <code>test_sgemm.c</code> that checks that your <code>sgemm</code> implementation correctly computes the product of small matrices with variying sizes and shapes (e.g. 1x1, 2x2, 3x1, 1x3, 3x3).","text":""},{"location":"lab6/#c-check-that-your-tests-pass","title":"c) Check that your tests pass.","text":"<p>Now that you have a working implementation, you can call <code>sgemm</code> from <code>main.c</code> with random matrices of different sizes passed as command line arguments.</p>"},{"location":"lab6/#2-performance-measurement-harness","title":"2 - Performance measurement harness","text":"<p>Create a new directory <code>performance/</code> and add two files: <code>performance.sh</code> and <code>plot.py</code>. For both the measurement harness and plotting script follow best practices taught in lecture 4.</p>"},{"location":"lab6/#1-measure-performance-and-energy-consumption","title":"1. Measure performance and energy consumption","text":"<p>We will use <code>perf</code> to measure the number of CPU cycles and energy consumption of our SGEMM implementation.</p> <p>Example command to measure cycles and energy consumption of a run of <code>sgemm</code> with M=512, K=512, N=512: <pre><code>perf stat -r 3 -e cycles,power/energy-pkg/ ./sgemm sgemm 512 512 512\n</code></pre></p> <p>The <code>-r 3</code> option tells <code>perf</code> to repeat the measurement 3 times and report the mean and variance.</p>"},{"location":"lab6/#2-write-a-script-performancesh","title":"2. Write a script <code>performance.sh</code>","text":"<p>The script should:</p> <ul> <li>run <code>sgemm</code> with M=512, K=512 and N with increasing sizes (100, 200, 300, ..., 3000).</li> <li>measure the number of CPU cycles and energy consumption using <code>perf stat</code> for each run.</li> <li>define a variable <code>REPETITIONS</code> that controls how many times each configuration is repeated. <code>perf</code> supports the <code>-r</code> option to repeat measurements. It outputs the mean and variance of the measurements, allowing to plot error bars.</li> <li>define a variable <code>EVENTS</code> to specify the events to measure (e.g. <code>cycles,power/energy-pkg/</code>).</li> <li>aggregate all measures into a <code>.json</code> file or <code>.csv</code> file.</li> </ul> <p>Tip</p> <p>If you are using <code>json</code>, you can use <code>jq</code> to process the output of <code>perf stat</code> and aggregate the results together with <code>jq -s 'flatten(1)'</code>.</p>"},{"location":"lab6/#3-write-a-script-plotpy","title":"3. Write a script <code>plot.py</code>","text":"<p>The script should:</p> <ul> <li>read the output of <code>performance.sh</code> and produces a plot with two y-axes:</li> <li>left y-axis: number of CPU cycles (with error bars)</li> <li>right y-axis: energy consumption (with error bars)</li> </ul>"},{"location":"lab6/#a-run-your-scripts-and-produce-an-initial-plot","title":"a) Run your scripts and produce an initial plot.","text":""},{"location":"lab6/#b-inspect-your-plot-do-you-see-any-knee-points-can-you-explain-them-hint-consider-cache-sizes","title":"b) Inspect your plot. Do you see any knee points? Can you explain them? (Hint: consider cache sizes.)","text":"<p>Tip</p> <p>You can use the following commands to inspect your CPU and memory topology: - <code>lstopo</code> to view memory/core topology (if available). - <code>cat /proc/cpuinfo</code> to inspect core model, cache sizes.</p>"},{"location":"lab6/#3-optimizations","title":"3 - Optimizations","text":"<p>Note</p> <p>In this section we will implement different optimizations step by step. After each optimization, you should run your performance measurement harness to see the impact of the optimization on performance and energy consumption. Each new version of the code should be implemented in a new function (e.g. <code>sgemm_ikj</code>, <code>sgemm_blocked</code>, <code>sgemm_omp</code>), and you should add a command line option to <code>main.c</code> to select which version to run. Do not forget to add tests for each new version of <code>sgemm</code> in <code>test_sgemm.c</code>.</p>"},{"location":"lab6/#1-vectorization","title":"1. Vectorization","text":"<p>Modern CPUs have SIMD units (SSE/AVX/AVX512). The compiler can generate SIMD code, but the code and data layout must be friendly.</p>"},{"location":"lab6/#a-compiler-flags","title":"a) Compiler flags","text":"<ol> <li>Compile with <code>-O3 -march=native</code> and inspect compiler vectorization reports (GCC/Clang flags to tell whether loops were vectorized: <code>-fopt-info-vec-optimized</code> or <code>-Rpass=loop-vectorize</code>).</li> <li>Measure runtime/energy after changes. Observe and explain differences.</li> </ol> <p>Tip</p> <p>If the compiler does not vectorize your loops, try to understand why. Common reasons include: - Data dependencies that prevent reordering. - Pointer aliasing (use <code>restrict</code> keyword if applicable). - Complex control flow inside loops.</p>"},{"location":"lab6/#b-loop-order-stride","title":"b) Loop order / stride","text":"<p>Ensure the innermost loop has contiguous memory accesses.</p> <ol> <li>Create a new function <code>sgemm_ikj</code> and call it from <code>main.c</code>. Add a command line option to select which version to run.</li> <li>Change the loop order to (i, k, j).</li> <li>Measure runtime/energy and compare to the naive version. Explain differences.</li> </ol>"},{"location":"lab6/#2-cache-blocking","title":"2. Cache blocking","text":"<p>Access to <code>B</code> in the naive algorithm typically strides through columns \u2014 poor locality for row-major storage. Blocking (tiling) improves cache reuse.</p>"},{"location":"lab6/#a-measure-last-level-cache-events-for-the-naive-implementation","title":"a) Measure last-level-cache events for the naive implementation.","text":"<p>Use <code>perf stat</code> with <code>LLC-loads</code> and <code>LLC-stores</code> events. Example:</p> <pre><code>perf stat -e LLC-loads,LLC-stores ./sgemm sgemm_ikj 1280 512 512\n</code></pre>"},{"location":"lab6/#b-implement-a-blocked-matrix-multiplication","title":"b) Implement a blocked matrix multiplication","text":"<p>Define a block size <code>BLOCK</code> (e.g. 32, 64) and implement <code>sgemm_blocked</code> in <code>sgemm.c</code>:</p> sgemm.h<pre><code>#define BLOCK 64  /* block size, tune for your CPU cache */\n/* sgemm_blocked has the same prototype as sgemm and sgemm_ikj */ \nvoid sgemm_blocked( ... );\n</code></pre> <p>Do not forget to call it from <code>main.c</code> and add a command line option to select it.</p> <p>Tip</p> <ul> <li> <p>Ensure <code>n</code> is a multiple of <code>BLOCK</code> for simplicity; either restrict inputs or pad matrices (padding can be an exercise).</p> </li> <li> <p>Inside blocks, use simple triple loops over block elements (ensure indices map correctly to row-major layout).</p> </li> </ul>"},{"location":"lab6/#c-measure-llc-loadsstores-for-the-blocked-version-and-compare-to-naive","title":"c) Measure LLC loads/stores for the blocked version and compare to naive.","text":""},{"location":"lab6/#d-measure-energy-and-time-for-blocked-version-and-compare","title":"d) Measure energy and time for blocked version and compare.","text":""},{"location":"lab6/#e-why-does-blocking-reduce-llc-misses-and-energytime","title":"e) Why does blocking reduce LLC misses and energy/time?","text":"<ol> <li>Parallelization</li> </ol>"},{"location":"lab6/#3-parallelization-with-openmp","title":"3. Parallelization with OpenMP","text":"<p>In this section, we focus on parallelizing the blocked matrix multiplication using OpenMP. While we will only target the CPU for now, other parallel runtimes (e.g., MPI, TBB) could also be explored in the future.</p>"},{"location":"lab6/#a-implement-a-parallel-version-using-openmp","title":"a) Implement a parallel version using OpenMP","text":"<ul> <li>Use OpenMP to parallelize the blocked version of <code>sgemm</code>.</li> <li> <p>Parallelize over blocks of rows for better load balancing.</p> <p>Add <code>#include &lt;omp.h&gt;</code> at the top of your <code>sgemm.c</code> file. Use the following pragma to parallelize the outer loop: <pre><code>#pragma omp parallel for schedule(static)\n</code></pre></p> </li> </ul> <p>Tip</p> <p>Static scheduling is often a good choice for matrix multiplication since the workload is evenly distributed, but you can experiment with other scheduling strategies (e.g., dynamic, guided) to see their impact on performance.</p>"},{"location":"lab6/#b-compile-and-measure-performance","title":"b) Compile and measure performance","text":"<p>You can set the number of threads with the <code>OMP_NUM_THREADS</code> environment variable. For example, to use 8 threads:</p> <pre><code>export OMP_NUM_THREADS=8  # Adjust based on your machine\n</code></pre> <p>Plot the performance and energy consumption of your OpenMP implementation for different numbers of threads (e.g., 1, 2, 4, 8, 16). Add your scripts to <code>performance/</code> and produce a scalability plot.</p>"},{"location":"lab6/#c-analyze-results","title":"c) Analyze results","text":"<ul> <li>Compare energy consumption and runtime to the single-threaded version.</li> <li>Experiment with different numbers of threads and observe the impact on energy and time.</li> <li>Is energy per run higher or lower with more threads? Why?</li> <li>How does memory bandwidth affect scaling as more threads are added?</li> </ul>"},{"location":"lab6/#5-making-a-library","title":"5 - Making a Library","text":"<p>Now that you have optimized your SGEMM implementation, you can package it as a library. In the next lab, we will use your library to implement a simple Neural Network inference engine. </p> <p>To do so, modify your <code>CMakeLists.txt</code> to build a static library <code>libsgemm.a</code> from <code>sgemm.c</code> and <code>sgemm.h</code>. Ensure the prototypes in the public header <code>sgemm.h</code> are well commented in Doxygen style. Modify the <code>CMakeLists.txt</code> so that users of the library know where to find the header files.</p>"},{"location":"lab6/#6-for-further-study","title":"6 - For further study","text":"<p>The matrix product we have implemented is efficient, but it is possible to push optimizations even further. Here are some references and avenues if this work interests you:</p> <ul> <li> <p>Algorithmic improvements such as Strassen allow to trade multiplications for additions, which in some cases can be beneficial.</p> </li> <li> <p>Cache-oblivious algorithms (recursive tiling based on space-filling curves). Instead of using blocking techniques, which must be parameterized by a fixed block size; it is possible to implement matrix multiplication to preserve locality regardless of scale. This is called a cache-oblivious algorithm in English. For matrix multiplication, such an algorithm can be obtained by reordering the elements according to the order given by the Lebesgue curve. This allows obtaining very efficient implementations for matrices whose dimension is a power of two.  </p> </li> <li> <p>Advanced BLAS. You can compare your implementation with <code>cblas_sgemm</code> from optimized vendor libraries (OpenBLAS, Intel MKL). You can even try using <code>cublas</code> library to target GPUs.</p> </li> </ul>"},{"location":"lab6/#7-summary","title":"7 - Summary","text":"<p>Upon completing this lab, you should know how to:</p> <ul> <li> Write a naive implementation of the SGEMM algorithm.</li> <li> Measure performance and energy consumption using <code>perf</code>.</li> <li> Optimize the SGEMM algorithm using vectorization, loop reordering, cache blocking, and parallelization with OpenMP.</li> <li> Analyze the impact of optimizations on performance and energy consumption.</li> </ul>"},{"location":"lab7/","title":"TD7: Projet IA - Part 2 - Neural Networks Inference Engine","text":""},{"location":"lecture1/","title":"Introduction to Software Engineering for HPC and AI","text":"<p> Download as slides \ud83d\udce5 </p>"},{"location":"lecture1/#syllabus","title":"Syllabus","text":"<ul> <li>Lecture 1: Introduction &amp; Development Environment</li> <li>Lecture 2: Mastering C for Performance and HPC</li> <li>Lecture 3: Building, Testing and Debugging Scientific Software</li> <li>Lecture 4: Experimental Design, Profiling and Performance/Energy Optimization</li> <li>Lecture 5: HPC for AI</li> </ul> <p>Project: Inference Engine for a Deep Network</p>"},{"location":"lecture1/#introduction-development-environment","title":"Introduction &amp; Development Environment","text":"<ul> <li>Principles of software engineering applied to HPC and AI.</li> <li>Introduction to computing architectures.</li> <li>Development tools: shell scripts, package management, Git, IDEs, etc.</li> </ul>"},{"location":"lecture1/#analytical-solution-to-the-2-body-problem","title":"Analytical solution to the 2-Body Problem","text":"<p>Consider two particles with masses \\(m_1\\) and \\(m_2\\) at positions \\(x_1\\) and \\(x_2\\) under gravitational interaction.</p> \\[m_1.a_1 = -\\frac{G.m_1.m_2}{\\|x_1 - x_2\\|^3} (x_2 - x_1)\\] \\[m_2.a_2 = -\\frac{G.m_1.m_2}{\\|x_1 - x_2\\|^3} (x_1 - x_2)\\] <p>Solved by Bernoulli in 1734, \\(x_1\\) and \\(x_2\\) can be expressed as simple equations that depend on time, masses, and initial conditions.</p>"},{"location":"lecture1/#why-simulate-the-n-body-problem","title":"Why Simulate the n-Body Problem?","text":"<ul> <li>For \\(n=3\\) or more, no practical analytical solution exists.</li> <li>Even advanced mathematical solutions (e.g., Sundman, 1909) are too slow for real use.</li> <li>Computer simulations allow us to study the motion of many interacting particles.</li> <li>Efficient algorithms (e.g., Barnes-Hut, Fast Multipole) make large-scale simulations possible.</li> <li>HPC is essential to simulate realistic systems in physics, astronomy, and AI.</li> <li>Simulation + HPC = understanding complex systems!</li> </ul>"},{"location":"lecture1/#naive-n-body-simulation-in-c","title":"Naive n-Body Simulation in C","text":"<pre><code>// Compute accelerations based on gravitational forces\nfor (int i = 0; i &lt; num_particles; i++) {\n  double ax = 0.0, ay = 0.0, az = 0.0;\n  for (int j = 0; j &lt; num_particles; j++) {\n    if (i == j) continue;\n    double dx = p[j].x - p[i].x;\n    double dy = p[j].y - p[i].y;\n    double dz = p[j].z - p[i].z;\n    double d_sq = dx * dx + dy * dy + dz * dz;\n    double d = sqrt(d_sq);\n    double f = G * p[i].m * p[j].m / (d_sq * d);\n    ax += f * dx / p[i].m;\n    ay += f * dy / p[i].m;\n    az += f * dz / p[i].m;\n  }\n  p[i].ax = ax;\n  p[i].ay = ay;\n  p[i].az = az;\n}\n</code></pre>"},{"location":"lecture1/#naive-n-body-simulation-in-c_1","title":"Naive n-Body Simulation in C","text":"<p>Introduce a time step <code>dt</code> and update positions based on gravitational forces.</p> <pre><code>// Update positions based on computed accelerations\nfor (int i = 0; i &lt; num_particles; i++) {\n  p[i].x += p[i].ax * dt * dt;\n  p[i].y += p[i].ay * dt * dt;\n  p[i].z += p[i].az * dt * dt;\n}\n</code></pre>"},{"location":"lecture1/#high-performance-computing","title":"High Performance Computing","text":"<p>Fugaku (2020, 442 petaflops, 7.3 million cores)</p> <ul> <li>n-body: integrates 1.45 trillion particules per second.</li> </ul> <p>How to achieve such performance?</p> <ul> <li>Algorithmic improvements:</li> <li>Use tree-based methods (Barnes-Hut) to reduce complexity from \\(O(n^2)\\) to \\(O(n \\log n)\\) or better.</li> <li>Parallelization: distribute computation accross many cores.</li> <li>Vectorization: use SIMD instructions to process multiple data points in parallel.</li> <li>Data locality: optimize data access patterns to minimize memory latency and maximize cache usage.</li> </ul> <p>Compiler optimizations, performance tuning, hardware acceleration are also crucial.</p>"},{"location":"lecture1/#hpc-architectures","title":"HPC Architectures","text":""},{"location":"lecture1/#cpu-instruction-set-isa-quick-review","title":"CPU &amp; Instruction Set (ISA) \u2014 quick review","text":"<ul> <li>CPU core executes instructions; machine state = registers, program counter and flags.</li> <li>Assembly encodes the instructions; compilers translate high-level code into the ISA.</li> <li>types: arithmetic/logical, load/store (memory), control flow (branches, calls), system calls</li> <li>Registers are the fastest storage; register pressure influence performance.</li> </ul>"},{"location":"lecture1/#example-intel-core2-architecture","title":"Example: Intel Core2 Architecture","text":""},{"location":"lecture1/#pipeline-memory-hierarchy-interrupts","title":"Pipeline, Memory Hierarchy &amp; Interrupts","text":"<ul> <li>Pipeline increases instruction throughput, classic 5-stages:</li> <li>Fetch \u2192 Decode \u2192 Execute \u2192 Memory \u2192 Write-back</li> <li>Hazards: data hazards (dependencies), control hazards (branch prediction), resource conflicts.</li> <li>Memory hierarchy: registers \u2192 L1/L2/L3 caches \u2192 DRAM \u2192 persistent storage; spatial and temporal locality drive cache effectiveness.</li> <li>Buses, coherence and NUMA: cross-socket memory access has higher latency; cache coherence and memory bandwidth limit scalability.</li> <li>Interrupts and exceptions: asynchronous interrupts signal external events; exceptions/traps handle synchronous faults; the OS performs context switching and servicing.</li> </ul>"},{"location":"lecture1/#multicore-memory-hierarchy-more-in-next-lecture","title":"Multicore memory hierarchy (more in next lecture ...)","text":""},{"location":"lecture1/#system-hierarchy-physical-view","title":"System hierarchy (physical view)","text":"<ul> <li>Rack \u2192 chassis \u2192 node \u2192 socket \u2192 core \u2192 hardware thread: a multi-level physical organization.</li> <li>Nodes often include accelerators (GPUs, TPUs, FPGAs) and have their own memory (DRAM, sometimes HBM).</li> <li>Heterogeneous hardware and multi-level parallelism are the norm in modern HPC systems.</li> </ul>"},{"location":"lecture1/#interconnects-and-io","title":"Interconnects and I/O","text":""},{"location":"lecture1/#interconnects","title":"Interconnects","text":"<ul> <li>Two key metrics: latency (small-message cost) and bandwidth (sustained transfer rate).</li> <li>Fabrics: Ethernet, InfiniBand, Omni-Path; features to note: RDMA, kernel bypass, hardware offloads.</li> <li>Network topology affects routing, contention and scalability.</li> </ul>"},{"location":"lecture1/#storage-and-io","title":"Storage and I/O","text":"<ul> <li>Parallel file systems provide shared high-throughput storage for HPC jobs.</li> <li>Design I/O to avoid bottlenecks and to fit checkpoint/analysis cadence (collective I/O, buffer in NVMe).</li> </ul>"},{"location":"lecture1/#levels-of-parallelism-mapping","title":"Levels of parallelism &amp; mapping","text":"<ul> <li>Inter-node (distributed memory) via MPI; intra-node threading via OpenMP/pthreads; SIMD/vector units for data-level parallelism.</li> <li>Accelerator offload (CUDA/HIP/OpenCL) creates hybrid MPI+X application patterns.</li> <li>Choose mapping to match algorithm characteristics (communication-heavy vs compute-dense).</li> </ul>"},{"location":"lecture1/#software-stack-operations-current-trends","title":"Software stack, operations &amp; current trends","text":"<ul> <li>Typical stack: compilers, MPI/libfabric, math libraries, system libs</li> <li>Job schedulers (Slurm/PBS) handle resource allocation, queues and batch workflows</li> </ul>"},{"location":"lecture1/#shell-basics-and-scripting","title":"Shell Basics and Scripting","text":""},{"location":"lecture1/#what-is-the-shell","title":"What is the Shell?","text":"<ul> <li>Definition: A shell is a command-line interface to interact with the operating system.</li> <li>Purpose: Execute commands, run programs, and automate tasks.</li> <li>Common Shells: <code>bash</code>, <code>zsh</code>, <code>fish</code>, <code>sh</code>.</li> <li>Why Learn It?</li> <li>Essential for HPC environments.</li> <li>Enables automation and efficient system interaction.</li> </ul>"},{"location":"lecture1/#basic-shell-commands","title":"Basic Shell Commands","text":"<ul> <li>File and Directory Management:</li> <li><code>ls</code>: List files and directories.</li> <li><code>cd &lt;directory&gt;</code>: Change directory.</li> <li><code>pwd</code>: Print current working directory.</li> <li><code>mkdir &lt;directory&gt;</code>: Create a new directory.</li> <li><code>rm &lt;file&gt;</code>: Remove a file.</li> <li>File Viewing:</li> <li><code>cat &lt;file&gt;</code>: Display file contents.</li> <li><code>less &lt;file&gt;</code>: View file contents interactively.</li> <li><code>head &lt;file&gt;</code>: Show the first 10 lines.</li> <li><code>tail &lt;file&gt;</code>: Show the last 10 lines.</li> </ul>"},{"location":"lecture1/#redirections","title":"Redirections","text":"<ul> <li>Standard Input/Output:</li> <li><code>&lt;</code>: Redirect input from a file.</li> <li><code>&gt;</code>: Redirect output to a file (overwrite).</li> <li><code>&gt;&gt;</code>: Append output to a file.</li> <li>Examples:</li> <li><code>cat file.txt &gt; output.txt</code>: Save contents of <code>file.txt</code> to <code>output.txt</code>.</li> <li><code>grep \"error\" log.txt &gt;&gt; errors.txt</code>: Append lines containing \"error\" to <code>errors.txt</code>.</li> </ul>"},{"location":"lecture1/#pipes","title":"Pipes","text":"<ul> <li>Definition: Pipes (<code>|</code>) connect the output of one command to the input of another.</li> <li>Examples:</li> <li><code>ls | grep \".txt\"</code>: List <code>.txt</code> files.</li> <li><code>cat file.txt | wc -l</code>: Count the number of lines in <code>file.txt</code>.</li> <li>Why Use Pipes?</li> <li>Combine simple commands to perform complex tasks.</li> <li>Avoid creating intermediate files.</li> </ul>"},{"location":"lecture1/#variables-and-environment","title":"Variables and Environment","text":"<ul> <li>Variables:</li> <li><code>VAR=value</code>: Define a variable.</li> <li><code>$VAR</code>: Access the variable's value.</li> <li>Environment Variables:</li> <li><code>echo $HOME</code>: Display the home directory.</li> <li> <p><code>export PATH=$PATH:/new/path</code>: Add a directory to the <code>PATH</code>.</p> </li> <li> <p>Example:</p> </li> </ul> <pre><code>NODES=4\nPROGRAM=\"my_hpc_program\"\necho \"Running $PROGRAM on $NODES MPI nodes...\"\nmpirun -np $NODES ./$PROGRAM\n</code></pre>"},{"location":"lecture1/#writing-a-simple-script","title":"Writing a Simple Script","text":"<ul> <li>What is a Script?</li> <li>A file containing a sequence of shell commands.</li> <li>Creating a Script:</li> <li>Create a file: <code>vim script.sh</code>.</li> <li> <p>Add commands:</p> <pre><code>#!/bin/bash\necho \"Hello, World!\"\n</code></pre> </li> <li> <p>Make it executable: <code>chmod +x script.sh</code>.</p> </li> <li>Run it: <code>./script.sh</code>.</li> </ul>"},{"location":"lecture1/#conditional-statements","title":"Conditional Statements","text":"<pre><code>if [ -f \"config.json\" ]; then\n  echo \"config.json exists. Running the HPC program...\"\n  ./my_hpc_program --config=config.json\nelse\n  echo \"Error: config.json does not exist.\"\nfi\n</code></pre>"},{"location":"lecture1/#loops","title":"Loops","text":"<pre><code>for i in {1..5}; do\n  echo \"Running simulation with parameter set $i...\"\n  ./my_hpc_program --config=config_$i.json\ndone\n</code></pre>"},{"location":"lecture1/#functions-in-shell-scripts","title":"Functions in Shell Scripts","text":"<pre><code>run_simulation() {\n  echo \"Starting with config file: $1 and $2 nodes...\"\n  mpirun -np $2 ./simulation_program --config=$1\n  echo \"Simulation completed.\"\n}\nrun_simulation \"simulation_config.json\" 8\n</code></pre>"},{"location":"lecture1/#debugging-and-best-practices","title":"Debugging and Best Practices","text":"<ul> <li>Debugging:</li> <li>Run with <code>bash -x script.sh</code> to trace execution.</li> <li>Use <code>set -e</code> to exit on errors as the first command.</li> <li>Best Practices:</li> <li>Use comments (<code>#</code>) to explain code.</li> <li>Write reusable functions.</li> <li>Check for errors (<code>if [ $? -ne 0 ]; then</code>).</li> <li>Test scripts on small inputs before scaling up.</li> </ul>"},{"location":"lecture1/#package-management","title":"Package Management","text":""},{"location":"lecture1/#package-management-overview","title":"Package Management: Overview","text":"<ul> <li>Problem Solved: Simplifies software installation, updates, and dependency management.</li> <li>Ensures compatibility between libraries and applications.</li> <li>Tracks installed software versions for easy upgrades or rollbacks.</li> <li>Examples: <code>dnf</code> (Fedora/RHEL), <code>apt</code> (Debian/Ubuntu).</li> </ul>"},{"location":"lecture1/#package-managers-for-hpc","title":"Package Managers for HPC","text":"<ul> <li>Cluster-Specific Tools: <code>spack</code>, <code>guix</code> enable software installation without root privileges.</li> <li>Useful in HPC environments where users lack admin rights.</li> <li>Manage multiple versions of libraries and tools for reproducibility.</li> <li>Facilitate deployment of complex scientific software stacks.</li> </ul>"},{"location":"lecture1/#language-specific-containers","title":"Language-Specific &amp; Containers","text":"<ul> <li>Language-Specific Managers: <code>pip</code> (Python), <code>cargo</code> (Rust) simplify language ecosystem management.</li> <li>Containers: Tools like Docker/Singularity encapsulate software and dependencies.</li> <li>Enable portability across systems and reproducible environments.</li> <li>Virtualization/containerization is becoming popular in modern HPC workflows.</li> </ul>"},{"location":"lecture1/#version-control-systems","title":"Version Control Systems","text":""},{"location":"lecture1/#what-is-version-control","title":"What is Version Control?","text":"<p>Version control involves tracking and managing the changes made to project files.</p> <p>Each version is associated with a date, an author, and a message. Developers can work on a copy corresponding to a specific version.</p>"},{"location":"lecture1/#objectives","title":"Objectives","text":"<ul> <li>Enhance communication among developers (track code evolution, messages).</li> <li>Isolate experimental developments (work branches).</li> <li>Ensure code stability (stable version on the main branch, ability to revert to a stable version).</li> <li>Manage releases (tags for specific versions).</li> </ul>"},{"location":"lecture1/#vocabulary-for-versions","title":"Vocabulary for Versions","text":"<ul> <li>Version \u2014 a recorded state or revision in the project's history.</li> <li>Commit \u2014 a snapshot of the project at a given version with metadata.</li> <li>Branch \u2014 an independent line of development (use one branch per feature/experiment).</li> <li>Tag \u2014 a stable label pointing to a specific commit (e.g., releases).</li> <li>Diff / Patch \u2014 textual representation of changes between versions.</li> <li>Conflict \u2014 incompatible concurrent edits that must be resolved manually.</li> </ul>"},{"location":"lecture1/#vocabulary-for-storage","title":"Vocabulary for Storage","text":"<ul> <li>Repository \u2014 storage of the project's history (local <code>.git</code> and metadata).</li> <li>Clone \u2014 a full local copy of the repository including history.</li> <li>Working copy \u2014 editable files checked out from a repository.</li> <li>Index / Staging area \u2014 area to stage selected changes for the next commit.</li> <li>Remote \u2014 hosted repository (e.g., <code>origin</code> on GitHub/GitLab) for collaboration.</li> </ul>"},{"location":"lecture1/#distributed-vcs","title":"Distributed VCS","text":"<p>Distributed Version Control System (DVCS)</p>"},{"location":"lecture1/#advantages","title":"Advantages","text":"<ul> <li>Multiple repositories can exist.</li> <li>Version control can be performed locally.</li> <li>No need for network connectivity.</li> </ul>"},{"location":"lecture1/#examples","title":"Examples","text":"<ul> <li>Mercurial (2005) (Mozilla, Python, OpenOffice.org)</li> <li>Bazaar (2005) (Ubuntu, MySQL)</li> <li>Git (2005) (Linux Kernel, Debian, VLC, Android, Gnome, Qt)</li> </ul>"},{"location":"lecture1/#introduction-to-dvcs-git","title":"Introduction to DVCS: Git","text":""},{"location":"lecture1/#history","title":"History","text":"<ul> <li>Git was created in 2005 to version the development of the Linux kernel.</li> <li>Designed as a distributed version control system (replacing BitKeeper).</li> </ul>"},{"location":"lecture1/#context","title":"Context","text":"<ul> <li>Widely used by projects: Linux Kernel, Debian, VLC, Android, Gnome, Qt, etc.</li> <li>Accessible via command-line interface.</li> <li>Graphical tools available: gitk, qgit.</li> </ul>"},{"location":"lecture1/#core-principles-of-git","title":"Core Principles of Git","text":"<ul> <li>Git does not store differences between commits (unlike SVN).</li> <li>Instead, Git stores snapshots of the project's file hierarchy at each commit.</li> <li>These snapshots are based on hierarchical structures of objects.</li> <li>Git operations revolve around manipulating these objects.</li> </ul>"},{"location":"lecture1/#hash","title":"Hash","text":"<ul> <li>Each object has a unique hash (SHA1).</li> <li>Git identifies identical objects by comparing their hashes.</li> <li>The same content stored in different repositories will always have the same hash.</li> </ul>"},{"location":"lecture1/#git-objects","title":"Git Objects","text":"<p>Object types include:</p> <ul> <li>Blob: Stores file data.</li> <li>Tree: References a list of other trees or blobs.</li> <li>Commit: Points to a single tree, representing a project snapshot. Includes metadata like timestamp, author, and parent commits.</li> <li>Tag: Labels a specific commit for easy reference.</li> </ul>"},{"location":"lecture1/#commit-representation","title":"Commit Representation","text":"<p>(Git Community Book, p13) </p>"},{"location":"lecture1/#commit-structure","title":"Commit Structure","text":"<p>(Git Community Book, p14) </p>"},{"location":"lecture1/#git-repository","title":"Git Repository","text":"<ul> <li>.git directory:  </li> <li>Stores the project's history.  </li> <li>Contains metadata for version control.  </li> <li>Located at the root of the project.</li> </ul>"},{"location":"lecture1/#working-directory","title":"Working Directory","text":"<ul> <li>Current version of project files.  </li> <li>Files are replaced or removed by Git during branch or version changes.</li> </ul>"},{"location":"lecture1/#index-staging-area","title":"Index / Staging Area","text":"<ul> <li>Bridge between the working directory and the repository.  </li> <li>Used to group changes for a single commit.  </li> <li>Only the index content is committed, not the working directory.</li> </ul>"},{"location":"lecture1/#basic-commands","title":"Basic Commands","text":"<ul> <li><code>git init</code>: Initialize a Git repository.</li> <li><code>git clone &lt;repository&gt;</code>: Clone a repository.</li> <li><code>git status</code>: Check the status of the working directory and staging area.</li> <li><code>git add &lt;file&gt;</code>: Stage changes for commit.</li> <li><code>git commit</code>: Commit staged changes.</li> </ul>"},{"location":"lecture1/#basic-commands-continued","title":"Basic Commands (Continued)","text":"<ul> <li><code>git pull</code>: Update local repository from remote.</li> <li><code>git push</code>: Push local commits to remote repository.</li> <li><code>git log</code>: View commit history.</li> <li><code>git checkout &lt;hash&gt;</code>: Switch to a specific commit using its SHA1 hash.</li> <li><code>git branch &lt;branchName&gt;</code>: Create a new branch.</li> </ul>"},{"location":"lecture1/#branches-purpose","title":"Branches: Purpose","text":"<ul> <li>Work on changes that diverge from the main branch or another branch.</li> <li>Isolate experimental developments.</li> <li>Avoid disrupting shared development efforts.</li> <li>Version parallel developments with the option to merge later.</li> </ul>"},{"location":"lecture1/#branches-commands","title":"Branches: Commands","text":"<ul> <li><code>git branch</code> or <code>git checkout -b &lt;branchName&gt;</code>: Create a new branch.</li> <li><code>git checkout &lt;branchName&gt;</code>: Switch to an existing branch.</li> <li><code>git merge &lt;branchName&gt;</code>: Merge a branch into the current branch.</li> <li><code>git branch -d &lt;branchName&gt;</code>: Delete a branch.</li> <li><code>git branch</code>: List all branches and show the current branch.</li> </ul>"},{"location":"lecture1/#conflict-management","title":"Conflict Management","text":"<ul> <li> <p>Conflict: Occurs during branch merging when two changes affect the same lines.</p> </li> <li> <p>Resolution Steps:</p> </li> <li>Merge is paused.</li> <li>Conflict zones are marked in the file.</li> <li>Edit the file to resolve conflicts by choosing one version or combining changes.</li> <li>Verify and validate the resolution.</li> <li>Commit the resolved conflict.</li> </ul>"},{"location":"lecture1/#correction-methods","title":"Correction Methods","text":"<ul> <li>Undo Changes: Use <code>git reset</code> to discard modifications.</li> <li>Amend Last Commit: Use <code>git commit --amend</code> to modify the previous commit.</li> <li>Branch-Based Correction: Create a new branch from a specific version and work from there.</li> <li>Rewrite History: Use <code>git rebase</code> to edit commits and history.</li> </ul>"},{"location":"lecture1/#warning","title":"Warning","text":"<ul> <li>Rewriting History: Interactive rebasing is risky. Only rewrite commits that haven't been pushed to a remote repository. Prefer branch-based corrections for safer handling.</li> </ul>"},{"location":"lecture1/#centralized-collaboration","title":"Centralized Collaboration","text":"<p>(image from Joomla's documentation)</p>"},{"location":"lecture1/#decentralized-with-central-repository","title":"Decentralized with Central Repository","text":"<p>(image from Joomla's documentation)</p>"},{"location":"lecture1/#fully-decentralized-collaboration","title":"Fully Decentralized Collaboration","text":"<p>(image from Joomla's documentation)</p>"},{"location":"lecture1/#best-practices-for-collaborative-development","title":"Best Practices for Collaborative Development","text":""},{"location":"lecture1/#before-development","title":"Before Development","text":"<ul> <li>Define a developer charter:</li> <li>Naming conventions for files, functions, variables.</li> <li>Standards for technical documentation and comments.</li> <li> <p>Indentation rules (tabs vs spaces).</p> </li> <li> <p>Establish a version control strategy.</p> </li> </ul>"},{"location":"lecture1/#during-development","title":"During Development","text":"<ul> <li>Create isolated commits (one commit = one coherent change).</li> <li>Write concise commit messages (max 60 characters summarizing the change).</li> <li>Add detailed commit descriptions if necessary.</li> <li>Regularly update your working copy.</li> <li>Share updates with team members.</li> </ul>"},{"location":"lecture1/#references","title":"References","text":"<ul> <li>The Art of HPC by Victor Eijkhout</li> <li>What Every Programmer Should Know About Memory by Ulrich Drepper</li> <li>The Git Community Book</li> <li>Tech Talk: Linus Torvalds on Git (YouTube)</li> <li>TOP500 Supercomputers</li> <li>Modern Operating Systems by Andrew S. Tanenbaum</li> <li>GIT Lecture Notes by Thomas Dufaud (IUT V\u00e9lizy - UVSQ)</li> </ul>"},{"location":"lecture2/","title":"C for High Performance","text":"<p> Download as slides \ud83d\udce5 </p>"},{"location":"lecture2/#why-c-c-python","title":"Why C, C++, Python ?","text":"<p>Programming occurs at several abstraction levels from the hardware</p> <p></p>"},{"location":"lecture2/#why-c-c-python_1","title":"Why C, C++, Python ?","text":"<ul> <li>Layers close to metal are harder to program...<ul> <li>But they offer maximum control and performance</li> </ul> </li> <li>High-level abstraction maximize productivity...<ul> <li>But have significant overhead, less control over performance</li> </ul> </li> </ul> <p>In practice; we often combine multiple languages</p> <ul> <li>C for performance critical sections, python for higher level APIs</li> </ul>"},{"location":"lecture2/#why-c-c-python_2","title":"Why C, C++, Python ?","text":""},{"location":"lecture2/#c-programming-operations-and-typing","title":"C Programming - Operations and Typing","text":"<p>C is a strongly typed imperative language:</p> <pre><code>int main() {\n  int a = 5;\n  int b = 10;\n\n  int c = a + b;\n  float d = c / a;\n  float e = (float)c / a;\n\n  int f = a * a * a * a;\n\n  return 0;\n}\n</code></pre> <p><code>main</code> is the program entry point.</p>"},{"location":"lecture2/#c-programming-functions","title":"C Programming - Functions","text":"<pre><code>#include &lt;stdio.h&gt; // For printf(...)\n\nint sum_and_square(int a, int n) {\n  int tmp = a + n;\n  return tmp * tmp;\n}\n\nint main() {\n  int a = 5;\n  int b = 4;\n  int c = sum_and_square(a, b);\n  int d = sum_and_square(3, 9);\n\n  // Print the result to the console\n  printf(\"(5+4)**2: %d\\n\", c);\n  printf(\"(3+9)**2: %d\\n\", d);\n  return 0;\n}\n</code></pre>"},{"location":"lecture2/#c-programming-loops","title":"C Programming - Loops","text":"<p>Implementation C de \\(\\sum_{i=1}^{100}{i}\\)</p> <p><pre><code>#include &lt;stdio.h&gt; // For printf(...)\n\nint sum_range(const int start, const int end) {\n  int sum = 0;\n  // Consider start = 0; end = 100\n  // For i starting at 0; while i &lt;= 100; increment i by one\n  for (int i = start; i &lt;= end; i = i + 1) {\n    sum += i;\n  }\n  return sum;\n}\n\nint main() {\n  printf(\"Result: %d\\n\", sum_range(1, 100));\n  return 0;\n}\n</code></pre> <code>const</code> qualified variable cannot be modified. This may enable optimizations during compilation.</p>"},{"location":"lecture2/#c-programming-conditions","title":"C Programming - Conditions","text":"<p>Numbers of multiple of 3 inside \\([0, 99]\\) (i.e. \\(i \\mod 3 = 0\\)) <pre><code>void count_multiples_of_three() {\n  unsigned int count = 0;\n  // For i starting at 0; while i &lt; 100; increment i by one\n  for (unsigned int i = 0; i &lt; 100; i++) {\n    // if i % 3 (Remainder of the integer division) is equal to 0\n    if (i % 3 == 0) {\n      count++;\n    }\n  }\n  printf(\"Result: %d\\n\", count);\n}\n</code></pre></p>"},{"location":"lecture2/#note","title":"Note","text":"<p>Here we could also do <code>for (unsigned int i = 0; i &lt; 100; i += 3)</code></p>"},{"location":"lecture2/#c-programming-basic-pointers","title":"C Programming - Basic Pointers","text":"<p><pre><code>int a = 0;\nint b = 5;\n\nint* c = &amp;a;\n*c = *c + b;\nprintf(\"a: %d; b: %d; c: %d\\n\", a, b , *c);\n</code></pre> <code>c</code> contains the address of <code>a</code>; so <code>*c = *c + b</code> write in <code>a</code> the sum of <code>a</code> and <code>b</code>.</p> Adress Value Variable 0x004 0 a 0x008 5 b 0x00c 0x004 c ... ... ..."},{"location":"lecture2/#c-programming-arrays","title":"C Programming - Arrays","text":"<pre><code>int main() {\n  char morpion[9] = {'X', 'O',  '\\0',\n                     'O', 'X',  '\\0',\n                     'O', '\\0', '\\0'};\n  morpion[8] = 'X'; // The player clicked on the bottom-right cell !\n}\n</code></pre>"},{"location":"lecture2/#c-programming-structures","title":"C Programming - Structures","text":"<p>Structures are user-defined composite types:</p> <pre><code>typedef struct {\n  char* first_name;\n  char* last_name;\n  int age;\n  float mean_grade;\n  char gender;\n} Student;\n</code></pre> <pre><code>Student e1 = {\"Dupont\", \"Pierre\", 22, 13, 'm'};\nStudent e2 = {\"Major\", \"Major\", 22, 13.5, 'a'};\nStudent e3 = {\"Martin\", \"Evelynne\", 24, 14, 'f'};\n\nif (e1.mean_grade &gt; 10) {\n  printf(\"(%s %s) is a pretty good student !\\n\", \n         e1.first_name, e1.last_name);\n}\n</code></pre> <p>C has no concept of <code>class</code>, <code>object</code>, or <code>method</code> !</p>"},{"location":"lecture2/#c-programming-structures-2","title":"C programming - Structures 2","text":"<pre><code>void display_student(Student* s) {\n  // s-&gt;age is equivalent to (*s).age\n  printf(\"%s %s (%i): %f\\n\", s-&gt;first_name, \n                             s-&gt;last_name, s-&gt;age,\n                             s-&gt;mean_grade);\n}\n\n// We can have arrays of any types !\nStudent students[3] = {{\"Dupont\", \"Pierre\", 22, 13, 'm'}, ...};\nfor (int i = 0; i &lt; 3; i++)\n  display_student(&amp;students[i]);\n</code></pre>"},{"location":"lecture2/#c-programming-trading-abstraction-for-performance","title":"C Programming - Trading Abstraction for performance","text":""},{"location":"lecture2/#in-c-we-must-manually-take-care-of-very-low-level-concepts","title":"In C, we must manually take care of very low level concepts","text":"<ul> <li>We care about data layout, memory addresses, pointers, etc.</li> <li>The language doesn't provide linked lists, dynamic arrays, dictionaries, etc.</li> <li>No basic algorithms like sorting</li> </ul>"},{"location":"lecture2/#on-the-flip-side-we-can","title":"On the flip side, we can","text":"<ul> <li>Manually lay out data to maximize efficiency</li> <li>Remove any abstractions and overhead to maximize performance</li> <li>Generate code  that runs as close to the metal as possible</li> <li>Optimize our program for the hardware</li> </ul>"},{"location":"lecture2/#c-programming-trading-abstraction-for-performance-example","title":"C Programming - Trading Abstraction for performance (Example)","text":"<p>Consider the following python and C code:</p> <pre><code>sum = 0\nfor i in range(ub):\n  sum += i\nprint(sum)\n</code></pre> <pre><code>unsigned long long sum = 0;\nfor (unsigned int i = 0; i &lt; ub; i++){\n    sum += i;\n}\nprintf(\"Sum of first %llu integers is: %llu\\n\", ub, sum);\n</code></pre> <p>Where ub is a very large number (100 Millions in this example). Which one is faster, and by how much ?</p>"},{"location":"lecture2/#c-programming-trading-abstraction-for-performance-example_1","title":"C Programming - Trading Abstraction for performance (Example)","text":"<p>Results:</p> <ul> <li><code>C</code> version: 0.024s</li> <li><code>Python</code> version: 5.650s</li> </ul> <p>That's a speedup of \\(\\times 235\\). </p> <p>We will see later in this course how this is possible.</p>"},{"location":"lecture2/#numpy-and-other-libraries","title":"Numpy and other libraries","text":"<p>Note that we could use <code>numpy</code> or the <code>sum</code> python function: but those are actually implemented in <code>C</code> !</p>"},{"location":"lecture2/#managing-memory","title":"Managing Memory","text":""},{"location":"lecture2/#managing-memory-concept","title":"Managing Memory - Concept","text":""},{"location":"lecture2/#in-high-level-languages","title":"In High-level languages","text":"<ul> <li>We operate on abstracted data structures (lists, dictionaries, etc.)</li> <li>Memory is managed automatically (allocation, resizing, deallocation)</li> <li>We don't care about memory alignment, stack vs. heap, page size, Numa effects, etc.</li> </ul>"},{"location":"lecture2/#in-c","title":"In C","text":"<ul> <li>We perform directly with primitive data and raw memory</li> <li>We are responsible for allocation, layout, and cleanup</li> <li>We can only request chunks of raw memory, and fill it however we choose</li> <li>This is critical for performance</li> </ul> <p>This low level control is critical for performance; hence we must understand how memory works under the hood !</p>"},{"location":"lecture2/#managing-memory-memory-types","title":"Managing Memory - Memory Types","text":"<p>We can distinguish two types of memory</p> <ul> <li>Memory automatically allocated by the compiler on the stack.<ul> <li>Stores variables, functions arguments, etc.</li> <li>Fast but limited in size</li> </ul> </li> <li>Memory that is (manually) dynamically allocated on the heap <ul> <li>Must be allocated and freed by the developer !</li> </ul> </li> </ul> <p>The kernel (Linux / Windows) allocates memory pages and operates at a coarse grain level. The standard library (<code>libc</code>) manipulates pages on a finer scale and provides memory to the user.</p>"},{"location":"lecture2/#managing-memory-allocation","title":"Managing Memory - Allocation","text":"<pre><code>#include &lt;time.h&gt; // for time\n#include &lt;stdlib.h&gt; // For malloc,  srand, rand\n\nint do_the_thing(int n) {\n  // We allocate n numbers\n  float* numbers = malloc(sizeof(float) * n);\n\n  // We seed the random number generator\n  srand(time(NULL));\n\n  // We generate nsamples random numbers\n  for (int i = 0; i &lt; n; i++) {\n    numbers[i] = (float) rand() / RAND_MAX; // Generate a number in [0, 1]\n  }\n  ... // Do something complicated here\n  free(numbers); // Release memory back to the kernel\n  return 0;\n}\n</code></pre>"},{"location":"lecture2/#managing-memory-allocation_1","title":"Managing Memory - Allocation","text":"<p><code>malloc</code> returns a pointer to the beginning of the allocated memory range</p>"},{"location":"lecture2/#managing-memory-deallocation","title":"Managing Memory - Deallocation","text":"<p>Memory is not infinite ! </p> <p>In Python (and Java, C#, etc.); memory is managed by the garbage collector (GC):</p> <ul> <li>The runtime tracks all memory allocations; and all reference(s)</li> <li>When a memory block is not referenced by the program; the GC will release the memory back to the kernel.</li> </ul> <p>In C/C++, the user must deallocate memory using <code>free(ptr)</code>. </p>"},{"location":"lecture2/#memory-leak","title":"Memory leak","text":"<p>If memory is not freed (memory leak) the computer can run out:</p> <ul> <li>The kernel can kill the program</li> <li>The OS can crash</li> <li>Other applications requesting memory can crash or fail</li> </ul>"},{"location":"lecture2/#virtual-and-physical-memory-problem","title":"Virtual And Physical Memory - Problem","text":"<ul> <li>How can the kernel guarantee that memory is always contiguous?</li> <li>Can I acess memory from another program and steal their data?</li> <li>How can multiple applications share the same memory?</li> <li>Some variables have hard-coded addresses!</li> <li>How to handle (Internal/External) fragmentation (Empty slot)? </li> </ul>"},{"location":"lecture2/#virtual-and-physical-memory-concept","title":"Virtual And Physical Memory - Concept","text":"<p>We separate Physical Addresses (locations in memory) from Virtual Addresses (Logic locations) seen by each program !</p> <ul> <li>Physical memory is divided into small fixed-size blocks called pages (typically ~4KB).</li> <li>The CPU includes a Memory Management Unit (MMU) that translates virtual addresses into physical addresses.</li> <li>Each program is given its own isolated virtual address space.</li> <li>The kernel maintains a page table for each program that tells the MMU how to translate addresses.</li> </ul>"},{"location":"lecture2/#the-illusion-of-contiguity","title":"The Illusion of contiguity","text":"<p>Each process believes it has acces to a large, contiguous block of memory; while it can be physically fragmented or shared.</p>"},{"location":"lecture2/#virtual-and-physical-memory-diagram","title":"Virtual And Physical Memory - Diagram","text":"<p>*Note that this is a simplified representation.</p>"},{"location":"lecture2/#memory-hierarchy","title":"Memory Hierarchy","text":"<p>Which memory are we talking about ?</p> <p></p> <p>Note that GPU(s) also have their own separate memory !</p>"},{"location":"lecture2/#memory-hierarchy_1","title":"Memory Hierarchy","text":"<ul> <li>CPU computations are extremely fast, and memory access can be a bottleneck</li> <li>Registers have the lowest latency</li> <li>CPU caches (L1, L2, L3) act as fast buffers for memory</li> <li>DRAM (main memory) is much slower, but cheaper and larger</li> <li>Accessing DRAM causes significant delays compared to cache</li> </ul> <p>To achieve high performance, we must maximize data reuse in registers or caches, and minimize DRAM access.</p>"},{"location":"lecture2/#cpu-caches","title":"CPU Caches","text":"<p>Most CPU have 3 levels of cache</p> <ul> <li>L1d - First Level Cache (Very fast)</li> <li>L2 - Second Level Cache (Fast)</li> <li>L3 (Last Level Cache - LLC) (Larger but slower than L1/L2)</li> </ul> <p>Some cache level are per-core (L1, often L2) whereas others are shared between multiple cores (L3).</p>"},{"location":"lecture2/#instruction-cache","title":"Instruction Cache","text":"<p>The assembly instructions are stored in a separate (L1i) instruction cache</p>"},{"location":"lecture2/#cpu-caches_1","title":"CPU Caches","text":"<p>We speak of Heterogeneous Memory Hierarchy: the same memory accesses can have different latency depending on where the data resides !</p> <p>[Live example: LSTOPO]</p>"},{"location":"lecture2/#cpu-caches-in-practice","title":"CPU Caches - In practice","text":"<pre><code>for (int i = 0; i &lt; n; i++) {\n  T[i] = A[i] * B[i];\n}\n</code></pre> <ol> <li>The cache controller looks-up the data inside the CPU cache (L1 -&gt; L2 -&gt; L3)</li> <li>If available, data is sent to register for the ALU</li> <li>Else, a memory request is emitted</li> <li>This introduces latency and a bubble in the CPU pipeline</li> <li>When the memory request is resolved; execution resumes</li> <li>The results of \\(a*b\\) is written to cache, and eventually back to main memory later on.</li> </ol>"},{"location":"lecture2/#cpu-caches-in-practice_1","title":"CPU Caches - In practice","text":"<p>In practice:</p> <ul> <li>The CPU fetches entire cache line (Often 64 Bytes) at once (If float: \\(64B / 4B = 16\\) values at once) </li> <li>The CPU can prefetch data: it learns data access patterns and anticipates future memory access.</li> <li>The CPU can execute out-of-order; independent instructions are executed while the memory request is in flight.</li> </ul>"},{"location":"lecture2/#caches-cpu-strided-access","title":"Caches CPU - Strided Access","text":"<p>Consider two NBody 3D implementations:</p> <p>Array Of Structure (AoS)</p> <pre><code>// We allocate N tuples of (x, y, z) positions\nfloat* positions = malloc(sizeof(float) * N * 3);\n</code></pre> <p>Structure Of Array (SoA)</p> <pre><code>// We allocate separate arrays for each components\nfloat* x = malloc(sizeof(float) * N);\nfloat* y = malloc(sizeof(float) * N);\nfloat* z = malloc(sizeof(float) * N);\n</code></pre>"},{"location":"lecture2/#caches-cpu-strided-access_1","title":"Caches CPU - Strided Access","text":"<p>We want to record the number of particles with \\(x \\leq 0.5\\)</p> <p>Array Of Structure (AoS)</p> <pre><code>for (int i = 0; i &lt; N; i += 3)\n  if (positions[i] &lt; 0.5)\n    count++;\n</code></pre> <p>Structure Of Array (SoA)</p> <pre><code>for (int i = 0; i &lt; N; i++)\n  if (x[i] &lt; 0.5)\n    count++;\n</code></pre> <p>Which one is faster; and why ?</p> <p>Which access pattern makes better use of cache lines ?</p>"},{"location":"lecture2/#caches-cpu-strided-access_2","title":"Caches CPU - Strided Access","text":"<p><code>Perf</code> results summed across 100 runs:</p> Time # Instr # L1 Loads # L1 Miss # LLC Loads # LLC Miss AoS ~1.93s ~14 Billion ~3.5 Billion ~1 Million ~400k ~382k SoA ~1.75s ~14 Billion ~3.5 Billion ~300k ~24k ~15k # Cache references (LLC) # Cache miss AoS ~158 Million ~151 Million SoA ~52 Million ~35 Million <p>With AoS more load fail in the L1, leading to LLC accesses.</p> <p>Most LLC loads still results in misses, leading to DRAM access.</p>"},{"location":"lecture2/#compilation-assembly","title":"Compilation &amp; Assembly","text":""},{"location":"lecture2/#compilation-assembly-introduction","title":"Compilation &amp; Assembly - Introduction","text":"<p>C is a compiled language: we must translate the source code to assembly for the CPU</p> <p><code>gcc ./main.c -o main (&lt;flags&gt;)</code></p> <ul> <li>Python is interpreted</li> <li>More flexible but significantly slower</li> <li>C# and Java are compiled to intermediary bytecode and then executed via a virtual machine (or JIT-ed)</li> <li>Balances performance and productivity</li> <li>C/C++/Rust are compiled to assembly code</li> <li>Poor portability, but no intermediary.</li> </ul>"},{"location":"lecture2/#compilation-assembly-simple-loop","title":"Compilation &amp; Assembly - Simple Loop","text":"<pre><code>int sum = 0;\nfor (int i = 0; i &lt; 100000; i++){\n  sum += i;\n}\n</code></pre> <pre><code>main:\n.LFB6:\n    pushq   %rbp                 // We record the stack pointer\n    movq    %rsp, %rbp\n    movl    $0, -4(%rbp)         // Initialize sum\n    movl    $0, -8(%rbp)         // Initialize i\n    jmp .L2\n.L3:\n    movl    -8(%rbp), %eax       // Load sum to a register\n    addl    %eax, -4(%rbp)       // Add i and sum (from memory)\n    addl    $1, -8(%rbp)         // Add 1 to i (from memory)\n.L2:\n    cmpl    $99999, -8(%rbp)     // Check if i &lt; 100 000\n    jle .L3                      // Jump Less Equal\n    movl    $0, %eax             // Set the return value of main\n    popq    %rbp\n    ret                          // Return from main\n</code></pre> <p><code>gcc ./main.c -o main -OO</code></p>"},{"location":"lecture2/#compilation-assembly_1","title":"Compilation &amp; Assembly","text":"<p>Assembly is as close to the metal we usually get, and is architecture dependant:</p> <ul> <li>Intel and AMD use the x86 Instruction Set </li> <li>x86 has multiple extensions (FMA, sse, avx, avx512, etc.)</li> <li>To maximize performance, we should compile our applications on each platform</li> <li>Our binaries are not portable</li> <li>But we can use dedicated instructions</li> <li>Other instructions set exists (ARM, Risc V, etc.)</li> </ul>"},{"location":"lecture2/#compilation-assembly-optimization-passes","title":"Compilation &amp; Assembly - Optimization passes","text":"<p>The compiler is not just a translator:</p> <ul> <li>The compiler can generate optimized instructions from our program</li> <li>Constant values can be propagated, unused values/code removed</li> <li>Operations can be reordered, inlined, vectorized using SIMD, etc.</li> <li>Many, many more optimizations</li> </ul> <p>Those optimizations are enable through flags such as <code>-O1</code>, <code>-O2</code>, -<code>O3</code> which are predefined sets of optimization passes.</p> <p>The flag <code>-march=native</code> allows the compiler to target the current machine for compilation and use all the available ASM extensions.</p>"},{"location":"lecture2/#compilation-assembly-compiler-pipeline","title":"Compilation &amp; Assembly - Compiler Pipeline","text":"<p>There are several compilers with varying performance and features:</p> <ul> <li>GCC and Clang-LLVM (The classics)</li> <li>MSVC (Microsoft), mingw-LLVM, arm-clang (For ARM) and many, many others.</li> </ul>"},{"location":"lecture2/#makefile-basics-introduction","title":"Makefile Basics - Introduction","text":"<p>Make is a scripting tool to automate complex compilation workflows. It works by defining rules inside Makefiles.</p> <pre><code>CC := gcc\nCFLAGS := -g\n\nmain: main.c my_library.c my_library.h\n  $(CC) -o $@ $^ $(CFLAGS)\n</code></pre> <ul> <li><code>main</code> is the target (What we want to build)</li> <li><code>main.c my_library.c my_library.h</code> are the dependencies: rule reruns if any change</li> <li><code>$(CC) -o $@ $&lt; $(CFLAGS)</code> is the recipe</li> <li><code>$@</code> expands to the target name</li> <li><code>$^</code> expands to all dependency</li> </ul>"},{"location":"lecture2/#makefile-basics-phony-rules","title":"Makefile Basics - Phony rules","text":"<p>Makefiles expects that a rule <code>main</code> produces a file called <code>main</code>. However, not all rules produce files:</p> <pre><code>.PHONY: all clean\n\nall: main mylibrary\n\n...\n\nclean:\n  rm -rf *.o\n  rm -rf ./main\n</code></pre> <p>Here, <code>make all</code> will be an alias to build everything, while <code>make clean</code> is a custom rule to clean all build artifacts. Makefile has many, many other functionalities, outside the scope of this course.</p>"},{"location":"lecture2/#makefile-basics-usage","title":"Makefile Basics - Usage","text":"<p>The typical projects looks something like:</p> <pre><code>Project/\n  src/\n    main.c\n    my_library.c\n  include/\n    my_library.h\n  Makefile # We define the Make rules here\n</code></pre> <p><code>make</code> will look for a file in the <code>cwd</code> named <code>Makefile</code> or <code>makefile</code>. You can directly call <code>make all</code>, <code>make clean</code>, etc.</p>"},{"location":"lecture2/#parallelism-basics","title":"Parallelism Basics","text":""},{"location":"lecture2/#parallelism-basics-introduction","title":"Parallelism Basics - Introduction","text":"<p>Compiler optimization is only one side of high peformance computing.</p> <p>If you remember; we saw in <code>LSTOPO</code> that our CPU has many cores:</p> <ul> <li>Every core can perform computations independently of the other</li> <li>Multiple process (Google, vscode, firefox, excel) can run simultaneously on different cores.</li> <li>The kernel manages execution through thread scheduling and time-slicing</li> </ul>"},{"location":"lecture2/#main-thread","title":"Main Thread","text":"<p>Every process has at least one \"thread of execution\", which is an ordered sequence of instructions executed by the CPU.</p>"},{"location":"lecture2/#parallelism-basics-introduction_1","title":"Parallelism Basics - Introduction","text":"<p>What if we could split our programs into multiple threads ?</p> <ul> <li>If we have 1 thread only one computation happens at a time</li> <li>If we have 2 threads, we can potentially double throughput !</li> </ul> <p>In practice, there is some overhead, we must handle dependencies between instructions, etc.</p>"},{"location":"lecture2/#parallelism-basics-types-of-parallelism","title":"Parallelism Basics - Types of parallelism","text":"<p>We consider three main types of parallelism</p> <ul> <li>Single Instruction Multiple Data (SIMD): also called Vectorization</li> <li>single instruction operates simultaneously on multiple data elements.</li> <li>Shared Memory: Multiple threads inside the same memory space</li> <li>Threads share a memory space, enabling fast communication and synchronization.</li> <li>Distributed Memory: Multiple processes</li> <li>Communications are slower, but this model enables scaling across multiple machines.</li> </ul> <p>For this course, we will only focus on SIMD and Shared Memory parallelism.</p>"},{"location":"lecture2/#parallelism-basics-shared-memory","title":"Parallelism Basics - Shared Memory","text":"<p>Consider the following loop:</p> <pre><code>int sum = 0;\nfor (int i = 0; i &lt; 100; i++)\n  sum += i;\n</code></pre> <p>We can slice the iteration space in multiple chunks:</p> <p></p>"},{"location":"lecture2/#parallelism-basics-shared-memory_1","title":"Parallelism Basics - Shared Memory","text":"<p>We split the program into multiple instruction sequences running in parallel.</p> <ul> <li>Every thread operates a sum on a subset of the data</li> <li>We synchronize every thread and combine the partial sums via a global reduction.</li> </ul> <p><code>OpenMP</code> is an HPC tool designed for scenarios like this !</p> <p>It's a simple to use library/compiler pass to parallelize trivial loops.</p>"},{"location":"lecture2/#parallelism-basics-openmp","title":"Parallelism Basics- <code>OpenMP</code>","text":"<p><pre><code>int sum = 0;\n\n#pragma omp parallel for reduction(sum: +)\nfor (int i = 0; i &lt; 100; i++)\n  sum += i;\n</code></pre> <code>gcc ./main.c -fopenmp -O3 -march=native</code></p> <p>This directive automatically distributes the loop iterations across all available CPU cores,  performing a thread-safe reduction on sum.</p>"},{"location":"lecture2/#parallelism-basics-openmp-details","title":"Parallelism Basics - <code>OpenMP</code> details","text":"<p><code>OpenMP</code> defines a set of <code>clause</code> which are operations followed by a set of modifiers.</p> <ul> <li><code>#pragma omp</code>: is the start of all OpenMP clauses</li> <li><code>parallel:</code> enable the creations of multiple threads</li> <li><code>for</code>: toggle the automatic slicing of following loop</li> <li><code>reduction(sum: +)</code>: toggles a reductions clause for sum using the <code>+</code> operation.</li> </ul> <p>This code will be enough for most cases; but <code>OpenMP</code> allows for significantly more complex operations.</p>"},{"location":"lecture2/#parallelism-basics-advanced-openmp-example","title":"Parallelism Basics - Advanced <code>OpenMP</code> Example","text":"<pre><code>float global_min = FLT_MAX;\nint global_min_index = -1;\n#pragma omp parallel\n{\n  float min_value = FLT_MAX;\n  int min_index = -1;\n#pragma omp for nowait schedule(dynamic)\n  for (int i = 0; i &lt; N; i++) {\n    if (T[i] &lt; min_value) {\n      min_value = T[i];\n      min_index = i;\n    }\n  }\n#pragma omp critical\n  {\n    if (min_value &lt; global_min) {\n      global_min = min_value;\n      global_min_index = min_index;\n    }\n  }\n}\n</code></pre>"},{"location":"lecture2/#naive-nbody-3d-strong-scaling-setup","title":"Naive NBody 3D Strong Scaling - Setup","text":"<p>We increase the number of threads while keeping the work size constant.</p> <p><code>OMP_PLACES={0,2,4,6,8,10,12,14} OMP_PROC_BIND=True OMP_NUM_THREADS=8 ./nbody 10000</code> <code>sudo cpupower frequency-set -g performance</code></p> <p>5 Meta repetitions per run, 13th Gen Intel(R) Core(TM) i7-13850HX @5.30 GHz, 32KB/2MB/30MB:L1/L2/L3 15GB DDR5.</p>"},{"location":"lecture2/#naive-nbody-3d-strong-scaling-results","title":"Naive NBody 3D Strong Scaling - Results","text":"<p>Speedup is limited by runtime overhead, concurrency, memory bandwidth, data size, etc.</p>"},{"location":"lecture3/","title":"Building, Testing and Debugging Scientific Software","text":"<p> Download as slides \ud83d\udce5 </p>"},{"location":"lecture3/#objectives","title":"Objectives","text":"<ul> <li>Build systems: Advanced Makefiles, introduction to CMake for managing multi-file and multi-platform projects.</li> <li>Debugging: GDB, Valgrind for detecting memory errors and leaks.</li> <li>Software testing:</li> <li>Principles: Unit testing, integration testing.</li> <li>Test frameworks in C (e.g., Unity).</li> <li>Importance of testing for regression prevention and validation.</li> <li>Code documentation: Doxygen.</li> </ul>"},{"location":"lecture3/#makefiles","title":"Makefiles","text":""},{"location":"lecture3/#dependency-management","title":"Dependency Management","text":"<ul> <li>How to determine which files have changed?</li> </ul> <ul> <li>dependencies: <code>main.o</code> depends on changes in <code>lib.h</code></li> </ul>"},{"location":"lecture3/#makefile","title":"Makefile","text":"<ul> <li> <p>A <code>Makefile</code> uses a declarative language to describe targets and their dependencies.</p> </li> <li> <p>It is executed by the <code>make</code> command, which allows building different targets.</p> </li> <li> <p><code>make</code> uses timestamps to determine which files have changed.</p> </li> <li> <p><code>make</code> evaluates rules recursively to satisfy dependencies.</p> </li> </ul>"},{"location":"lecture3/#makefile-rule","title":"Makefile Rule","text":"<pre><code>prog: main.c lib.c lib.h\n  clang -o prog main.c lib.c -lm\n\ntarget: dependencies\n\\t  command to build the target from the dependencies\n</code></pre>"},{"location":"lecture3/#separate-compilation","title":"Separate Compilation","text":"<pre><code>prog: main.o lib.o\n  clang -o prog main.o lib.o -lm\n\nmain.o: main.c lib.h\n  clang -c -o main.o main.c\n\nlib.o: lib.c lib.h\n  clang -c -o lib.o lib.c\n</code></pre> <p>If <code>lib.c</code> is modified, which commands will be executed?</p>"},{"location":"lecture3/#phony-targets","title":"Phony Targets","text":"<p>You can add targets that do not correspond to a produced file. For example, it is useful to add a <code>clean</code> target to clean the project.</p> <pre><code>clean:\n  rm -f *.o prog\n.PHONY: clean\n</code></pre> <p><code>.PHONY</code> specifies that the <code>clean</code> rule should always be executed. Declaring all phony targets ensures they are always called (even if a file with the same name is created).</p>"},{"location":"lecture3/#default-rule","title":"Default Rule","text":"<pre><code>make clean\nmake prog\nmake\n</code></pre> <ul> <li>If <code>make</code> is called with a rule, that rule is built.</li> <li>If <code>make</code> is called without arguments, the first rule is built. It is customary to include a default <code>all:</code> rule as the first rule.</li> </ul> <pre><code>all: prog\n\nprog: ...\n</code></pre>"},{"location":"lecture3/#variables","title":"Variables","text":"<pre><code>CC=clang\nCFLAGS=-O2\nLDFLAGS=-lm\n\nprog: main.o lib.o\n  $(CC) -o prog main.o lib.o $(LDFLAGS)\n\nmain.o: main.c lib.h\n  $(CC) $(CFLAGS) -c -o main.o main.c\n\nlib.o: lib.c lib.h\n  $(CC) $(CFLAGS) -c -o lib.o lib.c\n</code></pre> <p>Variables can be overridden when calling <code>make</code>, e.g.,</p> <pre><code>make CC=gcc\n</code></pre>"},{"location":"lecture3/#special-variables","title":"Special Variables","text":"<p><code>$@</code>  target name <code>$^</code>  all dependencies <code>$&lt;</code>  first dependency</p> <pre><code>prog: main.o lib.o\n  $(CC)  -o $@ $^ $(LDFLAGS)\n\nmain.o: main.c lib.h\n  $(CC) $(CFLAGS) -c -o $@ $&lt;\n\nlib.o: lib.c lib.h\n  $(CC) $(CFLAGS) -c -o $@ $&lt; \n</code></pre> <p>The last two rules are very similar...</p>"},{"location":"lecture3/#implicit-rules","title":"Implicit Rules","text":""},{"location":"lecture3/#before","title":"Before","text":"<pre><code>main.o: main.c lib.h\n  $(CC) $(CFLAGS) -c -o $@ $&lt;\n\nlib.o: lib.c lib.h\n  $(CC) $(CFLAGS) -c -o $@ $&lt; \n</code></pre>"},{"location":"lecture3/#with-implicit-rule","title":"With Implicit Rule","text":"<pre><code>%.o: %.c\n  $(CC) $(CFLAGS) -c -o $@ $&lt;\n\nmain.o: lib.h\nlib.o: lib.h\n</code></pre>"},{"location":"lecture3/#other-build-systems","title":"Other Build Systems","text":"<ul> <li> <p>automake / autoconf: automatic generation of complex makefiles and management of system-specific configurations.</p> </li> <li> <p>cmake, scons: successors to Makefile, offering more elegant syntax and new features.</p> </li> </ul>"},{"location":"lecture3/#cmake","title":"CMake","text":""},{"location":"lecture3/#why-cmake","title":"Why CMake?","text":"<ul> <li>Advantages of Makefiles:</li> <li>Simplicity and transparency.</li> <li>No additional tools required.</li> <li> <p>Direct control over the build process.</p> </li> <li> <p>Advantages of CMake:</p> </li> <li>Cross-platform support (Linux, Windows, macOS).</li> <li>Generates build files for multiple build systems (Make, Ninja, etc.).</li> <li>Modular and target-based design.</li> <li>Built-in support for testing, installation, and packaging.</li> </ul>"},{"location":"lecture3/#general-design-of-cmake","title":"General Design of CMake","text":"<ul> <li>CMake as a Meta-Build System:</li> <li>Generates build files for different generators (e.g., Make, Ninja).</li> <li> <p>Abstracts platform-specific details.</p> </li> <li> <p>Workflow:</p> </li> <li>Write <code>CMakeLists.txt</code> to define the project.</li> <li> <p>Configure the project:</p> <pre><code>cmake -B build\n</code></pre> </li> <li> <p>Build the project:</p> <pre><code>cmake --build build\n# or when using Make as backend\nmake -C build\n</code></pre> </li> </ul> <p>Out-of-source builds are recommended to keep source directories clean.</p>"},{"location":"lecture3/#basic-structure-of-cmakeliststxt","title":"Basic Structure of <code>CMakeLists.txt</code>","text":"<pre><code>cmake_minimum_required(VERSION 3.15)\nproject(MyProject LANGUAGES C)\n\nset(CMAKE_C_STANDARD 11)\n</code></pre> <ul> <li><code>cmake_minimum_required</code>: Specifies the minimum version of CMake required.</li> <li><code>project</code>: Defines the project name and the programming language(s) used.</li> <li><code>set</code>: Sets variables, e.g., C standard version.</li> </ul>"},{"location":"lecture3/#adding-an-executable","title":"Adding an Executable","text":"<pre><code>add_executable(my_executable src/main.c)\n</code></pre> <ul> <li>Creates an executable named <code>my_executable</code>.</li> </ul>"},{"location":"lecture3/#adding-a-shared-library","title":"Adding a Shared Library","text":"<pre><code>add_library(my_library SHARED src/library.c)\n</code></pre> <ul> <li>Creates a shared library named <code>libmy_library.so</code> (on Linux).</li> </ul>"},{"location":"lecture3/#linking-libraries-to-executables","title":"Linking Libraries to Executables","text":"<pre><code>add_library(my_library SHARED src/library.c)\nadd_executable(my_executable src/main.c)\ntarget_link_libraries(my_executable PRIVATE my_library)\n</code></pre> <ul> <li><code>add_library</code>: Creates a shared library.</li> <li><code>add_executable</code>: Creates an executable.</li> <li><code>target_link_libraries</code>: Links the library to the executable.</li> </ul> <p>PRIVATE means that <code>my_executable</code> uses <code>my_library</code>, but <code>my_library</code> does not need to be linked when other targets link to <code>my_executable</code>.</p>"},{"location":"lecture3/#library-dependency-transitivity","title":"Library dependency transitivity","text":"<pre><code>add_library(libA SHARED src/libA.c)\nadd_library(libB SHARED src/libB.c)\ntarget_link_libraries(libB PUBLIC libA)\nadd_executable(my_executable src/main.c)\ntarget_link_libraries(my_executable PRIVATE libB)\n</code></pre> <ul> <li><code>my_executable</code> is linked to <code>libB</code> and also to <code>libA</code> because <code>libB</code> links to <code>libA</code> with <code>PUBLIC</code>.</li> <li>If <code>libB</code> linked to <code>libA</code> with <code>PRIVATE</code>, <code>my_executable</code> would not be linked to <code>libA</code>.</li> <li>If <code>libB</code> linked to <code>libA</code> with <code>INTERFACE</code>, <code>my_executable</code> would be linked to <code>libA</code> but not <code>libB</code>.</li> <li>See this reference for more details.</li> </ul>"},{"location":"lecture3/#global-include-directories","title":"Global Include Directories","text":"<pre><code>include_directories(include)\n</code></pre> <ul> <li>Adds the <code>include</code> directory globally for all targets.</li> <li>Limitation: Can lead to conflicts in larger projects.</li> </ul>"},{"location":"lecture3/#target-specific-include-directories","title":"Target-Specific Include Directories","text":"<pre><code>target_include_directories(my_library\n    PUBLIC include\n)\n</code></pre> <ul> <li>PUBLIC: Include directory is needed when building and using the library.</li> <li>PRIVATE: Include directory is needed only when building the library.</li> <li>INTERFACE: Include directory is needed only when using the library.</li> </ul>"},{"location":"lecture3/#porting-our-minimal-makefile-example-to-cmake","title":"Porting our minimal Makefile example to CMake","text":"<pre><code>cmake_minimum_required(VERSION 3.15)\nproject(MyProject LANGUAGES C)\n\n# Add the executable target\nadd_executable(prog main.c lib.c)\n\n# Specify include directories for the target\ntarget_include_directories(prog \n  PRIVATE ${CMAKE_CURRENT_SOURCE_DIR})\n\n# Add compile options\ntarget_compile_options(prog PRIVATE ${CFLAGS})\n\n# Link libraries if needed\ntarget_link_libraries(prog PRIVATE m)\n</code></pre>"},{"location":"lecture3/#debug-vs-release-builds","title":"Debug vs Release Builds","text":"<ul> <li>Debug Build:</li> <li>Includes debug symbols for debugging.</li> <li> <p>Example flags: <code>-g</code>, <code>-O0</code>.</p> </li> <li> <p>Release Build:</p> </li> <li>Optimized for performance.</li> <li>Example flags: <code>-O3</code>, <code>-DNDEBUG</code>.</li> </ul>"},{"location":"lecture3/#setting-build-types-in-cmake","title":"Setting Build Types in CMake","text":"<pre><code>if(NOT CMAKE_BUILD_TYPE)\n  set(CMAKE_BUILD_TYPE RelWithDebInfo CACHE STRING \"Build type\" FORCE)\nendif()\n</code></pre> <ul> <li> <p>Build types: <code>Debug</code>, <code>Release</code>, <code>RelWithDebInfo</code>, <code>MinSizeRel</code>.</p> </li> <li> <p>CACHE: Makes the variable persistent across CMake runs. In out-of-source builds <code>CMakeLists.txt</code> is not re-evaluated on subsequent runs.</p> </li> <li>FORCE: Overrides any previous value.</li> <li>STRING: \"Build type\" provides a description in CMake GUI.</li> </ul>"},{"location":"lecture3/#adding-compiler-flags","title":"Adding Compiler Flags","text":"<pre><code>target_compile_options(my_library PRIVATE\n    $&lt;$&lt;CONFIG:Debug&gt;:-g -Wall&gt;\n    $&lt;$&lt;CONFIG:Release&gt;:-O3 -DNDEBUG&gt;\n)\n</code></pre> <ul> <li>Generator Expressions: <code>$&lt;CONFIG:Debug&gt;</code> applies flags only for Debug builds.</li> </ul>"},{"location":"lecture3/#installing-targets","title":"Installing Targets","text":"<pre><code>install(TARGETS my_library\n    LIBRARY DESTINATION lib\n    PUBLIC_HEADER DESTINATION include\n)\n</code></pre> <ul> <li>Installs the shared library to the <code>lib</code> directory.</li> <li>Installs public headers to the <code>include</code> directory.</li> </ul>"},{"location":"lecture3/#using-gnuinstalldirs","title":"Using GNUInstallDirs","text":"<pre><code>include(GNUInstallDirs)\n\ninstall(TARGETS my_library\n    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n    PUBLIC_HEADER DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}\n)\n</code></pre> <ul> <li>Defines standard GNU library and include directories paths.</li> </ul>"},{"location":"lecture3/#generating-and-building-the-project","title":"Generating and Building the Project","text":"<ol> <li>Configure the Project:</li> </ol> <pre><code>cmake -B build\n</code></pre> <ul> <li> <p>Generates build files in the <code>build</code> directory.</p> </li> <li> <p>Build the Project:</p> </li> </ul> <pre><code>cmake --build build\n# or when using Make as backend\nmake -C build\n</code></pre> <ol> <li>Run the Program:</li> </ol> <pre><code>./build/my_executable\n</code></pre>"},{"location":"lecture3/#best-practices-for-cmake","title":"Best Practices for CMake","text":"<ul> <li>Use Target-Based Commands:</li> <li>Prefer <code>target_include_directories</code> over <code>include_directories</code>.</li> <li> <p>Prefer <code>target_link_libraries</code> over global linking.</p> </li> <li> <p>Organize <code>CMakeLists.txt</code>:</p> </li> <li>Group related targets together.</li> <li> <p>Use comments to explain sections.</p> </li> <li> <p>Avoid Global Commands:</p> </li> <li> <p>Avoid <code>include_directories</code> and <code>link_libraries</code> globally.</p> </li> <li> <p>Use Modern CMake Features:</p> </li> <li>Generator expressions for conditional configurations.</li> <li><code>FetchContent</code> for managing external dependencies.</li> </ul>"},{"location":"lecture3/#debugging-tools","title":"Debugging Tools","text":""},{"location":"lecture3/#buggy-program-example","title":"Buggy program example","text":"<pre><code>/* Linked list of n = 5 nodes\n         .---------.    .---------.           .--------------.\n         | val = 4 |    | val = 3 |           | val = 0      |\n head -&gt; | next  --|--&gt; | next  --|--&gt; ... -&gt; | next =  NULL |\n         '---------'    '---------'           '--------------'\n */\n\n#include &lt;stdlib.h&gt;\n#include &lt;assert.h&gt;\n\nstruct Node\n{\n  int val;\n  struct Node *next;\n};\n\nint main()\n{\n  int n = 5;\n\n  struct Node *head = init_list(n);\n  // ... do something with the list ...\n  delete(head);\n\n  return 0;\n}\n</code></pre>"},{"location":"lecture3/#linked-list-initialization-and-deletion","title":"Linked List Initialization and Deletion","text":"<pre><code>struct Node *init_list(int n)\n{\n  struct Node *head = NULL;\n  for (int i = 0; i &lt; n; ++i)\n  {\n    struct Node *p = malloc(sizeof *p);\n    assert(p != NULL);\n    p-&gt;val = i;\n    p-&gt;next = head;\n    head = p;\n  }\n  return head;\n}\n\nvoid delete(struct Node *head)\n{\n  while (head)\n  {\n    struct Node *next = head-&gt;next;\n    free(head);\n    head = head-&gt;next;\n  }\n}\n</code></pre>"},{"location":"lecture3/#running-the-program","title":"Running the program...","text":"<pre><code>$ gcc -g -O0 -o buggy buggy.c\n$ ./buggy\nSegmentation fault (core dumped)\n</code></pre>"},{"location":"lecture3/#gdb-gnu-debugger","title":"GDB: GNU Debugger","text":"<ul> <li>Inspect the state of a program at the moment it crashes.</li> <li>Step through the code line by line.</li> <li>Inspect variables and memory.</li> <li>Set breakpoints to pause execution at specific lines.</li> </ul> <p>(Live demonstration)</p> <pre><code>$ gdb ./buggy\nProgram received signal SIGSEGV, Segmentation fault.\n0x000055555555522b in delete (head=0xa45d97b66d0683e8) at buggy.c:28\n28          struct Node *next = head-&gt;next;\n(gdb) x head\n0xa45d97b66d0683e8:     Cannot access memory at address 0xa45d97b66d0683e8\n</code></pre>"},{"location":"lecture3/#valgrind-memory-debugging-and-leak-detection","title":"Valgrind: memory debugging and leak detection","text":"<ul> <li>Detects memory leaks, invalid memory access, and uninitialized memory usage.</li> <li>Runs the code in a virtual sandbox that monitors every memory operation.</li> </ul> <p>(Live demonstration)</p> <pre><code>$ valgrind --leak-check=full ./buggy\n==537945== Invalid read of size 8\n==537945==    at 0x109243: delete (buggy.c:30)\n==537945==    by 0x109282: main (buggy.c:40)\n==537945==  Address 0x4a94188 is 8 bytes inside a block of size 16 free'd\n==537945==    at 0x484988F: free (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)\n==537945==    by 0x10923E: delete (buggy.c:29)\n==537945==    by 0x109282: main (buggy.c:40)\n==537945==  Block was alloc'd at\n==537945==    at 0x4846828: malloc (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)\n==537945==    by 0x1091B2: init_list (buggy.c:15)\n==537945==    by 0x109272: main (buggy.c:38)\n</code></pre>"},{"location":"lecture3/#other-tools-asan-ubsan","title":"Other tools: ASAN, UBSAN","text":"<ul> <li>AddressSanitizer (ASAN): Detects memory errors such as buffer overflows and use-after-free.</li> <li>UndefinedBehaviorSanitizer (UBSAN): Detects undefined behavior in C/C++ programs.</li> <li>Works on threaded programs and has lower overhead than Valgrind.</li> </ul> <p>(live demonstration) <pre><code>$ gcc -fsanitize=address -g -O0 -o buggy_asan buggy.c\n$ ./buggy_asan\n=================================================================\n==538335==ERROR: AddressSanitizer: heap-use-after-free on address 0x502000000098 at pc 0x5bec7c7343e9 bp 0x7ffdf3015150 sp 0x7ffdf3015140\nREAD of size 8 at 0x502000000098 thread T0\n    #0 0x5bec7c7343e8 in delete /home/poliveira/test-gdb/buggy.c:30\n    #1 0x5bec7c73442c in main /home/poliveira/test-gdb/buggy.c:40\n</code></pre></p>"},{"location":"lecture3/#software-testing","title":"Software Testing","text":""},{"location":"lecture3/#importance-of-software-testing","title":"Importance of Software Testing","text":"<ul> <li>1996: Ariane-5 self-destructed due to an unhandled floating-point exception, resulting in a $500M loss.</li> <li>1998: Mars Climate Orbiter lost due to navigation data expressed in imperial units, resulting in a $327.6M loss.</li> <li>1988-1994: FAA Advanced Automation System project abandoned due to management issues and overly ambitious specifications, resulting in a $2.6B loss.</li> <li>1985-1987: Therac-25 medical accelerator malfunctioned due to a thread concurrency issue, causing five deaths and numerous injuries.</li> </ul>"},{"location":"lecture3/#technical-debt","title":"Technical Debt","text":""},{"location":"lecture3/#software-costs","title":"Software Costs","text":""},{"location":"lecture3/#verification-and-validation-vv","title":"Verification and Validation (V&amp;V)","text":"<ul> <li>Validation: Does the software meet the client's needs?  </li> <li> <p>\"Are we building the right product?\"</p> </li> <li> <p>Verification: Does the software work correctly?  </p> </li> <li>\"Are we building the product right?\"</li> </ul>"},{"location":"lecture3/#approaches-to-verification","title":"Approaches to Verification","text":"<ul> <li>Formal methods</li> <li>Modeling and simulations</li> <li>Code reviews</li> <li>Testing</li> </ul>"},{"location":"lecture3/#testing-process","title":"Testing Process","text":""},{"location":"lecture3/#v-cycle-model","title":"V Cycle Model","text":""},{"location":"lecture3/#different-types-of-tests","title":"Different Types of Tests","text":"<ul> <li>Unit Tests:</li> <li>Test individual functions in isolation.</li> <li> <p>Test-driven development (TDD): Focus on writing maintainable, simple, and decoupled code.</p> </li> <li> <p>Integration Tests:</p> </li> <li>Test the correct behavior when combining modules.</li> <li> <p>Validate only functional correctness.</p> </li> <li> <p>Validation Tests:</p> </li> <li>Test compliance with specifications.</li> <li> <p>Test other characteristics: performance, security, etc.</p> </li> <li> <p>Acceptance Tests:</p> </li> <li> <p>Validate requirements with the client.</p> </li> <li> <p>Regression Tests:</p> </li> <li>Ensure that fixed bugs do not reappear.</li> </ul>"},{"location":"lecture3/#black-box-and-white-box-testing","title":"Black-Box and White-Box Testing","text":""},{"location":"lecture3/#black-box-testing-functional","title":"Black-Box Testing (Functional)","text":"<ul> <li>Tests are generated from specifications.</li> <li>Uses assumptions different from the programmer's.</li> <li>Tests are independent of implementation.</li> <li>Difficult to find programming defects.</li> </ul>"},{"location":"lecture3/#white-box-testing-structural","title":"White-Box Testing (Structural)","text":"<ul> <li>Tests are generated from source code.</li> <li>Maximizes coverage by testing all code branches.</li> <li>Difficult to find omission or specification errors.</li> </ul> <p>Both approaches are complementary.</p>"},{"location":"lecture3/#what-to-test","title":"What to Test?","text":"<ul> <li>Running the program on all possible inputs is too costly.</li> <li>Choose a subset of inputs:</li> <li>Partition inputs into equivalence classes to maximize coverage.</li> <li>Test all code branches.</li> <li>Test edge cases.</li> <li>Test invalid cases.</li> <li>Test combinations (experimental design).</li> </ul>"},{"location":"lecture3/#example-of-partitioning-13","title":"Example of Partitioning (1/3)","text":""},{"location":"lecture3/#specification","title":"Specification","text":"<pre><code>/* compare returns:\n *   0 if a is equal to b\n *   1 if a is strictly greater than b\n *  -1 if a is strictly less than b\n */\nint compare (int a, int b);\n</code></pre> <p>What inputs should be tested?</p>"},{"location":"lecture3/#equivalence-classes-23","title":"Equivalence Classes (2/3)","text":"Variable Possible Values a {positive, negative, zero} b {positive, negative, zero} result {0, 1, -1}"},{"location":"lecture3/#example-test-cases","title":"Example Test Cases","text":"a b result 10 10 0 20 5 1 3 7 -1 -30 -30 0 -5 -10 1 ... ... ... <p>It is possible to select a subset of classes!</p>"},{"location":"lecture3/#boundary-tests-33","title":"Boundary Tests (3/3)","text":"a b result -2147483648 -1 -1"},{"location":"lecture3/#discussion","title":"Discussion","text":"<ul> <li>Automatic test generation.</li> <li>Test coverage calculation.</li> <li>Mutation testing.</li> <li>Fuzzing.</li> <li>Importance of using automated testing tools.</li> <li>Importance of using continuous integration tools.</li> </ul>"},{"location":"lecture3/#unity-test-framework","title":"Unity Test Framework","text":""},{"location":"lecture3/#introduction-to-unity","title":"Introduction to Unity","text":"<p>Unity Test Framework</p> <ul> <li>Lightweight and simple unit testing framework for C.</li> <li>Designed for embedded systems but can be used in any C project.</li> <li>Provides a set of macros and functions to define and run tests.</li> </ul>"},{"location":"lecture3/#setting-up-unity","title":"Setting Up Unity","text":"<ul> <li> <p>Separate Unity tests into a separate directory, e.g., <code>tests/</code>. </p> </li> <li> <p>Include the Unity header in your test files:</p> </li> </ul> <pre><code>#include \"unity.h\"\n</code></pre> <ul> <li>Requires linking against the Unity library</li> <li>We will link against a static library <code>libunity.a</code>, since Unity uses CMake, we will use FetchContent to add it to our projects.</li> </ul>"},{"location":"lecture3/#writing-tests","title":"Writing Tests","text":"<ul> <li>test_functions use <code>TEST</code> macros provided by Unity to assert conditions.</li> </ul> <pre><code>void test_function_name(void) {\n    ...\n    TEST_ASSERT_EQUAL_INT(expected, actual);\n    TEST_ASSERT_NOT_NULL(pointer);\n    TEST_ASSERT_TRUE(condition);\n    ... \n}\n</code></pre> <ul> <li>Reference for all assertions: Unity Assertions</li> </ul>"},{"location":"lecture3/#example-testing-our-linked-list","title":"Example: testing our linked list","text":"<pre><code>#include \"unity.h\"\n#include \"buggy.h\"\nvoid test_delete_single_node(void) {\n    struct Node *head = init_list(1); \n    TEST_ASSERT_NOT_NULL(head); // head should not be NULL\n    TEST_ASSERT_EQUAL_INT(0, head-&gt;val); // head should be 0\n    delete(head); // should not crash\n    TEST_ASSERT_NULL(head); // head should be NULL after deletion\n}\nvoid test_delete_multiple_nodes(void) {\n    struct Node *head = init_list(5);\n    TEST_ASSERT_EQUAL_INT(4, head-&gt;val); // head should be 4\n    TEST_ASSERT_EQUAL_INT(3, head-&gt;next-&gt;val); \n    delete(head); // should not crash\n    TEST_ASSERT_NULL(head); // head should be NULL after deletion\n}\n</code></pre>"},{"location":"lecture3/#running-tests","title":"Running Tests","text":"<ul> <li>Create a test runner function to execute all tests:</li> </ul> <pre><code>int main(void) ## Boundary Tests{\n    UNITY_BEGIN();\n    RUN_TEST(test_function_name);\n    ...\n    return UNITY_END();\n}\n</code></pre>"},{"location":"lecture3/#setup-and-teardown","title":"SetUp and TearDown","text":"<ul> <li>SetUp and TearDown functions can be defined to run before and after each test.</li> </ul> <pre><code>void setUp(void) {\n    // Code to run before each test\n}\n\nvoid tearDown(void) {\n    // Code to run after each test\n}\n</code></pre>"},{"location":"lecture3/#code-coverage-with-unit-tests","title":"Code Coverage with unit tests","text":"<ul> <li>Use <code>gcov</code> or <code>llvm-cov</code> to measure code coverage of your tests.</li> <li>Compile your code with coverage flags:</li> </ul> <pre><code>gcc --coverage -g -O0 -o test_runner test_runner.c my_code.c -lunity\n</code></pre> <ul> <li> <p>gcov instruments the basic blocks of code to record what is executed during tests.</p> </li> <li> <p>gcovr generate HTML reports showing which parts of the code were covered by tests.</p> </li> </ul>"},{"location":"lecture3/#documentation-with-doxygen","title":"Documentation with Doxygen","text":"<ul> <li>Doxygen is a documentation generator for C, C++, and other languages.</li> <li>It extracts comments from the source code and generates documentation in various formats (HTML, LaTex, etc.).</li> <li>Use special comment blocks to document functions, parameters, return values, and more.</li> <li>Example of a documented function:</li> </ul> <pre><code>/**\n * @brief Initializes a linked list with n nodes.\n * @param n Number of nodes to create.\n * @return Pointer to the head of the linked list\n * @return NULL if memory allocation fails.\n */\nstruct Node *init_list(int n);\n</code></pre> <ul> <li>Generate documentation using the <code>doxygen</code> command with a configuration file (<code>Doxyfile</code>).</li> </ul>"},{"location":"lecture3/#credits-and-bibliography","title":"Credits and Bibliography","text":"<ul> <li>Course \"Automated Software Testing,\" S\u00e9bastien Bardin.</li> <li>CMake Tutorial</li> <li>CMake Best Practices</li> <li>Unity Test Framework</li> <li>Valgrind</li> <li>GDB</li> <li>ASAN/UBSAN</li> <li>Doxygen</li> </ul>"},{"location":"lecture4/","title":"CM4: Experimental Methodology, Profiling, and Performance/Energy Optimization","text":"<p> Download as slides \ud83d\udce5 </p>"},{"location":"lecture4/#scientific-visualization","title":"Scientific visualization","text":""},{"location":"lecture4/#plot-example-intro","title":"Plot Example - Intro","text":"<p>In the following slides, you will be shown a series of plots; mainly taken from the PPN course reports of previous students.</p> <p>For each plot:</p> <ul> <li>Try to understand what is represented</li> <li>Explain what you observe</li> <li>Give a definitive conclusion from the data shown</li> </ul> <p>Raise your hands when ready to propose an explanation.</p>"},{"location":"lecture4/#plot-example-1","title":"Plot Example (1)","text":"<p>PPN Example - (No Caption)</p>"},{"location":"lecture4/#plot-example-2","title":"Plot Example (2)","text":"<p>PPN Example - (No Caption)</p>"},{"location":"lecture4/#plot-example-3","title":"Plot Example (3)","text":"<p>PPN Example - (No Caption)</p>"},{"location":"lecture4/#plot-example-4","title":"Plot Example (4)","text":"<p>PPN Example - \"R\u00e9capitulatif des optimisations faites\"</p>"},{"location":"lecture4/#plot-example-5","title":"Plot Example (5)","text":"<p>PPN Example - \"Nouveau trac\u00e9 de la latence cache\"</p>"},{"location":"lecture4/#plot-example-6","title":"Plot Example (6)","text":"<p>Prof Example - (KNM): (a) Speedup map of GA-Adaptive (7k samples) over the Intel MKL hand-tuning for <code>dgetrf</code> (LU), higher is better. (b) Analysis of the slowdown region (performance regression). (c) Analysis of the high speedup region. \\(3,000\\) random solutions were evaluated for each distribution.</p>"},{"location":"lecture4/#plot-example-7","title":"Plot Example (7)","text":"<p>Prof Example - (SPR): Geometric mean Speedup (higher is better)  against the MKL reference configuration on <code>dgetrf</code> (LU), depending on the sampling algorithm. 46x46 validation grid. 7k/15k/30k denotes the samples count. GA-Adaptive outperforms all other sampling strategies for auto-tuning. With 30k samples it achieves a mean speedup of \\(\\times 1.3\\) of the MKL dgetrf kernel.</p>"},{"location":"lecture4/#plot-example-what-makes-a-good-plot","title":"Plot Example - What makes a good plot","text":"<p>Ask yourself:</p> <ul> <li>What do I want to communicate ?</li> <li>What data do I need ?</li> <li>Is my plot understandable in ~10 seconds ?</li> <li>Is my plot self-contained ?</li> <li>Is the context, environment, and methodology clear ?</li> </ul>"},{"location":"lecture4/#plot-example-summary","title":"Plot Example - Summary","text":"<p>HPC is a scientific endeavour; data analysis and plotting are essential.</p> <ul> <li>Plots drive decisions</li> <li>Plots make results trustworthy</li> <li>Plots explain complex behaviors</li> </ul> <p>Datasets are large, multi-disciplinary, and often hard to reproduce.</p>"},{"location":"lecture4/#experimental-methodology","title":"Experimental Methodology","text":""},{"location":"lecture4/#experimental-methodology-workflow","title":"Experimental Methodology - Workflow","text":""},{"location":"lecture4/#statistical-significance-introduction","title":"Statistical significance - Introduction","text":"<p>Computers are noisy, complex systems:</p> <ul> <li>Thread scheduling is non deterministic -&gt; runtime varies between runs.</li> <li>Dynamic CPU frequency (Turbo/Boost)</li> <li>Systems are heterogeneous (CPU/GPU, dual socket, numa effects, E/P cores)</li> <li>Temperature/thermal throttling can alter runtime</li> </ul> <p>How can we make sure our experimental measurements are reliable and conclusive?</p>"},{"location":"lecture4/#statistical-significance-warm-up-effects","title":"Statistical significance - Warm-up effects","text":"<p>Systems need time to reach steady-state:</p> <p></p> <p>On a laptop: \\(\\mathrm{Mean} = 0.315\\ \\mathrm{ms},\\ \\mathrm{CV} = 13.55\\%\\) </p> <p>We need \"warm-up\" iterations to measure stable performance and skip cold caches, page faults, frequency scaling.</p>"},{"location":"lecture4/#statistical-significance-noise-mitigation","title":"Statistical significance - Noise mitigation","text":"<p>Noise can only be mitigated:</p> <ul> <li>Stop all other background processes (other users)</li> <li>Stabilize CPU Frequency (<code>sudo cpupower -g performance</code>)<ul> <li>Make sure laptops are plugged to avoid powersaving policies</li> </ul> </li> <li>Pin threads via <code>taskset</code>, <code>OMP_PLACES</code> and <code>OMP_PROC_BIND</code></li> <li>Consider hyperthreading</li> <li>Use stable compute nodes</li> </ul> <p>Meta-repetitions are essential to mitigate noisy measurements.</p>"},{"location":"lecture4/#statistical-significance-example","title":"Statistical significance - Example","text":"<p>Same experiment on a stabilized benchmarking server:</p> <p></p> <p>On a laptop: \\(\\mathrm{Mean} = 0.315\\ \\mathrm{ms},\\ \\mathrm{CV} = 13.55\\%\\) Stabilized node: \\(\\mathrm{Mean} = 0.582\\ \\mathrm{ms},\\ \\mathrm{CV} = 1.14\\%\\)</p>"},{"location":"lecture4/#note","title":"Note","text":"<p>Timing on a laptop is always subpar</p>"},{"location":"lecture4/#statistical-significance-mean-median-variance","title":"Statistical significance - Mean, Median, Variance","text":"<p>Single-run measurements are misleading; we need statistics.</p> <ul> <li>Mean runtime \\(\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\)</li> <li>Median: less sensitive to outliers than the mean</li> <li>Variance/standard deviation: Measure of uncertainty</li> <li>Relative metrics are useful: Coefficient of variation (\\(CV = \\frac{\\sigma}{\\bar{x}} \\times 100 \\%\\))</li> </ul> <p>We usually give both the mean and standard deviation when giving performance results. Plots usually show \\(\\bar{x} \\pm 1 \\sigma\\) as a shaded region around the mean to represent uncertainty.</p>"},{"location":"lecture4/#note_1","title":"Note","text":"<p>Distribution plots can be useful: stable measurements are often close to Gaussian,    even if systematic noise may lead to skewed or heavy-tailed distributions.</p>"},{"location":"lecture4/#statistical-significance-confidence-intervals","title":"Statistical significance - Confidence Intervals","text":"<p>How to decide how many repetitions we should perform ?</p> <ul> <li>Usually, the costlier the kernels, the less meta-repetitions are expected</li> <li>Short or really short kernels should have more metas to reduce the influence of noise</li> </ul> <p>Remember that:</p> \\[CI_{0.95} \\approx \\bar{x} \\pm 1.96 \\cdot \\frac{\\sigma}{\\sqrt{n}}\\] <p>More repetitions increase confidence, but returns diminish: CI width \\(\\propto \\tfrac{1}{\\sqrt{n}}\\)</p>"},{"location":"lecture4/#note_2","title":"Note","text":"<p>Confidence intervals are a bit less common in plots than \\(\\pm 1 \\sigma\\) but can also be used !</p>"},{"location":"lecture4/#statistical-significance-p-score-hypothesis-testing","title":"Statistical significance - p-score &amp; Hypothesis testing","text":"<p>In HPC, mean/median and variance often suffice, but hypothesis testing can become handy in some contexts.</p> <ul> <li>Null hypothesis (\\(H_0\\)): GPU and CPU have the same performance for small matrixes<ul> <li>Differences in measurements are only due to noise</li> </ul> </li> <li> <p>Alternative hypothesis: CPU is faster for small matrixes</p> </li> <li> <p>p-value is the probability that \\(H_0\\) explains a phenomenon.</p> </li> <li>If \\(p &lt; 0.05\\), we can safely reject \\(H_0\\) (Statistically significant difference)</li> </ul> <p>Example: \\(\\bar{x}_{GPU} = 5.0 \\mathrm{s}\\), \\(\\sigma_{GPU} = 0.20\\), \\(\\bar{x}_{CPU} = 4.8 \\mathrm{s}\\), \\(\\sigma_{CPU} = 0.4\\), Two-sample t-test with 10 samples \\(p = 0.02\\).</p> <p>The measured differences between CPU and GPU execution time are statistically significant.</p>"},{"location":"lecture4/#experimental-methodology-reproducibility","title":"Experimental Methodology \u2013 Reproducibility","text":"<p>Reproducibility is a very hot topic (Reproducibility crisis in science):</p> <ul> <li>Data and protocols are first-class citizens: as important as the plots themselves  </li> <li>Transparency matters: make data, scripts, and parameters accessible  </li> <li>Enables others to verify, build on, and trust your results</li> </ul>"},{"location":"lecture4/#note_3","title":"Note","text":"<p>Beware of your mindset: your results should be credible and honest before being \"good\".</p> <p>\"Our results are unstable, we have yet to understand why, this is what we tried\"   is a completely valid answer</p>"},{"location":"lecture4/#plotting-tools","title":"Plotting Tools","text":""},{"location":"lecture4/#plotting-tools-cheetsheet","title":"Plotting tools - Cheetsheet","text":""},{"location":"lecture4/#plotting-tools-matplotlib","title":"Plotting tools - Matplotlib","text":""},{"location":"lecture4/#plotting-tools-seaborn","title":"Plotting tools - Seaborn","text":""},{"location":"lecture4/#profiling","title":"Profiling","text":""},{"location":"lecture4/#profiling-time","title":"Profiling - Time","text":""},{"location":"lecture4/#gprof","title":"gprof","text":""},{"location":"lecture4/#perf-introduction","title":"Perf - Introduction","text":""},{"location":"lecture4/#perf-performance-counters","title":"Perf - Performance counters","text":""},{"location":"lecture4/#profiling-energy","title":"Profiling - Energy","text":""},{"location":"lecture4/#perf-energy","title":"Perf - Energy","text":""},{"location":"lecture4/#vtune","title":"Vtune","text":""},{"location":"lecture5/","title":"CM5: HPC pour l\u2019IA","text":"<p> Download as slides \ud83d\udce5 </p>"},{"location":"lecture5/#cm5-hpc-pour-lia","title":"CM5: HPC pour l\u2019IA","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur blandit lorem tincidunt felis luctus posuere. Sed nec eros non justo laoreet aliquam pulvinar at quam. Maecenas sagittis quis purus eu hendrerit. Maecenas egestas sapien metus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Aliquam felis urna, hendrerit vitae lacus quis, pellentesque semper lacus. Sed pharetra ex ut condimentum congue. Pellentesque non malesuada ipsum. Interdum et malesuada fames ac ante ipsum primis in faucibus. In nunc turpis, luctus vitae sem vitae, congue feugiat tellus. Sed pretium ipsum elit, ut iaculis nunc accumsan tincidunt. Nulla elementum libero vitae quam scelerisque imperdiet. </p>"},{"location":"lecture5/#objectifs","title":"Objectifs","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur blandit lorem tincidunt felis luctus posuere. Sed nec eros non justo laoreet aliquam pulvinar at quam. Maecenas sagittis quis purus eu hendrerit. Maecenas egestas sapien metus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Aliquam felis urna, hendrerit vitae lacus quis, pellentesque semper lacus. Sed pharetra ex ut condimentum congue. Pellentesque non malesuada ipsum. Interdum et malesuada fames ac ante ipsum primis in faucibus. In nunc turpis, luctus vitae sem vitae, congue feugiat tellus. Sed pretium ipsum elit, ut iaculis nunc accumsan tincidunt. Nulla elementum libero vitae quam scelerisque imperdiet. </p>"},{"location":"annex/bash_cheatsheet/","title":"Bash Cheatsheet","text":"Goal Command Variants Create a directory <code>mkdir &lt;path&gt;</code> <code>mkdir -p &lt;path&gt;</code> to ignore errors Go inside a directory <code>cd &lt;path&gt;</code> <code>cd ..</code> to go up one level, <code>cd ~</code> to go to your home List all files <code>ls (&lt;path&gt;)</code> <code>ls -lah (&lt;path&gt;)</code> for pretty print with human-readable numbers. Show hidden files Print cwd <code>pwd</code> Convert to absolute path <code>realpath (&lt;path&gt;)</code> Print text <code>echo &lt;text&gt;</code> <code>echo $&lt;VARIABLE&gt;</code> to print a variable Redirect output to file <code>&gt;</code> Example: <code>echo \"Bonjour\" &gt; test.txt</code> Print file content <code>cat &lt;path&gt;</code> For big files: <code>less &lt;path&gt;</code> Delete a file <code>rm &lt;path&gt;</code> Delete a directory <code>rmdir &lt;path&gt;</code> Delete a non empty directory <code>rm -rf &lt;path&gt;</code> Create empty file <code>touch &lt;path&gt;</code> Copy a file <code>cp &lt;input&gt; &lt;output&gt;</code> <code>cp -r &lt;input&gt; &lt;output&gt;</code> to copy folders recursively"},{"location":"annex/install_fedora/","title":"Installing Fedora (Step-by-Step Guide)","text":"<p>This guide explains how to install Fedora and set up the required tools for this course. Following these steps will give you an environment suitable for the entire Master\u2019s program.</p> <p>Note that Dual boot is not covered in this guide.</p>"},{"location":"annex/install_fedora/#requirements","title":"Requirements","text":"<p>To install Fedora, you will need to:</p> <ul> <li>Make a complete backup of all your data (Installation will permanently delete everything already on the computer.)</li> <li>Grab a USB Stick, ~10GB should be enough. Note that the stick will be wiped out</li> <li>A working computer to install Fedora on the USB stick.</li> </ul>"},{"location":"annex/install_fedora/#downloading-fedora","title":"Downloading Fedora","text":"<p>First, you should go to the Fedora website (fedoraproject.org), then download and install the Fedora Media Writer. Make sure you've plugged your USB Stick, then follow these steps:</p> <p></p>"},{"location":"annex/install_fedora/#fedora-version","title":"Fedora Version","text":"<p>Here, I recommend you choose either Fedora Workstation or KDE Plasma Desktop:</p> <ul> <li>Fedora Workstation is the official Gnome version of Fedora: It is very stable and lightweight. The desktop is more akin to MacOS.</li> <li>KDE Plasma Desktop is the official KDE Spin of Fedora. KDE is less stable and can be very heavy, but it's also more similar to Windows and the look-and-feel are easier to customize.</li> </ul> <p>Note that you can switch between the two without reinstalling Fedora, though it requires some steps.</p>"},{"location":"annex/install_fedora/#writing","title":"Writing","text":"<p>Here, you should make sure that:</p> <ul> <li>You select the correct hardware architecture for the target computer. It most likely is Intel/AMD 64 bit.</li> <li>Select your USB Drive, here <code>VendorCo</code> should be the name of your drive.</li> </ul> <p>Danger</p> <p>Remember that the USB drive will be completely erased when you press Download and Write !</p> <p></p> <p>Wait for the download to be complete, then safely remove the USB stick and plug it in the computer you want to install Fedora to.</p> <p>Danger</p> <p>Remember to backup your important files !</p>"},{"location":"annex/install_fedora/#booting-on-fedora","title":"Booting on Fedora","text":"<p>Now, you will need to boot on the Fedora drive to begin the installation.  When you start your device, you should see something akin to PRESS DEL OR F2 TO ENTER BIOS SETTING. Press the corresponding key when you see this screen until your BIOS shows up. You can restart your computer if you need to.</p> <p>On some hardware, F12 or ESC may directly show a temporary boot menu.</p> <p></p> <p>You should see something like this. Note that it may look very different, as this menu is hardware dependant.</p> <p>You should look for something named Boot Priorities or Boot Order, and modify the boot order so that the first item is either:</p> <ul> <li>The name of your USB Drive</li> <li>OR Something like \"Fedora Live Image\"</li> <li>OR \"Boot from USB\"</li> </ul> <p>Make sure you save the settings if necessary, then exit the BIOS. Do not modify anything else in this menu if you don't know what you're doing.</p>"},{"location":"annex/install_fedora/#installing-fedora","title":"Installing Fedora","text":"<p>Now, you PC should reboot into Fedora. It's possible a Grub menu appears with multiple options, you should select the first one named \"Install Fedora\" OR \"Start Fedora Workstation Live\".</p> <p></p> <p>You should then select to \"Install Fedora to Hard Drive\"</p> <p></p> <p>Then:</p> <ul> <li>Select the language of your choice, though I recommend English (United States)</li> <li>Select the correct keyboard layout:<ul> <li>us for QWERTY</li> <li>fr for AZERTY</li> </ul> </li> <li>Click next</li> </ul> <p></p> <p>Select the disk where you want to install Fedora, and make sure you select Use entire disk. Then click Next.</p> <p></p> <p>We will skip encryption for this guide, directly click Next.</p> <p>The next page will summarize the changes and ask you to confirm before starting the installation. You may be asked to create a new used. Make sure to remember the password !</p> <p>Danger</p> <p>Make sure your device is plugged in if its a laptop !</p> <p>When the installation is finished, power off the device, THEN remove the USB drive, then power on. Do not unplug the USB drive while installation is ongoing.</p> <p>Congratulations, Fedora is now installed! You can log in with the user account you created and begin installing the course packages.</p>"},{"location":"annex/oh-my-zsh/","title":"Installing oh-my-zsh","text":"<p>Zsh is a powerful shell that can replace Bash. It provides better auto-completion, improved globbing, and an extensible configuration system.</p> <p>oh-my-zsh is a community-driven framework for managing Zsh configuration. It comes with themes and plugins that make your console more productive.</p>"},{"location":"annex/oh-my-zsh/#1-install-zsh","title":"1) Install Zsh","text":"Fedora<pre><code>sudo dnf install zsh\n</code></pre> Ubuntu/Debian<pre><code>sudo apt update\nsudo apt install zsh\n</code></pre>"},{"location":"annex/oh-my-zsh/#2-install-oh-my-zsh","title":"2) Install oh-my-zsh","text":"<p>Run the official installation script <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre></p> <p>Or look up the command at https://ohmyz.sh/#install</p>"},{"location":"annex/oh-my-zsh/#3-set-zsh-as-the-default-shell","title":"3) Set Zsh as the default shell","text":"<pre><code>chsh -s $(which zsh)\n</code></pre> <p>Note that you may have to log back in for changes to take effect.</p>"},{"location":"annex/oh-my-zsh/#4-add-plugins","title":"4) Add plugins","text":"<p>Open the <code>~/.zshrc</code> file and find this line: <pre><code>plugins=(git)\n</code></pre></p> <p>And change it to: <pre><code>plugins=(git dnf pip zsh-syntax-highlighting zsh-autosuggestions)\n</code></pre></p> <p>Then run Fedora<pre><code>sudo dnf install zsh-syntax-highlighting zsh-autosuggestions\n</code></pre></p>"},{"location":"annex/oh-my-zsh/#5-optional-set-up-powerlevel-10k","title":"5) Optional: Set up powerlevel-10k","text":"<p>powerlevel-10k is a nice theme for oh-my-zsh which I highly recommend.</p> <p>You can find up-to-date installation instructions at <code>https://github.com/romkatv/powerlevel10k</code>.</p>"}]}